
## data_standardortools_collection


|collection|concerns_data_topic|has_relevant_organization|purpose_detail|is_open|requires_registration|url|publication|formal_specification|id|category|name|description|subclass_of|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||The ACE file format is a specification for storing data about genomic contigs. The original ACE format was developed for use with Consed, a program for viewing, editing, and finishing DNA sequence assemblies. ACE files are generated by various assembly programs, including Phrap, CAP3, Newbler, Arachne, AMOS (sequence assembly) (more specifically Minimo) and Tigr Assembler v2.|True|False|[https://en.wikipedia.org/wiki/ACE_(genomic_file_format)](https://en.wikipedia.org/wiki/ACE_(genomic_file_format))||[https://web.archive.org/web/20100609072313/http://bcr.musc.edu/manuals/CONSED.txt](https://web.archive.org/web/20100609072313/http://bcr.musc.edu/manuals/CONSED.txt)|[STANDARDSDATASTANDARDORTOOL:1](https://w3id.org/bridge2ai/standards-datastandardortool-schema/1)|[BiomedicalStandard](BiomedicalStandard)|.ACE format|.ACE format||
| policy|| [STANDARDSORGANIZATION:67](STANDARDSORGANIZATION:67)|NIH has issued the Data Management and Sharing (DMS) policy (effective January 25, 2023) to promote the sharing of scientific data. Sharing scientific data accelerates biomedical research discovery, in part, by enabling validation of research results, providing accessibility to high-value datasets, and promoting data reuse for future research studies. Under the DMS policy, NIH expects that investigators and institutions do the following. Plan and budget for the managing and sharing of data, Submit a DMS plan for review when applying for funding, Comply with the approved DMS plan.|True|False|[https://sharing.nih.gov/data-management-and-sharing-policy/about-data-management-and-sharing-policy/data-management-and-sharing-policy-overview](https://sharing.nih.gov/data-management-and-sharing-policy/about-data-management-and-sharing-policy/data-management-and-sharing-policy-overview)|||[STANDARDSDATASTANDARDORTOOL:2](https://w3id.org/bridge2ai/standards-datastandardortool-schema/2)|[BiomedicalStandard](BiomedicalStandard)|DMS|2023 NIH Data Management and Sharing Policy||
| datamodel| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)| [STANDARDSORGANIZATION:93](STANDARDSORGANIZATION:93)|The Access to Biological Collections Data (ABCD) Schema is an evolving comprehensive standard for the access to and exchange of data about specimens and observations (a.k.a. primary biodiversity data). The ABCD Schema attempts to be comprehensive and highly structured, supporting data from a wide variety of databases. It is compatible with several existing data standards. Parallel structures exist so that either (or both) atomised data and free-text can be accommodated. Version 1.2 is currently in use with the GBIF (Global Biodiversity Information Facility) and BioCASE (Biological Collection Access Service for Europe) networks. Apart from the GBIF and BioCASE networks, the potential for the application of ABCD extends to internal networks, or in-house legacy data access (e.g. datasets from external sources that shall not be converted and integrated into an institution's own data, but be kept separately, though easily accessible). By defining relations between terms, ABCD is a step towards an ontology for biological collections.|True|False|[https://abcd.tdwg.org/](https://abcd.tdwg.org/)|||[STANDARDSDATASTANDARDORTOOL:3](https://w3id.org/bridge2ai/standards-datastandardortool-schema/3)|[BiomedicalStandard](BiomedicalStandard)|ABCD|Access to Biological Collections Data Schema||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||AGP format describes the assembly of a larger sequence object from smaller objects. The large object can be a contig, a scaffold (supercontig), or a chromosome. Each line (row) of the AGP file describes a different piece of the object, and has the column entries defined below. Extended comments follow. It does not serve for either a description of how sequence reads were assembled, or a description of the alignments between components used to construct a larger object. Not all of the information in proprietary assembly files can be represented in the AGP format. It is also not for recording the spans of features like repeats or genes.|True|False|[https://www.ncbi.nlm.nih.gov/assembly/agp/AGP_Specification/](https://www.ncbi.nlm.nih.gov/assembly/agp/AGP_Specification/)|||[STANDARDSDATASTANDARDORTOOL:4](https://w3id.org/bridge2ai/standards-datastandardortool-schema/4)|[BiomedicalStandard](BiomedicalStandard)|AGP|AGP format||
| markuplanguage| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)| [STANDARDSORGANIZATION:8](STANDARDSORGANIZATION:8)|The Analytical Information Markup Language (AnIML) is the emerging ASTM XML standard for analytical chemistry data. It is currently in pre-release form. It is a combination of a highly flexible core schema that defines XML tagging for any kind of analytical information; A set of technique definition documents. These XML files, one per analytical technique, apply tight constraints to the flexible core and in turn are defined by the Technique Schema; Extensions to Technique Definitions are possible to accommodate vendor- and institution-specific data fields. Mission Statement Our goal is to serve as the open-source development platform for a new XML standard for Analytical Chemistry Information. The project is a collaborative effort between many groups and individuals and is sanctioned by the ASTM subcommittee E13.15. http://animl.cvs.sourceforge.net/viewvc/animl/schema/animl-core.xsd|True|False|[https://www.animl.org/](https://www.animl.org/)|||[STANDARDSDATASTANDARDORTOOL:5](https://w3id.org/bridge2ai/standards-datastandardortool-schema/5)|[BiomedicalStandard](BiomedicalStandard)|AnIML|Analytical Information Markup Language||
| guidelines|||Guidelines intended to improve the reporting of animal experiments.|True|False|[https://arriveguidelines.org/](https://arriveguidelines.org/)|[doi:10.1371/journal.pbio.3000411](doi:10.1371/journal.pbio.3000411)||[STANDARDSDATASTANDARDORTOOL:6](https://w3id.org/bridge2ai/standards-datastandardortool-schema/6)|[BiomedicalStandard](BiomedicalStandard)|ARRIVE|Animal Research Reporting In Vivo Experiments||
|| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|Provides a common means of electronically storing both the ECG wave form and associated annotations.|True|False|||[https://www.hl7.org/implement/standards/product_brief.cfm?product_id=70](https://www.hl7.org/implement/standards/product_brief.cfm?product_id=70)|[STANDARDSDATASTANDARDORTOOL:7](https://w3id.org/bridge2ai/standards-datastandardortool-schema/7)|[BiomedicalStandard](BiomedicalStandard)|aECG|Annotated ECG standard||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9) [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSORGANIZATION:71](STANDARDSORGANIZATION:71)|The Annotation and Image Markup project provides a standardized schema for capturing the results of medical imaging exams, primarily radiology, using controlled terminologies/ontologies. AIM captures results in terms of the region within an image in which areas of interest are located, the semantic descriptions of those regions, inferences about them, calculations on them, and quantitative features derived by computer programs run on them. AIM is interoperable with DICOM-SR and HL7-CDA, other standards for image metadata, but it provides unique advantages by providing an explicit semantic model of imaging results.|True|False|||[https://github.com/NCIP/annotation-and-image-markup](https://github.com/NCIP/annotation-and-image-markup)|[STANDARDSDATASTANDARDORTOOL:8](https://w3id.org/bridge2ai/standards-datastandardortool-schema/8)|[BiomedicalStandard](BiomedicalStandard)|AIM|Annotation and Image Markup schema||
| guidelines|| [STANDARDSORGANIZATION:4](STANDARDSORGANIZATION:4)|AI in healthcare; three major expressions of how trust is created and maintained - Human Trust, Technical Trust, and Regulatory Trust.|False|False|[https://shop.cta.tech/collections/standards/products/the-use-of-artificial-intelligence-in-healthcare-trustworthiness-cta-2090](https://shop.cta.tech/collections/standards/products/the-use-of-artificial-intelligence-in-healthcare-trustworthiness-cta-2090)|||[STANDARDSDATASTANDARDORTOOL:9](https://w3id.org/bridge2ai/standards-datastandardortool-schema/9)|[BiomedicalStandard](BiomedicalStandard)|ANSI/CTA-2090|ANSI/CTA Standard - The Use of Artificial Intelligence in Health Care Trustworthiness||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A binary version of raw DNA sequence reads from Applied Biosystems sequencing analysis software. Also known as ABIF.|False|False|||[https://projects.nfstc.org/workshops/resources/articles/ABIF_File_Format.pdf](https://projects.nfstc.org/workshops/resources/articles/ABIF_File_Format.pdf)|[STANDARDSDATASTANDARDORTOOL:10](https://w3id.org/bridge2ai/standards-datastandardortool-schema/10)|[BiomedicalStandard](BiomedicalStandard)|AB1|Applied Biosystems sequence read binary format file||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A binary version of raw DNA sequence reads from Applied Biosystems sequencing analysis software.|False|False|||[https://tools.thermofisher.com/content/sfs/manuals/4346366_DNA_Sequenc_Analysis_5_1_UG.pdf](https://tools.thermofisher.com/content/sfs/manuals/4346366_DNA_Sequenc_Analysis_5_1_UG.pdf)|[STANDARDSDATASTANDARDORTOOL:11](https://w3id.org/bridge2ai/standards-datastandardortool-schema/11)|[BiomedicalStandard](BiomedicalStandard)|ABI|Applied Biosystems sequence read binary format file||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A binary alignment format used by the ARB package.|True|False|[http://www.arb-home.de/documentation.html](http://www.arb-home.de/documentation.html)|[doi:10.1093/nar/gkh293](doi:10.1093/nar/gkh293)||[STANDARDSDATASTANDARDORTOOL:12](https://w3id.org/bridge2ai/standards-datastandardortool-schema/12)|[BiomedicalStandard](BiomedicalStandard)|ARB|ARB software binary alignment format||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:79](STANDARDSORGANIZATION:79)|ADL is designed as an abstract human-readable and computer-processible syntax. ADL archetypes can be hand-edited using a normal text editor. The intended audience includes standards bodies producing health informatics standards; Academic groups using openEHR; The open source healthcare community; Solution vendors; Medical informaticians and clinicians interested in health information.|True|False|||[https://specifications.openehr.org/releases/AM/latest/ADL1.4.html](https://specifications.openehr.org/releases/AM/latest/ADL1.4.html)|[STANDARDSDATASTANDARDORTOOL:13](https://w3id.org/bridge2ai/standards-datastandardortool-schema/13)|[BiomedicalStandard](BiomedicalStandard)|ADL|Archetype Definition Language||
| datamodel| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|Specifications for sharing single sets of patient care plans. Based on FHIR R2.|True|False|[http://www.fhir.org/guides/argonaut/r2/StructureDefinition-argo-careplan.html](http://www.fhir.org/guides/argonaut/r2/StructureDefinition-argo-careplan.html)|||[STANDARDSDATASTANDARDORTOOL:14](https://w3id.org/bridge2ai/standards-datastandardortool-schema/14)|[BiomedicalStandard](BiomedicalStandard)|StructureDefinition-argo-careplan|Argonaut Data Query Implementation Guide||
| minimuminformationschema| [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16)||The curation process is significantly slowed down by missing information in the articles analyzed. The identity of the clones used to generate ISH probes and the precise sequences tested in reporter assays constituted the most frequent omissions. To help authors ensure in the future that necessary information is present in their article, the Article Minimum Information Standard (AMIS) guidelines have been defined. The guideline describes the mandatory (and useful) information that should be mentioned in literature articles to facilitate the curation process. These guidelines extend the minimal information defined by the MISFISHIE format (Deutsch at al. 2008, Nature Biotechnology).|True|False||[doi:10.1038/npre.2010.5054.1](doi:10.1038/npre.2010.5054.1)||[STANDARDSDATASTANDARDORTOOL:15](https://w3id.org/bridge2ai/standards-datastandardortool-schema/15)|[BiomedicalStandard](BiomedicalStandard)|AMIS|Article Minimum Information Standard||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A format for sequence alignments.|True|False|[https://genome.ucsc.edu/goldenPath/help/axt.html](https://genome.ucsc.edu/goldenPath/help/axt.html)|||[STANDARDSDATASTANDARDORTOOL:16](https://w3id.org/bridge2ai/standards-datastandardortool-schema/16)|[BiomedicalStandard](BiomedicalStandard)|Axt|Axt Alignment Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A file containing the index for a Binary Alignment Map (BAM) file.|True|False|[https://www.ncbi.nlm.nih.gov/tools/gbench/tutorial6/](https://www.ncbi.nlm.nih.gov/tools/gbench/tutorial6/)|||[STANDARDSDATASTANDARDORTOOL:17](https://w3id.org/bridge2ai/standards-datastandardortool-schema/17)|[BiomedicalStandard](BiomedicalStandard)|BAI|BAM indexing format file||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||The bedGraph format allows display of continuous-valued data in track format.|True|False|[http://genome.ucsc.edu/goldenPath/help/bedgraph.html](http://genome.ucsc.edu/goldenPath/help/bedgraph.html)|||[STANDARDSDATASTANDARDORTOOL:18](https://w3id.org/bridge2ai/standards-datastandardortool-schema/18)|[BiomedicalStandard](BiomedicalStandard)|BEDgraph|BEDgraph format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||The bigBed format stores annotation items that can be either a simple or a linked collection of exons, much as BED files do.|True|False|[https://genome.ucsc.edu/goldenPath/help/bigBed.html](https://genome.ucsc.edu/goldenPath/help/bigBed.html)|||[STANDARDSDATASTANDARDORTOOL:19](https://w3id.org/bridge2ai/standards-datastandardortool-schema/19)|[BiomedicalStandard](BiomedicalStandard)|bigBED|Big Browser Extensible Data Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||The bigWig format is for display of dense, continuous data that will be displayed in the Genome Browser as a graph.|True|False|[https://genome.ucsc.edu/goldenPath/help/bigWig.html](https://genome.ucsc.edu/goldenPath/help/bigWig.html)|||[STANDARDSDATASTANDARDORTOOL:20](https://w3id.org/bridge2ai/standards-datastandardortool-schema/20)|[BiomedicalStandard](BiomedicalStandard)|bigWig|Big Wiggle Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||sequencing alignment|True|False|[https://samtools.github.io/hts-specs/](https://samtools.github.io/hts-specs/)|||[STANDARDSDATASTANDARDORTOOL:21](https://w3id.org/bridge2ai/standards-datastandardortool-schema/21)|[BiomedicalStandard](BiomedicalStandard)|BAM/CRAM|Binary Alignment Map / Compressed Reference-oriented Alignment Map||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A BAM file (.bam) is the binary version of a SAM file.|True|False|[https://en.wikipedia.org/wiki/Binary_Alignment_Map](https://en.wikipedia.org/wiki/Binary_Alignment_Map)||[https://samtools.github.io/hts-specs/SAMv1.pdf](https://samtools.github.io/hts-specs/SAMv1.pdf)|[STANDARDSDATASTANDARDORTOOL:22](https://w3id.org/bridge2ai/standards-datastandardortool-schema/22)|[BiomedicalStandard](BiomedicalStandard)|BAM|Binary Alignment Map format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A .2bit file stores multiple DNA sequences (up to 4 Gb total) in a compact randomly-accessible format. The file contains masking information as well as the DNA itself.|True|False|[http://genome.ucsc.edu/FAQ/FAQformat.html#format7](http://genome.ucsc.edu/FAQ/FAQformat.html#format7)|||[STANDARDSDATASTANDARDORTOOL:23](https://w3id.org/bridge2ai/standards-datastandardortool-schema/23)|[BiomedicalStandard](BiomedicalStandard)|2bit|Binary sequence information Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A binary version of the variant call format (VCF).|True|False|[https://samtools.github.io/bcftools/bcftools.html](https://samtools.github.io/bcftools/bcftools.html)|||[STANDARDSDATASTANDARDORTOOL:24](https://w3id.org/bridge2ai/standards-datastandardortool-schema/24)|[BiomedicalStandard](BiomedicalStandard)|BCF|Binary variant call format||
|| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)| [IEEE](IEEE)|Because of the many different ways to organize data, a major goal of the BioCompute project is to build and maintain a formal standard through recognized, accredited standards setting organizations like the Institute for Electrical and Electronics Engineers (IEEE) and the International Standards Organization (ISO). A formal, consensus-based standard builds predictability and even more stability into the way in which bioinformatic methods are communicated. The standard, officially known as 2791-2020, has two parts, the standards document and the schema, which is maintained in an open source repository.|True|False|[https://docs.biocomputeobject.org/user_guide/](https://docs.biocomputeobject.org/user_guide/)|[doi:10.5731/pdajpst.2016.006734](doi:10.5731/pdajpst.2016.006734)||[STANDARDSDATASTANDARDORTOOL:25](https://w3id.org/bridge2ai/standards-datastandardortool-schema/25)|[BiomedicalStandard](BiomedicalStandard)|BioCompute|BioCompute Object standard||
| datamodel| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20)| [STANDARDSORGANIZATION:67 NCATS Translator](STANDARDSORGANIZATION:67 NCATS Translator)|A high level datamodel of biological entities (genes, diseases, phenotypes, pathways, individuals, substances, etc) and their associations.|True|False|[https://biolink.github.io/biolink-model/](https://biolink.github.io/biolink-model/)|[doi:10.1111/cts.13302](doi:10.1111/cts.13302)||[STANDARDSDATASTANDARDORTOOL:26](https://w3id.org/bridge2ai/standards-datastandardortool-schema/26)|[BiomedicalStandard](BiomedicalStandard)|Biolink|Biolink Model||
| markuplanguage|||A language for representing scientific findings in the life sciences in a computable form.|True|False|[https://bel.bio/](https://bel.bio/)||[https://language.bel.bio/](https://language.bel.bio/)|[STANDARDSDATASTANDARDORTOOL:27](https://w3id.org/bridge2ai/standards-datastandardortool-schema/27)|[BiomedicalStandard](BiomedicalStandard)|BEL|Biological Expression Language||
||| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15) [STANDARDSORGANIZATION:31](STANDARDSORGANIZATION:31) [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40) [STANDARDSORGANIZATION:71](STANDARDSORGANIZATION:71)|The Biomedical Research Integrated Domain Group (BRIDG) Model is a collaborative effort engaging stakeholders from the Clinical Data Interchange Standards Consortium (CDISC), the HL7 BRIDG Work Group, the US National Cancer Institute (NCI), and the US Food and Drug Administration (FDA). The goal of the BRIDG Model is to produce a shared view of the dynamic and static semantics for the domain of basic, pre-clinical, clinical, and translational research and its associated regulatory artifacts.|True|False|[https://bridgmodel.nci.nih.gov/](https://bridgmodel.nci.nih.gov/)|[doi:10.1093/jamia/ocx004](doi:10.1093/jamia/ocx004)|[https://github.com/CBIIT/bridg-model/](https://github.com/CBIIT/bridg-model/)|[STANDARDSDATASTANDARDORTOOL:28](https://w3id.org/bridge2ai/standards-datastandardortool-schema/28)|[BiomedicalStandard](BiomedicalStandard)|BRIDG Model|Biomedical Research Integrated Domain Group Model||
| markuplanguage| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||BioPAX is a standard language that aims to enable integration, exchange, visualization and analysis of biological pathway data. Specifically, BioPAX supports data exchange between pathway data groups and thus reduces the complexity of interchange between data formats by providing an accepted standard format for pathway data. By offering a standard, with well-defined semantics for pathway representation, BioPAX allows pathway databases and software to interact more efficiently. In addition, BioPAX enables the development of pathway visualization from databases and facilitates analysis of experimentally generated data through combination with prior knowledge. The BioPAX effort is coordinated closely with that of other pathway related standards initiatives namely; PSI-MI, SBML, CellML, and SBGN in order to deliver a compatible standard in the areas where they overlap.|True|False|[http://www.biopax.org/](http://www.biopax.org/)|[doi:10.1038/nbt.1666](doi:10.1038/nbt.1666)||[STANDARDSDATASTANDARDORTOOL:29](https://w3id.org/bridge2ai/standards-datastandardortool-schema/29)|[BiomedicalStandard](BiomedicalStandard)|BioPAX|BioPAX standard||
|| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)| [STANDARDSORGANIZATION:28](STANDARDSORGANIZATION:28)|Bioschemas aims to improve the Findability on the Web of life sciences resources such as datasets, software, and training materials.|True|False|[https://bioschemas.org/](https://bioschemas.org/)||[https://github.com/BioSchemas/specifications](https://github.com/BioSchemas/specifications)|[STANDARDSDATASTANDARDORTOOL:30](https://w3id.org/bridge2ai/standards-datastandardortool-schema/30)|[BiomedicalStandard](BiomedicalStandard)|Bioschemas|Bioschemas||
| guidelines| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)| [STANDARDSORGANIZATION:72](STANDARDSORGANIZATION:72)|Human biospecimens are subject to a number of different collection, processing, and storage factors that can significantly alter their molecular composition and consistency. These biospecimen preanalytical factors, in turn, influence experimental outcomes and the ability to reproduce scientific results. Currently, the extent and type of information specific to the biospecimen preanalytical conditions reported in scientific publications and regulatory submissions varies widely. To improve the quality of research utilizing human tissues, it is critical that information regarding the handling of biospecimens be reported in a thorough, accurate, and standardized manner. The Biospecimen Reporting for Improved Study Quality (BRISQ) recommendations outlined herein are intended to apply to any study in which human biospecimens are used. The purpose of reporting these details is to supply others, from researchers to regulators, with more consistent and standardized information to better evaluate, interpret, compare, and reproduce the experimental results. The BRISQ guidelines are proposed as an important and timely resource tool to strengthen communication and publications around biospecimen-related research and help reassure patient contributors and the advocacy community that the contributions are valued and respected|True|False||[doi:10.1002/cncy.20147](doi:10.1002/cncy.20147)||[STANDARDSDATASTANDARDORTOOL:31](https://w3id.org/bridge2ai/standards-datastandardortool-schema/31)|[BiomedicalStandard](BiomedicalStandard)|BRISQ|Biospecimen Reporting for Improved Study Quality||
| datamodel| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20)| [STANDARDSORGANIZATION:28](STANDARDSORGANIZATION:28)|Data model and exchange formats for basic bioinformatics types of data - sequences, alignments, feature records with associated data and metadata.|True|False|[http://bioxsd.org/](http://bioxsd.org/)|[doi:10.1093/bioinformatics/btq391](doi:10.1093/bioinformatics/btq391)|[https://github.com/bioxsd/bioxsd](https://github.com/bioxsd/bioxsd)|[STANDARDSDATASTANDARDORTOOL:32](https://w3id.org/bridge2ai/standards-datastandardortool-schema/32)|[BiomedicalStandard](BiomedicalStandard)|BioXSD|BioXSD||
| datamodel| [STANDARDSDATATOPIC:22](STANDARDSDATATOPIC:22)||The Brain Imaging Data Structure (BIDS) is a simple and intuitive way to organize and describe data. This document defines the BIDS specification, which provides many details to help implement the standard. It includes the core specification as well as many extensions to specific brain imaging modalities, and increasingly also to other kinds of data.|True|False|[https://bids-specification.readthedocs.io/en/stable/](https://bids-specification.readthedocs.io/en/stable/)|[doi:10.1038/sdata.2016.44](doi:10.1038/sdata.2016.44)|[https://github.com/bids-standard/bids-specification](https://github.com/bids-standard/bids-specification)|[STANDARDSDATASTANDARDORTOOL:33](https://w3id.org/bridge2ai/standards-datastandardortool-schema/33)|[BiomedicalStandard](BiomedicalStandard)|BIDS|Brain Imaging Data Structure||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||The Brief Fatigue Inventory (BFI) is used to rapidly assess the severity and impact of cancer-related fatigue. An increasing focus on cancer-related fatigue emphasized the need for sensitive tools to assess this most frequently reported symptom. The six interference items correlate with standard quality-of-life measures.|True|False|[https://www.mdanderson.org/research/departments-labs-institutes/departments-divisions/symptom-research/symptom-assessment-tools/brief-fatigue-inventory.html](https://www.mdanderson.org/research/departments-labs-institutes/departments-divisions/symptom-research/symptom-assessment-tools/brief-fatigue-inventory.html)|[doi:10.1002/(sici)1097-0142(19990301)85:5<1186::aid-cncr24>3.0.co;2-n](doi:10.1002/(sici)1097-0142(19990301)85:5<1186::aid-cncr24>3.0.co;2-n)|[http://www.npcrc.org/files/news/brief_fatigue_inventory.pdf](http://www.npcrc.org/files/news/brief_fatigue_inventory.pdf)|[STANDARDSDATASTANDARDORTOOL:34](https://w3id.org/bridge2ai/standards-datastandardortool-schema/34)|[BiomedicalStandard](BiomedicalStandard)|BFI|Brief Fatigue Inventory||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||The Brief Pain Inventory (BPI) rapidly assesses the severity of pain and its impact on functioning. The BPI has been translated into dozens of languages, and it is widely used in both research and clinical settings.|True|False|[https://www.mdanderson.org/research/departments-labs-institutes/departments-divisions/symptom-research/symptom-assessment-tools/brief-pain-inventory.html](https://www.mdanderson.org/research/departments-labs-institutes/departments-divisions/symptom-research/symptom-assessment-tools/brief-pain-inventory.html)||[http://www.npcrc.org/files/news/briefpain_short.pdf](http://www.npcrc.org/files/news/briefpain_short.pdf)|[STANDARDSDATASTANDARDORTOOL:35](https://w3id.org/bridge2ai/standards-datastandardortool-schema/35)|[BiomedicalStandard](BiomedicalStandard)|BPI|Brief Pain Inventory||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||BED (Browser Extensible Data) format provides a flexible way to define the data lines that are displayed in an annotation track. BED lines have three required fields and nine additional optional fields. The number of fields per line must be consistent throughout any single set of data in an annotation track. The order of the optional fields is binding. Lower-numbered fields must always be populated if higher-numbered fields are used.|True|False|[https://genome.ucsc.edu/FAQ/FAQformat.html#format1](https://genome.ucsc.edu/FAQ/FAQformat.html#format1)||[https://github.com/samtools/hts-specs/blob/master/BEDv1.pdf](https://github.com/samtools/hts-specs/blob/master/BEDv1.pdf)|[STANDARDSDATASTANDARDORTOOL:36](https://w3id.org/bridge2ai/standards-datastandardortool-schema/36)|[BiomedicalStandard](BiomedicalStandard)|BED|Browser Extensible Data Format||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:10](STANDARDSORGANIZATION:10)|A graphical notation that depicts the steps in a business process. BPMN depicts the end-to-end flow of a business process. The notation has been specifically designed to coordinate the sequence of processes and the messages that flow between different process participants in a related set of activities.|True|False|[https://www.omg.org/bpmn/index.htm](https://www.omg.org/bpmn/index.htm)|||[STANDARDSDATASTANDARDORTOOL:37](https://w3id.org/bridge2ai/standards-datastandardortool-schema/37)|[BiomedicalStandard](BiomedicalStandard)|BPMN|Business Process Modeling Notation||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:10](STANDARDSORGANIZATION:10)|A common meta- model and notation for modeling and graphically expressing a case as well as an interchange format for exchanging case models among different tools.|True|False|[https://www.omg.org/cmmn/](https://www.omg.org/cmmn/)|||[STANDARDSDATASTANDARDORTOOL:38](https://w3id.org/bridge2ai/standards-datastandardortool-schema/38)|[BiomedicalStandard](BiomedicalStandard)|CMMN|Case Management Model and Notation||
| guidelines| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)||The CARE guidelines provide a framework that supports transparency and accuracy in the publication of case reports and the reporting of information from patient encounters.|True|False|[https://www.care-statement.org/](https://www.care-statement.org/)|||[STANDARDSDATASTANDARDORTOOL:39](https://w3id.org/bridge2ai/standards-datastandardortool-schema/39)|[BiomedicalStandard](BiomedicalStandard)|CARE|Case Report guidelines||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|The CDISC Case Report Tabulation Data Definition Specification (define.xml) Version 1.0 reflects changes from a comment period through the Health Level 7 (HL7) Regulated Clinical Research Information Management Technical Committee (RCRIM) in December 2003 (www.hl7.org) and CDISC's website in September 2004 as well as the work done by the define.xml team in conjunction with the CDISC ODM team to add functionality, features, and additional documentation. This document specifies the standard for providing Case Report Tabulations Data Definitions in an XML format for submission to regulatory authorities (e.g., FDA). The XML schema used to define the expected structure for these XML files is based on an extension to the CDISC Operational Data Model (ODM). The 1999 FDA electronic submission (eSub) guidance and the electronic Common Technical Document (eCTD) documents specify that a document describing the content and structure of the included data should be provided within a submission. This document is known as the Data Definition Document (e.g., "define.pdf" in the 1999 guidance). The Data Definition Document provides a list of the datasets included in the submission along with a detailed description of the contents of each dataset. To increase the level of automation and improve the efficiency of the Regulatory Review process, define.xml can be used to provide the Data Definition Document in a machine-readable format.|True|True|[https://www.cdisc.org/standards/data-exchange/define-xml](https://www.cdisc.org/standards/data-exchange/define-xml)|||[STANDARDSDATASTANDARDORTOOL:40](https://w3id.org/bridge2ai/standards-datastandardortool-schema/40)|[BiomedicalStandard](BiomedicalStandard)|Define|CDISC Case Report Tabulation Data Definition Specification||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|Controlled terminology for data analysis and assessments.|True|False|[https://evs.nci.nih.gov/ftp1/CDISC/ADaM/ADaM%20Terminology.html](https://evs.nci.nih.gov/ftp1/CDISC/ADaM/ADaM%20Terminology.html)||[https://evs.nci.nih.gov/ftp1/CDISC/ADaM/](https://evs.nci.nih.gov/ftp1/CDISC/ADaM/)|[STANDARDSDATASTANDARDORTOOL:41](https://w3id.org/bridge2ai/standards-datastandardortool-schema/41)|[BiomedicalStandard](BiomedicalStandard)|CDISC ADaM|CDISC Controlled Terminology for Analysis Dataset Model||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|Controlled terminology for biomedical protocols.|True|False|[https://evs.nci.nih.gov/ftp1/CDISC/Protocol/Protocol%20Terminology.html](https://evs.nci.nih.gov/ftp1/CDISC/Protocol/Protocol%20Terminology.html)||[https://evs.nci.nih.gov/ftp1/CDISC/Protocol/](https://evs.nci.nih.gov/ftp1/CDISC/Protocol/)|[STANDARDSDATASTANDARDORTOOL:42](https://w3id.org/bridge2ai/standards-datastandardortool-schema/42)|[BiomedicalStandard](BiomedicalStandard)|CDISC Protocol|CDISC Controlled Terminology for Data Collection for Protocol||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4) [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|Disease-specific metadata, examples and guidance on implementing CDISC standards.|True|False|[https://www.cdisc.org/standards/therapeutic-areas](https://www.cdisc.org/standards/therapeutic-areas)|||[STANDARDSDATASTANDARDORTOOL:43](https://w3id.org/bridge2ai/standards-datastandardortool-schema/43)|[BiomedicalStandard](BiomedicalStandard)|CDISC TAUGs|CDISC Controlled Terminology for Therapeutic Area Standards||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|A standard for organizing and formatting data to streamline processes in collection, management, analysis and reporting.|True|False|[https://www.cdisc.org/standards/foundational/sdtm](https://www.cdisc.org/standards/foundational/sdtm)||[https://evs.nci.nih.gov/ftp1/CDISC/SDTM/](https://evs.nci.nih.gov/ftp1/CDISC/SDTM/)|[STANDARDSDATASTANDARDORTOOL:44](https://w3id.org/bridge2ai/standards-datastandardortool-schema/44)|[BiomedicalStandard](BiomedicalStandard)|SDTM|CDISC Controlled Terminology Standards for Data Aggregation through Study Data Tabulation Model (including QRS, Medical Device and Pharmacogenomics Data)||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|A standard way to collect data consistently across studies and sponsors so that data collection formats and structures provide clear traceability of submission data into the Study Data Tabulation Model (SDTM).|True|False|[https://www.cdisc.org/standards/foundational/cdash](https://www.cdisc.org/standards/foundational/cdash)||[https://evs.nci.nih.gov/ftp1/CDISC/SDTM/](https://evs.nci.nih.gov/ftp1/CDISC/SDTM/)|[STANDARDSDATASTANDARDORTOOL:45](https://w3id.org/bridge2ai/standards-datastandardortool-schema/45)|[BiomedicalStandard](BiomedicalStandard)|CDASH|CDISC Controlled Terminology Standards for Data Collection through Clinical Data Acquisition Standards Harmonization||
| markuplanguage|| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|CDISC Dataset-XML, which was released for comment under the name “StudyDataSet-XML” but was renamed to avoid confusion with the CDISC SDS team, is a new standard used to exchange study datasets in an XML format. The purpose of Dataset-XML is to support the interchange of tabular data for clinical research applications using ODM-based XML technologies. The Dataset-XML model is based on the CDISC Operational Data Model (ODM) standard and should follow the metadata structure defined in the CDISC Define-XML standard. Dataset-XML can represent any tabular dataset including SDTM, ADaM, SEND, or non-standard legacy datasets. Some noteworthy items relating to Dataset-XML v1.0 include alternative to SAS Version 5 Transport (XPT) format for datasets ODM-based model for representation of SEND, SDTM, ADaM or legacy datasets Capable of supporting CDISC regulatory data submissions Based on Define-XML v2 or v1 metadata, easy to reference Dataset-XML supports all language encodings supported by XML.|True|True|[https://www.cdisc.org/standards/data-exchange/dataset-xml](https://www.cdisc.org/standards/data-exchange/dataset-xml)|||[STANDARDSDATASTANDARDORTOOL:46](https://w3id.org/bridge2ai/standards-datastandardortool-schema/46)|[BiomedicalStandard](BiomedicalStandard)|CDISC Dataset|CDISC Dataset-XML||
| datamodel| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|LAB provides a standard model for the acquisition and exchange of laboratory data, primarily between labs and sponsors or CROs. The LAB standard was specifically designed for the interchange of lab data acquired in clinical trials.|True|True|[https://www.cdisc.org/standards/data-exchange/lab](https://www.cdisc.org/standards/data-exchange/lab)|||[STANDARDSDATASTANDARDORTOOL:47](https://w3id.org/bridge2ai/standards-datastandardortool-schema/47)|[BiomedicalStandard](BiomedicalStandard)|CDISC LAB|CDISC Laboratory Data Model||
| datamodel| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|standard for exchanging biomedical data|True|False|[https://www.cdisc.org/standards/data-exchange/odm](https://www.cdisc.org/standards/data-exchange/odm)|||[STANDARDSDATASTANDARDORTOOL:48](https://w3id.org/bridge2ai/standards-datastandardortool-schema/48)|[BiomedicalStandard](BiomedicalStandard)|CDISC ODM|CDISC Operational Data Model||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|The CDISC Protocol Representation Model Version 1.0 (PRM V1.0) is intended for those involved in the planning and design of a research protocol. The model focuses on the characteristics of a study and the definition and association of activities within the protocols, including arms and epochs. PRM V1.0 also includes the definitions of the roles that participate in those activities. The scope of this model includes protocol content including Study Design, Eligibility Criteria, and the requirements from the ClinicalTrials.gov and World Health Organization (WHO) registries. The majority of business requirements were provided by subject matter experts in clinical trial protocols. PRM V1.0 is based on the BRIDG Release 3.0 Protocol Representation sub-domain. It includes all classes in the BRIDG Protocol Representation sub-domain plus some classes from other BRIDG sub-domains, generally classes required for ClinicalTrials.gov and the WHO registries.|True|True|[https://www.cdisc.org/standards/foundational/protocol](https://www.cdisc.org/standards/foundational/protocol)|||[STANDARDSDATASTANDARDORTOOL:49](https://w3id.org/bridge2ai/standards-datastandardortool-schema/49)|[BiomedicalStandard](BiomedicalStandard)|CDISC PRM|CDISC Protocol Representation Model||
||| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|The CDISC SEND is intended to guide the organization, structure, and format of standard nonclinical tabulation datasets for interchange between organizations such as sponsors and CROs and for submission to the US Food and Drug Administration (FDA)|True|True|[https://www.cdisc.org/standards/foundational/send](https://www.cdisc.org/standards/foundational/send)|||[STANDARDSDATASTANDARDORTOOL:50](https://w3id.org/bridge2ai/standards-datastandardortool-schema/50)|[BiomedicalStandard](BiomedicalStandard)|SEND|CDISC Standard for the Exchange of Nonclinical Data||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|The CDISC Study Design Model in XML (SDM-XML) version 1.0 allows organizations to provide rigorous, machine-readable, interchangeable descriptions of the designs of their clinical studies, including treatment plans, eligibility and times and events. As an extension to the existing CDISC Operational Data Model (ODM) specification, SDM-XML affords implementers the ease of leveraging existing ODM concepts and re-using existing ODM definitions. SDM-XML defines three key sub-modules – Structure, Workflow, and Timing – permitting various levels of detail in any representation of a clinical study’s design, while allowing a high degree of authoring flexibility. The specification document is available for download as a PDF file. A ZIP file containing the XML Schemas, several examples, and an SDM-XML element and attribute reference also is available.|True|True|[https://www.cdisc.org/standards/data-exchange/sdm-xml](https://www.cdisc.org/standards/data-exchange/sdm-xml)|||[STANDARDSDATASTANDARDORTOOL:51](https://w3id.org/bridge2ai/standards-datastandardortool-schema/51)|[BiomedicalStandard](BiomedicalStandard)|CDISC SDM|CDISC Study Design Model in XML||
| fileformat|||Chado is a modular schema covering many aspects of biology, not just sequence data. Chado-XML has exactly the same scope as the Chado schema.|True|False||[doi:10.1093/bioinformatics/btm189](doi:10.1093/bioinformatics/btm189)|[https://github.com/GMOD/Chado](https://github.com/GMOD/Chado)|[STANDARDSDATASTANDARDORTOOL:52](https://w3id.org/bridge2ai/standards-datastandardortool-schema/52)|[BiomedicalStandard](BiomedicalStandard)|CHADO|CHADO XML interchange Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||The chain format describes a pairwise alignment that allow gaps in both sequences simultaneously.|True|False|[http://genome.ucsc.edu/goldenPath/help/chain.html](http://genome.ucsc.edu/goldenPath/help/chain.html)|||[STANDARDSDATASTANDARDORTOOL:53](https://w3id.org/bridge2ai/standards-datastandardortool-schema/53)|[BiomedicalStandard](BiomedicalStandard)|chain|Chain Format for pairwise alignment||
| fileformat| [STANDARDSDATATOPIC:27](STANDARDSDATATOPIC:27)||The CARD file format is the standard means in CHARMM for providing a human readable and writable coordinate file.|True|False|[https://charmm-gui.org/charmmdoc/io.html](https://charmm-gui.org/charmmdoc/io.html)|||[STANDARDSDATASTANDARDORTOOL:54](https://w3id.org/bridge2ai/standards-datastandardortool-schema/54)|[BiomedicalStandard](BiomedicalStandard)|CARD|CHARMM Card File Format||
| markuplanguage| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)||CML (Chemical Markup Language) is an XML language designed to hold most of the central concepts in chemistry. It was the first language to be developed and plays the same role for chemistry as MathML for mathematics and GML for geographical systems. CML covers most mainstream chemistry and especially molecules, reactions, solid-state, computation and spectroscopy. Since it has a special flexible approach to numeric science it also covers a very wide range of chemical properties, parameters and experimental observation. It is particularly concerned with the communication between machines and humans, and machines to machines. It has been heavily informed by the current chemical scholarly literature and chemical databases. XML is a mainstream approach providing semantics for science, such as MathML, SBML/BIOPAX (biology), GML and KML (geo) SVG (graphics) and NLM-DTD, ODT and OOXML (documents). CML provides support for most chemistry, especially molecules, compounds, reactions, spectra, crystals and computational chemistry (compchem). CML has been developed by Peter Murray-Rust and Henry Rzepa since 1995. It is the de facto XML for chemistry, accepted by publishers and with more than 1 million lines of Open Source code supporting it. CML can be validated and built into authoring tools (for example the Chemistry Add-in for Microsoft Word). A list of CML-compliant and CML-aware software can be found on the software page. The infrastructure includes legacy converters, dictionaries and conventions, Semantic Web and Linked Open Data. There are several versions of the CML schema. The most recent schema is schema 3. This essentially relaxes many of the constraints imposed in the previous stable release (schema 2.4), allowing users to put together the elements and attributes in a more flexible manner to fit the data that they want to represent more easily.|True|False|[https://www.xml-cml.org/](https://www.xml-cml.org/)|||[STANDARDSDATASTANDARDORTOOL:55](https://w3id.org/bridge2ai/standards-datastandardortool-schema/55)|[BiomedicalStandard](BiomedicalStandard)|CML|Chemical Markup Language||
| datamodel| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4) [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)||Provides a structure and format for exchanging information about the clinical effect of genetic variants, which retains the contextual and supporting information related to the interpretation of the variant.|True|False|[https://dataexchange.clinicalgenome.org/interpretation/](https://dataexchange.clinicalgenome.org/interpretation/)||[https://github.com/clingen-data-model/clingen-interpretation](https://github.com/clingen-data-model/clingen-interpretation)|[STANDARDSDATASTANDARDORTOOL:56](https://w3id.org/bridge2ai/standards-datastandardortool-schema/56)|[BiomedicalStandard](BiomedicalStandard)|ClinGen Interpretation|ClinGen Interpretation Model||
||| [STANDARDSORGANIZATION:16](STANDARDSORGANIZATION:16)|Exchange of data about and produced by in vitro diagnostic tests.|False|True|[https://clsi.org/standards/products/automation-and-informatics/documents/auto16/](https://clsi.org/standards/products/automation-and-informatics/documents/auto16/)|||[STANDARDSDATASTANDARDORTOOL:57](https://w3id.org/bridge2ai/standards-datastandardortool-schema/57)|[BiomedicalStandard](BiomedicalStandard)|CLSI AUTO16|CLSI Next-Generation In Vitro Diagnostic Interface||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26) [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)||Format for a multiple alignment of protein or DNA sequences.|True|False|[https://bioinfo.nhri.edu.tw/gcg/doc/11.0/clustalw+.html](https://bioinfo.nhri.edu.tw/gcg/doc/11.0/clustalw+.html)|||[STANDARDSDATASTANDARDORTOOL:58](https://w3id.org/bridge2ai/standards-datastandardortool-schema/58)|[BiomedicalStandard](BiomedicalStandard)|MSF|CLUSTAL-W Alignment Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26) [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)||Format for the tree (or “dendrogram”) used to guide the a multiple sequence alignment process.|True|False|[https://bioinfo.nhri.edu.tw/gcg/doc/11.0/clustalw+.html](https://bioinfo.nhri.edu.tw/gcg/doc/11.0/clustalw+.html)|||[STANDARDSDATASTANDARDORTOOL:59](https://w3id.org/bridge2ai/standards-datastandardortool-schema/59)|[BiomedicalStandard](BiomedicalStandard)|DND|CLUSTAL-W Dendrogram Guide File Format||
| guidelines| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||...we propose the CODE-EHR minimum standards framework to be used by researchers and clinicians to improve the design of studies and enhance transparency of study methods. The CODE-EHR framework aims to develop robust and effective utilisation of health-care data for research purposes.|True|False||[doi:10.1016/S2589-7500(22)00151-0](doi:10.1016/S2589-7500(22)00151-0)||[STANDARDSDATASTANDARDORTOOL:60](https://w3id.org/bridge2ai/standards-datastandardortool-schema/60)|[BiomedicalStandard](BiomedicalStandard)|CODE-EHR|CODE-EHR best-practice framework for the use of structured electronic health-care records in clinical research||
| fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||The CXI ﬁle format was created as common format for all the data in the Coherent X-ray Imaging Data Bank (CXIDB). Naturally its scope is all experimental data collected during Coherent X-ray Imaging experiments as well as all data generated during the analysis of the experimental data.|True|False|[https://www.cxidb.org/cxi.html](https://www.cxidb.org/cxi.html)|||[STANDARDSDATASTANDARDORTOOL:61](https://w3id.org/bridge2ai/standards-datastandardortool-schema/61)|[BiomedicalStandard](BiomedicalStandard)|CXI|Coherent X-ray Imaging Data Bank format||
| datamodel| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||The CCPN Data Model for macromolecular NMR is intended to cover all data needed for macromolecular NMR spectroscopy from the initial experimental data to the final validation. It serves for exchange of data between programs, for storage, data harvesting, and database deposition. The data model proper is an abstract description of the relevant data and their relationships - it is implemented in the modeling language UML. From this CCPN autogenerates interfaces (APIs) for various languages, format description and I/O routines, and documentation.|True|False|[https://sites.google.com/site/ccpnwiki/home/documentation/ccpnmr-analysis/core-concepts/the-ccpn-data-model](https://sites.google.com/site/ccpnwiki/home/documentation/ccpnmr-analysis/core-concepts/the-ccpn-data-model)|[doi:10.1002/prot.20449](doi:10.1002/prot.20449)||[STANDARDSDATASTANDARDORTOOL:62](https://w3id.org/bridge2ai/standards-datastandardortool-schema/62)|[BiomedicalStandard](BiomedicalStandard)|CCPN|Collaborative Computing Project for the NMR community data model||
| datamodel| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:68](STANDARDSORGANIZATION:68)|Biomedical metadata.|True|False|[https://docs.nih-cfde.org/en/latest/c2m2/draft-C2M2_specification/](https://docs.nih-cfde.org/en/latest/c2m2/draft-C2M2_specification/)||[https://osf.io/bq6k9/](https://osf.io/bq6k9/)|[STANDARDSDATASTANDARDORTOOL:63](https://w3id.org/bridge2ai/standards-datastandardortool-schema/63)|[BiomedicalStandard](BiomedicalStandard)|CFDE C2M2|Common Fund Data Ecosystem Crosscut Metadata Model||
| guidelines|||This dataset outlines a proposed set of core, minimal metadata elements that can be used to describe biomedical datasets, such as those resulting from research funded by the National Institutes of Health. It can inform efforts to better catalog or index such data to improve discoverability. The proposed metadata elements are based on an analysis of the metadata schemas used in a set of NIH-supported data sharing repositories. Common elements from these data repositories were identified, mapped to existing data-specific metadata standards from to existing multidisciplinary data repositories, DataCite and Dryad, and compared with metadata used in MEDLINE records to establish a sustainable and integrated metadata schema.|True|False|[https://figshare.com/articles/dataset/Common_Metadata_Elements_for_Cataloging_Biomedical_Datasets/1496573](https://figshare.com/articles/dataset/Common_Metadata_Elements_for_Cataloging_Biomedical_Datasets/1496573)||[https://figshare.com/articles/dataset/Common_Metadata_Elements_for_Cataloging_Biomedical_Datasets/1496573?file=3377663](https://figshare.com/articles/dataset/Common_Metadata_Elements_for_Cataloging_Biomedical_Datasets/1496573?file=3377663)|[STANDARDSDATASTANDARDORTOOL:64](https://w3id.org/bridge2ai/standards-datastandardortool-schema/64)|[BiomedicalStandard](BiomedicalStandard)|Common Metadata|Common Metadata Elements for Cataloging Biomedical Datasets||
| diagnosticinstrument|| [STANDARDSORGANIZATION:30](STANDARDSORGANIZATION:30)|Developed in conjunction with the University of Chicago, the COST is a patient-reported outcome measure that describes the financial distress experienced by cancer patients. Since its initial publication, an additional item from the FACIT System has been included to screen for financial toxicity and to provide a good global summary item for financial toxicity.|True|False|[https://www.facit.org/measures/FACIT-COST](https://www.facit.org/measures/FACIT-COST)|[doi:10.1002/cncr.30369](doi:10.1002/cncr.30369)||[STANDARDSDATASTANDARDORTOOL:65](https://w3id.org/bridge2ai/standards-datastandardortool-schema/65)|[BiomedicalStandard](BiomedicalStandard)|FACIT-COST|COmprehensive Score for financial Toxicity A FACIT Measure of Financial Toxicity||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|A widely-used, XML-based format for electronic health records. Superceded by FHIR document standards.|True|True|[https://www.healthit.gov/topic/standards-technology/consolidated-cda-overview](https://www.healthit.gov/topic/standards-technology/consolidated-cda-overview)||[http://www.hl7.org/implement/standards/product_brief.cfm?product_id=492](http://www.hl7.org/implement/standards/product_brief.cfm?product_id=492)|[STANDARDSDATASTANDARDORTOOL:66](https://w3id.org/bridge2ai/standards-datastandardortool-schema/66)|[BiomedicalStandard](BiomedicalStandard)|C-CDA|Consolidated Clinical Document Architecture||
| guidelines|||A reporting guideline for qualitative research interviews and focus groups comprising 32 criteria, the list of which is available from http://www.cnfs.net/modules/module2/story_content/external_files/13_COREQ_checklist_000017.pdf|True|False||[doi:10.1093/intqhc/mzm042](doi:10.1093/intqhc/mzm042)|[http://www.cnfs.net/modules/module2/story_content/external_files/13_COREQ_checklist_000017.pdf](http://www.cnfs.net/modules/module2/story_content/external_files/13_COREQ_checklist_000017.pdf)|[STANDARDSDATASTANDARDORTOOL:67](https://w3id.org/bridge2ai/standards-datastandardortool-schema/67)|[BiomedicalStandard](BiomedicalStandard)|COREQ|Consolidated criteria for reporting qualitative research||
| guidelines|||The Consolidated Health Economic Evaluation Reporting Standards (CHEERS) statement is an attempt to consolidate and update previous health economic evaluation guidelines efforts into one current, useful reporting guidance. The primary audiences for the CHEERS statement are researchers reporting economic evaluations and the editors and peer reviewers assessing them for publication.|True|True||[doi:10.1136/bmj.f1049](doi:10.1136/bmj.f1049)|[https://www.ispor.org/heor-resources/good-practices/article/consolidated-health-economic-evaluation-reporting-standards-2022-cheers-2022-statement-updated-reporting-guidance-for-health-economic-evaluations](https://www.ispor.org/heor-resources/good-practices/article/consolidated-health-economic-evaluation-reporting-standards-2022-cheers-2022-statement-updated-reporting-guidance-for-health-economic-evaluations)|[STANDARDSDATASTANDARDORTOOL:68](https://w3id.org/bridge2ai/standards-datastandardortool-schema/68)|[BiomedicalStandard](BiomedicalStandard)|CHEERS|Consolidated Health Economic Evaluation Reporting Standards||
| guidelines| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)||CONSORT, which stands for Consolidated Standards of Reporting Trials, encompasses various initiatives developed by the CONSORT Group to alleviate the problems arising from inadequate reporting of randomized controlled trials (RCTs)|True|False|[https://www.consort-statement.org/](https://www.consort-statement.org/)|[doi:10.1136/bmj.c332](doi:10.1136/bmj.c332)||[STANDARDSDATASTANDARDORTOOL:69](https://w3id.org/bridge2ai/standards-datastandardortool-schema/69)|[BiomedicalStandard](BiomedicalStandard)|CONSORT|Consolidated Standards of Reporting Trials||
| guidelines|||A suite of open industry standards and specifications that provide several means to end-to-end interoperability between personal medical devices and health information systems.|True|False|[https://www.pchalliance.org/continua-design-guidelines](https://www.pchalliance.org/continua-design-guidelines)||[https://members.pchalliance.org/document/dl/2148](https://members.pchalliance.org/document/dl/2148)|[STANDARDSDATASTANDARDORTOOL:70](https://w3id.org/bridge2ai/standards-datastandardortool-schema/70)|[BiomedicalStandard](BiomedicalStandard)|Continua|Continua Design Guidelines||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||HDF5-based critical care data exchange format which stores multiparametric data in an efficient, self-describing, hierarchical structure and supports real-time streaming and compression. In addition to cardiorespiratory and laboratory data, the format can, in future, accommodate other large datasets such as imaging and genomics.|True|False|[https://ccdef.org/](https://ccdef.org/)|[doi:10.1088/1361-6579/abfc9b](doi:10.1088/1361-6579/abfc9b)|[https://github.com/autonlab/auviewer](https://github.com/autonlab/auviewer)|[STANDARDSDATASTANDARDORTOOL:71](https://w3id.org/bridge2ai/standards-datastandardortool-schema/71)|[BiomedicalStandard](BiomedicalStandard)|CCDEF|Critical care data exchange format||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|A file format that can be used to store data in an encrypted and authenticated state. Existing applications can, with minimal modification, read and write data in the encrypted format.|True|False|[https://samtools.github.io/hts-specs/crypt4gh.pdf](https://samtools.github.io/hts-specs/crypt4gh.pdf)||[https://github.com/samtools/hts-specs](https://github.com/samtools/hts-specs)|[STANDARDSDATASTANDARDORTOOL:72](https://w3id.org/bridge2ai/standards-datastandardortool-schema/72)|[BiomedicalStandard](BiomedicalStandard)|Crypt4GH|Crypt4GH format||
| fileformat| [STANDARDSDATATOPIC:27](STANDARDSDATATOPIC:27)||The acronym CIF is used both for the Crystallographic Information File, the data exchange standard file format of Hall, Allen & Brown (1991) (see Documentation), and for the Crystallographic Information Framework, a broader system of exchange protocols based on data dictionaries and relational rules expressible in different machine-readable manifestations, including, but not restricted to, Crystallographic Information File and XML.|True|False|[https://en.wikipedia.org/wiki/Crystallographic_Information_File](https://en.wikipedia.org/wiki/Crystallographic_Information_File)|||[STANDARDSDATASTANDARDORTOOL:73](https://w3id.org/bridge2ai/standards-datastandardortool-schema/73)|[BiomedicalStandard](BiomedicalStandard)|CIF|Crystallographic Information File format||
| codesystem| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:3](STANDARDSORGANIZATION:3)|Code set used to bill outpatient & office procedures.|False|True|[https://www.ama-assn.org/amaone/cpt-current-procedural-terminology](https://www.ama-assn.org/amaone/cpt-current-procedural-terminology)||[https://www.cms.gov/Medicare/Fraud-and-Abuse/PhysicianSelfReferral](https://www.cms.gov/Medicare/Fraud-and-Abuse/PhysicianSelfReferral)|[STANDARDSDATASTANDARDORTOOL:74](https://w3id.org/bridge2ai/standards-datastandardortool-schema/74)|[BiomedicalStandard](BiomedicalStandard)|CPT|Current Procedural Terminology||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:23](STANDARDSORGANIZATION:23)|The freely available international DDI standard describes data that result from observational methods in the social, behavioral, economic, and health sciences. DDI is used to document data in over 60 countries of the world.|True|False|[https://ddialliance.org/Specification/DDI-Lifecycle/3.3/](https://ddialliance.org/Specification/DDI-Lifecycle/3.3/)|||[STANDARDSDATASTANDARDORTOOL:75](https://w3id.org/bridge2ai/standards-datastandardortool-schema/75)|[BiomedicalStandard](BiomedicalStandard)|DDI-Lifecycle|Data Documentation Initiative Lifecycle||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|A simple design pattern system that can easily be consumed, whatever your code base, for OWL ontologies.|True|False|[https://oboacademy.github.io/obook/tutorial/dosdp-template/](https://oboacademy.github.io/obook/tutorial/dosdp-template/)|[doi:10.1186/s13326-017-0126-0](doi:10.1186/s13326-017-0126-0)|[https://github.com/INCATools/dead_simple_owl_design_patterns](https://github.com/INCATools/dead_simple_owl_design_patterns)|[STANDARDSDATASTANDARDORTOOL:76](https://w3id.org/bridge2ai/standards-datastandardortool-schema/76)|[BiomedicalStandard](BiomedicalStandard)|DOS-DP|Dead simple owl design pattern exchange format||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:10](STANDARDSORGANIZATION:10)|A modeling language and notation for the precise specification of business decisions and business rules.|True|False|[https://www.omg.org/dmn/](https://www.omg.org/dmn/)|||[STANDARDSDATASTANDARDORTOOL:77](https://w3id.org/bridge2ai/standards-datastandardortool-schema/77)|[BiomedicalStandard](BiomedicalStandard)|DMN|Decision Model and Notation||
| markuplanguage| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||When taxonomic descriptions are prepared for input to computer programs, the form of the coding is usually dictated by the requirements of a particular program or set of programs. This restricts the type of data that can be represented, and the number of other programs that can use the data. Even when working with a particular program, it is frequently necessary to set up different versions of the same basic data, for example, when using restricted sets of taxa or characters to make special-purpose keys. The potential advantages of automation, especially in connexion with large groups, cannot be realized if the data have to be restructured by hand for every operation. The DELTA (DEscription Language for TAxonomy) system was developed to overcome these problems. It was designed primarily for easy use by people rather than for convenience in computer programming, and is versatile enough to replace the written description as the primary means of recording data. Consequently, it can be used as a shorthand method of recording data, even if computer processing of the data is not envisaged.|True|False|[https://www.delta-intkey.com/](https://www.delta-intkey.com/)|||[STANDARDSDATASTANDARDORTOOL:78](https://w3id.org/bridge2ai/standards-datastandardortool-schema/78)|[BiomedicalStandard](BiomedicalStandard)|DELTA|Description Language for Taxonomy||
| audiovisual fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard specifies a general model for the storage of Medical Imaging information on removable media. The purpose of this Part is to provide a framework allowing the interchange of various types of medical images and related information on a broad range of physical storage media.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part10.html](http://dicom.nema.org/medical/dicom/current/output/html/part10.html)|[STANDARDSDATASTANDARDORTOOL:79](https://w3id.org/bridge2ai/standards-datastandardortool-schema/79)|[BiomedicalStandard](BiomedicalStandard)|DICOMDIR|DICOM Part 10 Media Storage and File Format for Media Interchange||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard specifies application specific subsets of the DICOM Standard to which an implementation may claim conformance. Such a conformance statement applies to the interoperable interchange of medical images and related information on storage media for specific clinical uses.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part11.html](http://dicom.nema.org/medical/dicom/current/output/html/part11.html)|[STANDARDSDATASTANDARDORTOOL:80](https://w3id.org/bridge2ai/standards-datastandardortool-schema/80)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 11|DICOM Part 11 Media Storage Application Profiles||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard facilitates the interchange of information between digital imaging computer systems in medical environments. This interchange will enhance diagnostic imaging and potentially other clinical applications. The multi-part DICOM Standard defines the services and data that shall be supplied to achieve this interchange of information.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part12.html](http://dicom.nema.org/medical/dicom/current/output/html/part12.html)|[STANDARDSDATASTANDARDORTOOL:81](https://w3id.org/bridge2ai/standards-datastandardortool-schema/81)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 12|DICOM Part 12 Media Formats and Physical Media for Media Interchange||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|PS3.14 specifies a standardized Display Function for display of grayscale images. It provides examples of methods for measuring the Characteristic Curve of a particular Display System for the purpose of either altering the Display System to match the Grayscale Standard Display Function, or for measuring the conformance of a Display System to the Grayscale Standard Display Function. Display Systems include such things as monitors with their associated driving electronics and printers producing films that are placed on light-boxes or alternators.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part14.html](http://dicom.nema.org/medical/dicom/current/output/html/part14.html)|[STANDARDSDATASTANDARDORTOOL:82](https://w3id.org/bridge2ai/standards-datastandardortool-schema/82)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 14|DICOM Part 14 Grayscale Standard Display Function||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard specifies Security and System Management Profiles to which implementations may claim conformance. Security and System Management Profiles are defined by referencing externally developed standard protocols, such as TLS, ISCL, DHCP, and LDAP, with attention to their use in a system that uses DICOM Standard protocols for information interchange.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part15.html](http://dicom.nema.org/medical/dicom/current/output/html/part15.html)|[STANDARDSDATASTANDARDORTOOL:83](https://w3id.org/bridge2ai/standards-datastandardortool-schema/83)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 15|DICOM Part 15 Security and System Management Profiles||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard specifies the DICOM Content Mapping Resource (DCMR), which defines the Templates and Context Groups used elsewhere in the Standard.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part16.html](http://dicom.nema.org/medical/dicom/current/output/html/part16.html)|[STANDARDSDATASTANDARDORTOOL:84](https://w3id.org/bridge2ai/standards-datastandardortool-schema/84)|[BiomedicalStandard](BiomedicalStandard)|DCMR|DICOM Part 16 Content Mapping Resource||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard contains explanatory information in the form of Normative and Informative Annexes.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part17.html](http://dicom.nema.org/medical/dicom/current/output/html/part17.html)|[STANDARDSDATASTANDARDORTOOL:85](https://w3id.org/bridge2ai/standards-datastandardortool-schema/85)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 17|DICOM Part 17 Explanatory Information||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|PS3.18 specifies web services (using the HTTP family of protocols) for managing and distributing DICOM (Digital Imaging and Communications in Medicine) Information Objects, such as medical images, annotations, reports, etc. to healthcare organizations, providers, and patients. The term DICOMweb is used to designate the RESTful Web Services described here.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part18.html](http://dicom.nema.org/medical/dicom/current/output/html/part18.html)|[STANDARDSDATASTANDARDORTOOL:86](https://w3id.org/bridge2ai/standards-datastandardortool-schema/86)|[BiomedicalStandard](BiomedicalStandard)|DICOMweb|DICOM Part 18 Web Services||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard defines an interface between two software applications. One application, the Hosting System, provides the second application with data, such as a set of images and related data. The second application, the Hosted Application, analyzes that data, potentially returning the results of that analysis, for example in the form of another set of images and/or structured reports, to the first application. Such an Application Program Interface (API) differs in scope from other portions of the DICOM Standard in that it standardizes the data interchange between software components on the same system, instead of data interchange between different systems.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part19.html](http://dicom.nema.org/medical/dicom/current/output/html/part19.html)|[STANDARDSDATASTANDARDORTOOL:87](https://w3id.org/bridge2ai/standards-datastandardortool-schema/87)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 19|DICOM Part 19 Application Hosting||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|An implementation need not employ all the optional components of the DICOM Standard. After meeting the minimum general requirements, a conformant DICOM implementation may utilize whatever SOP Classes, communications protocols, Media Storage Application Profiles, optional (Type 3) Attributes, codes and controlled terminology, etc., needed to accomplish its designed task.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part02.html](http://dicom.nema.org/medical/dicom/current/output/html/part02.html)|[STANDARDSDATASTANDARDORTOOL:88](https://w3id.org/bridge2ai/standards-datastandardortool-schema/88)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 2|DICOM Part 2 Conformance||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98) [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|This Part of the DICOM Standard specifies templates for the encoding of imaging reports using the HL7 Clinical Document Architecture Release 2 (CDA R2, or simply CDA) Standard. Within this scope are clinical procedure reports for specialties that use imaging for screening, diagnostic, or therapeutic purposes.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part20.html](http://dicom.nema.org/medical/dicom/current/output/html/part20.html)|[STANDARDSDATASTANDARDORTOOL:89](https://w3id.org/bridge2ai/standards-datastandardortool-schema/89)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 20|DICOM Part 20 Imaging Reports using HL7 Clinical Document Architecture||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard specifies the transformations between DICOM and other representations of the same information.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part21.html](http://dicom.nema.org/medical/dicom/current/output/html/part21.html)|[STANDARDSDATASTANDARDORTOOL:90](https://w3id.org/bridge2ai/standards-datastandardortool-schema/90)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 21|DICOM Part 21 Transformations between DICOM and other Representations||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard specifies an SMPTE ST 2110-10 based service, relying on RTP, for the real-time transport of DICOM metadata. It provides a mechanism for the transport of DICOM metadata associated with a video or an audio flow based on the SMPTE ST 2110-20 and SMPTE ST 2110-30, respectively.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part22.html](http://dicom.nema.org/medical/dicom/current/output/html/part22.html)|[STANDARDSDATASTANDARDORTOOL:91](https://w3id.org/bridge2ai/standards-datastandardortool-schema/91)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 22|DICOM Part 22 Real-Time Communication||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard specifies the set of Information Object Definitions (IODs) that provide an abstract definition of real-world objects applicable to communication of digital medical information. For each IOD, this Part specifies any necessary information for the semantic description of the IOD, relationships to associated real-world objects relevant to the IOD, Attributes that describe the characteristics of the IOD.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part03.html](http://dicom.nema.org/medical/dicom/current/output/html/part03.html)|[STANDARDSDATASTANDARDORTOOL:92](https://w3id.org/bridge2ai/standards-datastandardortool-schema/92)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 3|DICOM Part 3 Information Object Definitions||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard specifies the set of Service Class Definitions that provide an abstract definition of real-world activities applicable to communication of digital medical information.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part04.html](http://dicom.nema.org/medical/dicom/current/output/html/part04.html)|[STANDARDSDATASTANDARDORTOOL:93](https://w3id.org/bridge2ai/standards-datastandardortool-schema/93)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 4|DICOM Part 4 Service Class Specifications||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|In this Part of the Standard the structure and encoding of the Data Set is specified. In the context of Application Entities communicating over a network, a Data Set is that portion of a DICOM Message that conveys information about real world objects being managed over the network. A Data Set may have other contexts in other applications of this Standard; e.g., in media exchange the Data Set translates to file content structure.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part05.html](http://dicom.nema.org/medical/dicom/current/output/html/part05.html)|[STANDARDSDATASTANDARDORTOOL:94](https://w3id.org/bridge2ai/standards-datastandardortool-schema/94)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 5|DICOM Part 5 Data Structures and Encoding||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard is PS 3.6 of a multi-part standard produced to facilitate the interchange of information between digital imaging computer systems in medical environments. This interchange will enhance diagnostic imaging and potentially other clinical applications. The multi-part DICOM Standard covers the protocols and data that shall be supplied to achieve this interchange of information.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part06.html](http://dicom.nema.org/medical/dicom/current/output/html/part06.html)|[STANDARDSDATASTANDARDORTOOL:95](https://w3id.org/bridge2ai/standards-datastandardortool-schema/95)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 6|DICOM Part 6 Data Dictionary||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This Part of the DICOM Standard specifies the DICOM Message Service Element (DIMSE). The DIMSE defines an Application Service Element (both the service and protocol) used by peer DICOM Application Entities for the purpose of exchanging medical images and related information.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part07.html](http://dicom.nema.org/medical/dicom/current/output/html/part07.html)|[STANDARDSDATASTANDARDORTOOL:96](https://w3id.org/bridge2ai/standards-datastandardortool-schema/96)|[BiomedicalStandard](BiomedicalStandard)|DIMSE|DICOM Part 7 Message Exchange||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|The Communication Protocols specified in this Part of PS3 closely fit the ISO Open Systems Interconnection Basic Reference Model (ISO 7498-1, see Figure 1-1). They relate to the following layers - Physical, Data Link, Network, Transport, Session, Presentation and the Association Control Services (ACSE) of the Application layer. The communication protocols specified by this Part are general purpose communication protocols (TCP/IP) and not specific to this Standard.|True|False|[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)||[http://dicom.nema.org/medical/dicom/current/output/html/part08.html](http://dicom.nema.org/medical/dicom/current/output/html/part08.html)|[STANDARDSDATASTANDARDORTOOL:97](https://w3id.org/bridge2ai/standards-datastandardortool-schema/97)|[BiomedicalStandard](BiomedicalStandard)|DICOM Part 8|DICOM Part 8 Network Communication Support for Message Exchange||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|Radiology imaging, including templates for narrative reports and machine-generated output.|True|False|[https://www.dicomstandard.org/](https://www.dicomstandard.org/)||[https://www.dicomstandard.org/current](https://www.dicomstandard.org/current)|[STANDARDSDATASTANDARDORTOOL:98](https://w3id.org/bridge2ai/standards-datastandardortool-schema/98)|[BiomedicalStandard](BiomedicalStandard)|DICOM|Digital Imaging And Communications In Medicine||
||| [STANDARDSORGANIZATION:26](STANDARDSORGANIZATION:26)|Describes how to use SMTP, S/MIME, and X.509 certificates to securely transport health information over the Internet.|True|False|||[https://wiki.directproject.org/w/images/e/e6/Applicability_Statement_for_Secure_Health_Transport_v1.2.pdf](https://wiki.directproject.org/w/images/e/e6/Applicability_Statement_for_Secure_Health_Transport_v1.2.pdf)|[STANDARDSDATASTANDARDORTOOL:99](https://w3id.org/bridge2ai/standards-datastandardortool-schema/99)|[BiomedicalStandard](BiomedicalStandard)|Direct Standard|Direct Applicability Statement for Secure Health Transport||
|| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||Allows sequence annotations to be decentralized among multiple third-party annotators and integrated on an as-needed basis by client-side software.|True|False||[doi:10.1186/1471-2105-2-7](doi:10.1186/1471-2105-2-7)|[https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-2-7/MediaObjects/12859_2001_8_MOESM1_ESM.pdf](https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-2-7/MediaObjects/12859_2001_8_MOESM1_ESM.pdf)|[STANDARDSDATASTANDARDORTOOL:100](https://w3id.org/bridge2ai/standards-datastandardortool-schema/100)|[BiomedicalStandard](BiomedicalStandard)|DAS|Distributed Sequence Annotation System||
| markuplanguage|||A metadata standard developed for the earth, environmental and ecological sciences.|True|False|[https://eml.ecoinformatics.org/](https://eml.ecoinformatics.org/)|[doi:10.5063/F11834T2](doi:10.5063/F11834T2)||[STANDARDSDATASTANDARDORTOOL:101](https://w3id.org/bridge2ai/standards-datastandardortool-schema/101)|[BiomedicalStandard](BiomedicalStandard)|EML|Ecological Metadata Language||
||| [STANDARDSORGANIZATION:93](STANDARDSORGANIZATION:93)|This standard provides a system whereby uses of plants (in their cultural context) can be described, using standardised descriptors and terms, and attached to taxonomic data sets. It resulted from discussions at the International Working Group on Taxonomic Databases for Plant Sciences (TDWG) between 1989 and 1992. Users and potential users of the standard include economic botanists and ethnobotanists whose purpose is to record all known information about the uses of a taxon; educationalists, taxonomists, biochemists, anatomists etc. who wish to record plant use, often at a broad level; economic botany collection curators who need to describe accurately the uses and values of specimens in their collections; bibliographers who need to describe plant uses referred to in publications and to apply keywords consistently for ease of data retrieval. While this standard is still in use, it is no longer actively maintained (labelled as prior on the TDWG website).|True|False|[https://www.tdwg.org/standards/economic-botany/](https://www.tdwg.org/standards/economic-botany/)|||[STANDARDSDATASTANDARDORTOOL:102](https://w3id.org/bridge2ai/standards-datastandardortool-schema/102)|[BiomedicalStandard](BiomedicalStandard)|EBDCS|Economic Botany Data Collection Standard||
| codesystem| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)| [STANDARDSORGANIZATION:61](STANDARDSORGANIZATION:61)|A system for classification of enzymes that also serves as a basis for assigning code numbers to them.|True|False|[https://iubmb.qmul.ac.uk/enzyme/rules.html](https://iubmb.qmul.ac.uk/enzyme/rules.html)|[doi:10.1126/science.150.3697.719](doi:10.1126/science.150.3697.719)||[STANDARDSDATASTANDARDORTOOL:103](https://w3id.org/bridge2ai/standards-datastandardortool-schema/103)|[BiomedicalStandard](BiomedicalStandard)|EC|Enzyme Commission Number||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||Instruments designed to assess (some of) the different aspects that define the QoL of (a specific group of) cancer patients.|True|True|[https://qol.eortc.org/questionnaires/](https://qol.eortc.org/questionnaires/)|||[STANDARDSDATASTANDARDORTOOL:104](https://w3id.org/bridge2ai/standards-datastandardortool-schema/104)|[BiomedicalStandard](BiomedicalStandard)|EORTC QLQ|EORTC Quality of Life questionnaires||
| fileformat| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)||A simple digital format supporting the technical aspects of exchange and storage of polygraphic signals has been specified. Implementation of the format is simple and independent of hard- or software environments. It allows for any local montages, transducers, prefiltering, sampling frequencies, etc. At present, 7 laboratories in various countries have used the format for exchanging sleep-wake recordings. These exchanges have made it possible to create a common database of sleep records, to compare the analysis algorithms local to the various laboratories to each other by applying these algorithms to identical signals, and to set up a computer-aided interlaboratory evaluation of manual and automatic analysis methods.|True|False|[https://www.edfplus.info/](https://www.edfplus.info/)|||[STANDARDSDATASTANDARDORTOOL:105](https://w3id.org/bridge2ai/standards-datastandardortool-schema/105)|[BiomedicalStandard](BiomedicalStandard)|EDF|European Data Format||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||A multidimensional set of minimal basic measurements suitable for all "common" dysphonias is proposed. It includes five different approaches - perception (grade, roughness, breathiness), videostroboscopy (closure, regularity, mucosal wave and symmetry), acoustics (jitter, shimmer, Fo-range and softest intensity), aerodynamics (phonation quotient), and subjective rating by the patient.|True|False||[doi:10.1007/s004050000299](doi:10.1007/s004050000299)||[STANDARDSDATASTANDARDORTOOL:106](https://w3id.org/bridge2ai/standards-datastandardortool-schema/106)|[BiomedicalStandard](BiomedicalStandard)|ELS|European Laryngological Society guidelines||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||The EQ-5D-3L descriptive system comprises the following five dimensions - mobility, self-care, usual activities, pain/discomfort and anxiety/depression. Each dimension has 3 levels - no problems, some problems, and extreme problems. The patient is asked to indicate his/her health state by ticking the box next to the most appropriate statement in each of the five dimensions. This decision results into a 1-digit number that expresses the level selected for that dimension. The digits for the five dimensions can be combined into a 5-digit number that describes the patient’s health state.|True|True|[https://euroqol.org/eq-5d-instruments/eq-5d-3l-about/](https://euroqol.org/eq-5d-instruments/eq-5d-3l-about/)|||[STANDARDSDATASTANDARDORTOOL:107](https://w3id.org/bridge2ai/standards-datastandardortool-schema/107)|[BiomedicalStandard](BiomedicalStandard)|EQ-5D-3L|EuroQol Five Dimension Three Level descriptive system||
| guidelines| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:28](STANDARDSORGANIZATION:28)|An online, open and live resource for the Life Sciences with recipes that help you to make and keep data Findable, Accessible, Interoperable and Reusable; in one word FAIR.|True|False|[https://faircookbook.elixir-europe.org/](https://faircookbook.elixir-europe.org/)|[doi:10.5281/zenodo.7156792](doi:10.5281/zenodo.7156792)||[STANDARDSDATASTANDARDORTOOL:108](https://w3id.org/bridge2ai/standards-datastandardortool-schema/108)|[BiomedicalStandard](BiomedicalStandard)|FAIR Cookbook|FAIR Cookbook||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|EHR exchange, EHRs|True|True|[https://www.hl7.org/fhir/overview.html](https://www.hl7.org/fhir/overview.html)|||[STANDARDSDATASTANDARDORTOOL:109](https://w3id.org/bridge2ai/standards-datastandardortool-schema/109)|[BiomedicalStandard](BiomedicalStandard)|FHIR|Fast Healthcare Interoperability Resources||
| fileformat| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A text-based data format for nucleotide and amino acid sequences.|True|False|[https://en.wikipedia.org/wiki/FASTA_format](https://en.wikipedia.org/wiki/FASTA_format)|||[STANDARDSDATASTANDARDORTOOL:110](https://w3id.org/bridge2ai/standards-datastandardortool-schema/110)|[BiomedicalStandard](BiomedicalStandard)|FASTA|FASTA Sequence Format||
| fileformat| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A text-based data format for nucleotide and amino acid sequences, with fields for quality scores.|True|False|[https://en.wikipedia.org/wiki/FASTQ_format](https://en.wikipedia.org/wiki/FASTQ_format)|||[STANDARDSDATASTANDARDORTOOL:111](https://w3id.org/bridge2ai/standards-datastandardortool-schema/111)|[BiomedicalStandard](BiomedicalStandard)|FASTQ|FASTQ Sequence and Sequence Quality Format||
| policy|| [STANDARDSORGANIZATION:39](STANDARDSORGANIZATION:39)|The Federal Policy for the Protection of Human Subjects or the “Common Rule” was published in 1991 and codified in separate regulations by 15 Federal departments and agencies, as listed below. The HHS regulations, 45 CFR part 46, include four subparts - subpart A, also known as the Federal Policy or the “Common Rule”; subpart B, additional protections for pregnant women, human fetuses, and neonates; subpart C, additional protections for prisoners; and subpart D, additional protections for children. Each agency includes in its chapter of the Code of Federal Regulations [CFR] section numbers and language that are identical to those of the HHS codification at 45 CFR part 46, subpart A. For all participating departments and agencies the Common Rule outlines the basic provisions for IRBs, informed consent, and Assurances of Compliance. Human subject research conducted or supported by each federal department/agency is governed by the regulations of that department/agency.|True|False|[https://www.hhs.gov/ohrp/regulations-and-policy/regulations/common-rule/index.html](https://www.hhs.gov/ohrp/regulations-and-policy/regulations/common-rule/index.html)|||[STANDARDSDATASTANDARDORTOOL:112](https://w3id.org/bridge2ai/standards-datastandardortool-schema/112)|[BiomedicalStandard](BiomedicalStandard)|Common Rule|Federal Policy for the Protection of Human Subjects||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|The Common Data Models Harmonization (CDMH) FHIR Implementation Guide (IG) will focus on mapping and translating observational data extracted for Patient Centered Outcome Research (PCOR) and other purposes into FHIR format. Data is extracted from the different networks each of which may use a different data model for their data representation. The project focuses on the Common Data Models (CDMs) from the following four networks:Patient Centered Outcome Research Network (PCORNet), Informatics for Integrating Biology and Bedside (i2b2) Accrual to Clinical Trials (ACT), also known as i2b2/ACT., Observational Medical Outcomes Partnership (OMOP), and Food and Drug Administration’s Sentinel|True|False|[https://build.fhir.org/ig/HL7/cdmh/](https://build.fhir.org/ig/HL7/cdmh/)||[https://build.fhir.org/ig/HL7/cdmh/profiles.html](https://build.fhir.org/ig/HL7/cdmh/profiles.html)|[STANDARDSDATASTANDARDORTOOL:113](https://w3id.org/bridge2ai/standards-datastandardortool-schema/113)|[BiomedicalStandard](BiomedicalStandard)|CDMH|FHIR Common Data Models Harmonization||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|A standardized suite of genomics operations in FHIR designed to support a wide range of clinical scenarios, such as variant discovery; clinical trial matching; hereditary condition and pharmacogenomic screening; and variant reanalysis.|True|False|[http://build.fhir.org/ig/HL7/genomics-reporting/operations.html](http://build.fhir.org/ig/HL7/genomics-reporting/operations.html)|[doi:10.1093/jamia/ocac246](doi:10.1093/jamia/ocac246)|[https://github.com/FHIR/genomics-operations](https://github.com/FHIR/genomics-operations)|[STANDARDSDATASTANDARDORTOOL:114](https://w3id.org/bridge2ai/standards-datastandardortool-schema/114)|[BiomedicalStandard](BiomedicalStandard)|Genomics Operations|FHIR Genomics Operations||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|The Provenance resource tracks information about the activity that created, revised, deleted, or signed a version of a resource, describing the entities and agents involved. This information can be used to form assessments about its quality, reliability, trustworthiness, or to provide pointers for where to go to further investigate the origins of the resource and the information in it.|True|False|[https://www.hl7.org/fhir/provenance.html](https://www.hl7.org/fhir/provenance.html)||[https://www.hl7.org/fhir/provenance-definitions.html](https://www.hl7.org/fhir/provenance-definitions.html)|[STANDARDSDATASTANDARDORTOOL:115](https://w3id.org/bridge2ai/standards-datastandardortool-schema/115)|[BiomedicalStandard](BiomedicalStandard)|Provenance|FHIR Provenance Resource||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|The CodeSystem resource is used to declare the existence of and describe a code system or code system supplement and its key properties, and optionally define a part or all of its content.|True|False|[http://hl7.org/fhir/codesystem.html](http://hl7.org/fhir/codesystem.html)|||[STANDARDSDATASTANDARDORTOOL:116](https://w3id.org/bridge2ai/standards-datastandardortool-schema/116)|[BiomedicalStandard](BiomedicalStandard)|CodeSystem|FHIR Resource CodeSystem||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|A statement of relationships from one set of concepts to one or more other concepts - either concepts in code systems, or data element/data element concepts, or classes in class models.|True|False|[http://hl7.org/fhir/conceptmap.html](http://hl7.org/fhir/conceptmap.html)|||[STANDARDSDATASTANDARDORTOOL:117](https://w3id.org/bridge2ai/standards-datastandardortool-schema/117)|[BiomedicalStandard](BiomedicalStandard)|ConceptMap|FHIR Resource ConceptMap||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|A curated namespace that issues unique symbols within that namespace for the identification of concepts, people, devices, etc. Represents a "System" used within the Identifier and Coding data types.|True|False|[http://hl7.org/fhir/namingsystem.html](http://hl7.org/fhir/namingsystem.html)|||[STANDARDSDATASTANDARDORTOOL:118](https://w3id.org/bridge2ai/standards-datastandardortool-schema/118)|[BiomedicalStandard](BiomedicalStandard)|NamingSystem|FHIR Resource NamingSystem||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|A TerminologyCapabilities resource documents a set of capabilities (behaviors) of a FHIR Terminology Server that may be used as a statement of actual server functionality or a statement of required or desired server implementation.|True|False|[http://hl7.org/fhir/terminologycapabilities.html](http://hl7.org/fhir/terminologycapabilities.html)|||[STANDARDSDATASTANDARDORTOOL:119](https://w3id.org/bridge2ai/standards-datastandardortool-schema/119)|[BiomedicalStandard](BiomedicalStandard)|TerminologyCapabilities|FHIR Resource TerminologyCapabilities||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|A ValueSet resource instance specifies a set of codes drawn from one or more code systems, intended for use in a particular context. Value sets link between CodeSystem definitions and their use in coded elements.|True|False|[http://hl7.org/fhir/valueset.html](http://hl7.org/fhir/valueset.html)|||[STANDARDSDATASTANDARDORTOOL:120](https://w3id.org/bridge2ai/standards-datastandardortool-schema/120)|[BiomedicalStandard](BiomedicalStandard)|ValueSet|FHIR Resource ValueSet||
| fileformat| [STANDARDSDATATOPIC:2](STANDARDSDATATOPIC:2)||The flow cytometry data file standard provides the specifications needed to completely describe flow cytometry data sets within the confines of the file containing the experimental data. In 1984, the first Flow Cytometry Standard format for data files was adopted as FCS 1.0. This standard was modified in 1990 as FCS 2.0 and again in 1997 as FCS 3.0. We report here on the next generation Flow Cytometry Standard data file format. FCS 3.1 is a minor revision based on suggested improvements from the community. The unchanged goal of the Standard is to provide a uniform file format that allows files created by one type of acquisition hardware and software to be analyzed by any other type.|True|False|[https://en.wikipedia.org/wiki/Flow_Cytometry_Standard](https://en.wikipedia.org/wiki/Flow_Cytometry_Standard)|[doi:10.1002/cyto.a.20825](doi:10.1002/cyto.a.20825)||[STANDARDSDATASTANDARDORTOOL:121](https://w3id.org/bridge2ai/standards-datastandardortool-schema/121)|[BiomedicalStandard](BiomedicalStandard)|FCS|Flow Cytometry Standard format||
| guidelines| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [FORCE11](FORCE11)|The Data Citation Principles cover the purpose, function and attributes of citations. These principles recognize the dual necessity of creating citation practices that are both human understandable and machine-actionable.|True|False|[https://force11.org/info/joint-declaration-of-data-citation-principles-final/](https://force11.org/info/joint-declaration-of-data-citation-principles-final/)|||[STANDARDSDATASTANDARDORTOOL:122](https://w3id.org/bridge2ai/standards-datastandardortool-schema/122)|[BiomedicalStandard](BiomedicalStandard)|FORCE11 DC|FORCE11 Data Citation Principles||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [FACIT](FACIT)|The Functional Assessment of Cancer Therapy - General (FACT-G) is a 27-item questionnaire designed to measure four domains of HRQOL in cancer patients - Physical, social, emotional, and functional well-being. Original development and validation involved 854 patients with cancer and 15 oncology specialists. An initial pool of 370 overlapping items for breast, lung, and colorectal cancer was generated by open-ended interviews with patients experienced with the symptoms of cancer and oncology professionals. Using preselected criteria, items were reduced to a 38-item general version. Factor and scaling analyses of these 38 items on 545 patients with mixed cancer diagnoses resulted in the 27-item FACT-General (FACT-G). Coefficients of reliability and validity were uniformly high. The scale's ability to discriminate patients on the basis of stage of disease, performance status rating (PSR), and hospitalization status supports its sensitivity. It has also demonstrated sensitivity to change over time.|True|False|[https://www.facit.org/measures/FACT-G](https://www.facit.org/measures/FACT-G)|||[STANDARDSDATASTANDARDORTOOL:123](https://w3id.org/bridge2ai/standards-datastandardortool-schema/123)|[BiomedicalStandard](BiomedicalStandard)|FACT-G|Functional Assessment of Cancer Therapy - General||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [FACIT](FACIT)|Functional Assessment of Chronic Illness Therapy - Dyspnea-10 item|True|False|[https://www.facit.org/measures/facit-dyspnea](https://www.facit.org/measures/facit-dyspnea)|[doi:10.1016/j.jval.2010.06.001](doi:10.1016/j.jval.2010.06.001)||[STANDARDSDATASTANDARDORTOOL:124](https://w3id.org/bridge2ai/standards-datastandardortool-schema/124)|[BiomedicalStandard](BiomedicalStandard)|FACIT-Dyspnea|Functional Assessment of Chronic Illness Therapy - Dyspnea||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [FACIT](FACIT)|The Functional Assessment of Non-Life Threatening Conditions (FANLTC) is a 26-item version of the FACT-G designed to be administered to patients with non-life threatening conditions. The item from the FACT-G making reference to anxiety about death has been removed, and the instrument measures four domains of HRQOL - Physical, social/family, emotional and functional well-being.|True|False|[https://www.facit.org/measures/FANLTC](https://www.facit.org/measures/FANLTC)|||[STANDARDSDATASTANDARDORTOOL:125](https://w3id.org/bridge2ai/standards-datastandardortool-schema/125)|[BiomedicalStandard](BiomedicalStandard)|FANLTC|Functional Assessment of Non-Life Threatening Conditions||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)||WGS data processing standards that allow different groups to produce functionally equivalent (FE) results, yet still innovate on data processing pipelines.|True|False||[doi:10.1038/s41467-018-06159-4](doi:10.1038/s41467-018-06159-4)|[https://github.com/CCDG/Pipeline-Standardization](https://github.com/CCDG/Pipeline-Standardization)|[STANDARDSDATASTANDARDORTOOL:126](https://w3id.org/bridge2ai/standards-datastandardortool-schema/126)|[BiomedicalStandard](BiomedicalStandard)|Regier2018|Functional equivalence of genome sequencing analysis pipelines enables harmonized variant calling across human genetics projects||
| markuplanguage| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||Functional genomics experiments present many challenges in data archiving, sharing and querying. As the size and complexity of data generated from such experiments grows, so does the requirement for standard data formats. To address these needs, the Functional Genomics Experiment [Object Model / Markup-Language] (FuGE-OM, FuGE-ML) has been created to facilitate the development of data standards.FuGE is a model of the shared components in different functional genomics domains. FuGE facilitates the development of data standards in functional genomics in two ways. 1. FuGE provides a model of common components in functional genomics investigations, such as materials, data, protocols, equipment and software. These models can be extended to develop modular data formats with consistent structure. 2. FuGE provides a framework for capturing complete laboratory workflows, enabling the integration of pre-existing data formats. In this context, FuGE allows the capture of additional metadata that gives formats a context within the complete workflow. FuGE is available as a UML model and an XML Schema|True|False|[https://fuge.sourceforge.net/index.php](https://fuge.sourceforge.net/index.php)|||[STANDARDSDATASTANDARDORTOOL:127](https://w3id.org/bridge2ai/standards-datastandardortool-schema/127)|[BiomedicalStandard](BiomedicalStandard)|FuGE-ML|Functional Genomics Experiment Markup Language||
| datamodel| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||FuGEFlow represents a collaborative effort to develop of flow cytometry experimental workflow description based on the FuGE model. The Functional Genomics Experiment data model (FuGE) describes common aspects of comprehensive, high-throughput experiments. FuGE is an extendable model that provides a basis for creation of new technology-specific data formats, such as FuGEFlow for flow cytometry.|True|False||[doi:10.1186/1471-2105-10-184](doi:10.1186/1471-2105-10-184)||[STANDARDSDATASTANDARDORTOOL:128](https://w3id.org/bridge2ai/standards-datastandardortool-schema/128)|[BiomedicalStandard](BiomedicalStandard)|FuGEFlow|Functional Genomics Experiment model for flow cytometry||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||A method to measure performance status with a high percentage of agreement between observers.|True|False||[doi:10.1186/s12885-015-1526-0](doi:10.1186/s12885-015-1526-0)||[STANDARDSDATASTANDARDORTOOL:129](https://w3id.org/bridge2ai/standards-datastandardortool-schema/129)|[BiomedicalStandard](BiomedicalStandard)|FAF|Functionality Assessment Flowchart||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|The metadata model for GA4GH, an international coalition of both public and private interested parties, formed to enable the sharing of genomic and clinical data.|True|False|||[https://github.com/ga4gh-metadata/metadata-schemas](https://github.com/ga4gh-metadata/metadata-schemas)|[STANDARDSDATASTANDARDORTOOL:130](https://w3id.org/bridge2ai/standards-datastandardortool-schema/130)|[BiomedicalStandard](BiomedicalStandard)|GA4GH|GA4GH metadata model||
| markuplanguage| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||The Gating-ML specification represents a proposal on how to form unambiguous XML-based gate definitions that may be used independently as well as included as one of the components of ACS. Such a description of gates can facilitate the interchange and validation of data between different software packages with the potential of significant increase of hardware and software interoperability. The specification supports rectangular gates in n dimensions (i.e., from one-dimensional range gates up to n-dimensional hyper-rectangular regions), polygon gates in two (and more) dimensions, ellipsoid gates in n dimensions, decision tree structures, and Boolean collections of any of the types of gates. Gates can be uniquely identified and may be ordered into a hierarchical structure to describe a gating strategy. Gates may be applied on parameters as in list mode data files (e.g., FCS files) or on transformed parameters as described by any explicit parameter transformation. Therefore, since version 1.5, parameter transformation and compensation description are included as part of the Gating-ML specification.|True|False|[http://flowcyt.sourceforge.net/gating/](http://flowcyt.sourceforge.net/gating/)|||[STANDARDSDATASTANDARDORTOOL:131](https://w3id.org/bridge2ai/standards-datastandardortool-schema/131)|[BiomedicalStandard](BiomedicalStandard)|Gating-ML|Gating-ML specification||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26) [STANDARDSDATATOPIC:33](STANDARDSDATATOPIC:33)||A text-based data format for nucleotide and amino acid sequences, with fields for a variety of sequence metadata.|True|False|[https://en.wikipedia.org/wiki/GenBank](https://en.wikipedia.org/wiki/GenBank)|||[STANDARDSDATASTANDARDORTOOL:132](https://w3id.org/bridge2ai/standards-datastandardortool-schema/132)|[BiomedicalStandard](BiomedicalStandard)|GB|GenBank Sequence Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12)||genePred is a table format commonly used for gene prediction.|True|False|[https://genome.ucsc.edu/FAQ/FAQformat.html#format9](https://genome.ucsc.edu/FAQ/FAQformat.html#format9)|||[STANDARDSDATASTANDARDORTOOL:133](https://w3id.org/bridge2ai/standards-datastandardortool-schema/133)|[BiomedicalStandard](BiomedicalStandard)|GenePred|Gene Prediction File Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26) [STANDARDSDATATOPIC:33](STANDARDSDATATOPIC:33)||The Gene Ontology project provides annotations describing attributes of biological entities such as genes and gene products. The Gene Ontology has historically provided annotations via Gene Association Format (GAF), including GAF-1 and GAF-2. Ontologies are distributed separately, using an OWL serialization or OBO format. The use of GAF has some drawbacks. Combined representation of gene/gene product data and annotations leads to redundancy/repetition No way to represent gene/gene product metadata for unannotated genes Requirement to maintain backward compatibility makes it harder to introduce enhancements such as use of an ontology for evidence types GAF formats will continue to be supported, but the need for a way to represent genes/gene products separately from annotations, as well as the need to use the evidence ontology has lead to the creation of the GPAD (Gene Product Annotation Data) and GPI (Gene Product Information) formats, defined here. Whilst GPAD and GPI have been defined for use within the Gene Ontology Consortium for GO annotation, this specification is designed to be reusable for analagous ontology-based annotation - for example, gene phenotype annotation.|True|False|[http://geneontology.org/docs/gene-product-association-data-gpad-format/](http://geneontology.org/docs/gene-product-association-data-gpad-format/)|||[STANDARDSDATASTANDARDORTOOL:134](https://w3id.org/bridge2ai/standards-datastandardortool-schema/134)|[BiomedicalStandard](BiomedicalStandard)|GPAD|Gene Product Annotation Data format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12)||GTF (Gene Transfer Format, GTF2.2) is an extension to, and backward compatible with, GFF2. The first eight GTF fields are the same as GFF. The feature field is the same as GFF, with the exception that it also includes the following optional values, 5UTR, 3UTR, inter, inter_CNS, and intron_CNS.|True|False|[http://genome.ucsc.edu/FAQ/FAQformat.html#format4](http://genome.ucsc.edu/FAQ/FAQformat.html#format4)|||[STANDARDSDATASTANDARDORTOOL:135](https://w3id.org/bridge2ai/standards-datastandardortool-schema/135)|[BiomedicalStandard](BiomedicalStandard)|GTF|Gene Transfer Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12)||The GMX and GMT file formats are tab-delimited file formats that describe gene sets.|True|False|[https://www.genepattern.org/file-formats-guide#GMT](https://www.genepattern.org/file-formats-guide#GMT)|||[STANDARDSDATASTANDARDORTOOL:136](https://w3id.org/bridge2ai/standards-datastandardortool-schema/136)|[BiomedicalStandard](BiomedicalStandard)|GMT|GenePattern GeneSet Table Format||
| fileformat| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||Genome feature annotation file format.|True|False|||[https://github.com/The-Sequence-Ontology/Specifications](https://github.com/The-Sequence-Ontology/Specifications)|[STANDARDSDATASTANDARDORTOOL:137](https://w3id.org/bridge2ai/standards-datastandardortool-schema/137)|[BiomedicalStandard](BiomedicalStandard)|GFF|General Feature Format||
| fileformat| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||The Gene Ontology Consortium stores annotation data, the representation of gene product attributes using GO terms, in standardized tab-delimited text files. Each line in the file represents a single association between a gene product and a GO term, with an evidence code and the reference to support the link.|True|False|[http://geneontology.org/docs/go-annotation-file-gaf-format-2.1/](http://geneontology.org/docs/go-annotation-file-gaf-format-2.1/)|||[STANDARDSDATASTANDARDORTOOL:138](https://w3id.org/bridge2ai/standards-datastandardortool-schema/138)|[BiomedicalStandard](BiomedicalStandard)|GAF|Genome Annotation File||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|Beacon v2 is a protocol/specification established by the Global Alliance for Genomics and Health initiative (GA4GH) that defines an open standard for federated discovery of genomic (and phenoclinic) data in biomedical research and clinical applications.|True|False|[http://docs.genomebeacons.org/](http://docs.genomebeacons.org/)|[doi:10.1002/humu.24369](doi:10.1002/humu.24369)|[https://github.com/ga4gh-beacon/beacon-v2](https://github.com/ga4gh-beacon/beacon-v2)|[STANDARDSDATASTANDARDORTOOL:139](https://w3id.org/bridge2ai/standards-datastandardortool-schema/139)|[BiomedicalStandard](BiomedicalStandard)|Beacon|Genome Beacons||
| fileformat| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)||The Genome Variation Format (GVF) is a very simple file format for describing sequence alteration features at nucleotide resolution relative to a reference genome.|True|False|||[https://github.com/The-Sequence-Ontology/Specifications/blob/master/gvf.md](https://github.com/The-Sequence-Ontology/Specifications/blob/master/gvf.md)|[STANDARDSDATASTANDARDORTOOL:140](https://w3id.org/bridge2ai/standards-datastandardortool-schema/140)|[BiomedicalStandard](BiomedicalStandard)|GVF|Genome Variation Format||
| markuplanguage| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||The Genomic Contextual Data Markup Language (GCDML) is a core project of the Genomic Standards Consortium (GSC) that is a reference implementation the Minimum Information about a Genome Sequence (MIGS/MIMS/MIMARKS), and the extensions the Minimum Information about a Metagenome Sequence (MIMS) and Minimum Information about a MARKer gene Sequence (MIMARKS).|True|False||[doi:10.1089/omi.2008.0A10](doi:10.1089/omi.2008.0A10)||[STANDARDSDATASTANDARDORTOOL:141](https://w3id.org/bridge2ai/standards-datastandardortool-schema/141)|[BiomedicalStandard](BiomedicalStandard)|GCDML|Genomic Contextual Data Markup Language||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)| [STANDARDSORGANIZATION:93](STANDARDSORGANIZATION:93)|In order to facilitate exchange of information on genomic samples and their derived data, the Global Genome Biodiversity Network (GGBN) Data Standard is intended to provide a platform based on a documented agreement to promote the efficient sharing and usage of genomic sample material and associated specimen information in a consistent way.|True|False|[https://www.tdwg.org/standards/ggbn/](https://www.tdwg.org/standards/ggbn/)|[doi:10.1093/database/baw125](doi:10.1093/database/baw125)||[STANDARDSDATASTANDARDORTOOL:142](https://w3id.org/bridge2ai/standards-datastandardortool-schema/142)|[BiomedicalStandard](BiomedicalStandard)|GGBN|Global Genome Biodiversity Network Data Standard||
|| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20)||GlycoCT format is devised to describe the carbohydrate sequences, with a controlled vocabulary to name monosaccharides, adopting IUPAC rules to generate a consistent, machine-readable nomenclature, based on a connection table approach, instead of a linear encoding scheme. The format uses a block concept to describe frequently occurring special features of carbohydrate sequences like repeating units. It exists in two variants, a condensed form and a more verbose XML syntax. Sorting rules assure the uniqueness of the condensed form, thus making it suitable as a direct primary key for database applications, which rely on unique identifiers. GlycoCT encompasses the capabilities of the heterogeneous landscape of digital encoding schemata in glycomics and is thus a step forward on the way to a unified and broadly accepted sequence format in glycobioinformatics.|True|False||[doi:10.1016/j.carres.2008.03.011](doi:10.1016/j.carres.2008.03.011)|[https://github.com/glycoinfo/GlycoCT](https://github.com/glycoinfo/GlycoCT)|[STANDARDSDATASTANDARDORTOOL:143](https://w3id.org/bridge2ai/standards-datastandardortool-schema/143)|[BiomedicalStandard](BiomedicalStandard)|GlycoCT|GlycoCT encoding scheme||
| fileformat| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||GTrack is a tabular format that was developed as part of the Genomic HyperBrowser system to provide a uniform representation of most types of genomic datasets. GTrack is able to replace common formats such as WIG, GFF, BED, FASTA, in addition to represent chromatin capture datasets, such as Hi-C and ChIA-PET.|True|False||[doi:10.1186/1471-2105-12-494](doi:10.1186/1471-2105-12-494)|[https://github.com/gtrack/gtrack](https://github.com/gtrack/gtrack)|[STANDARDSDATASTANDARDORTOOL:144](https://w3id.org/bridge2ai/standards-datastandardortool-schema/144)|[BiomedicalStandard](BiomedicalStandard)|GTrack|GTrack genomic data format||
| guidelines| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20)| [STANDARDSORGANIZATION:93](STANDARDSORGANIZATION:93)|GUIDs are Globally Unique Identifiers which should be referentially consistent and resolvable in order to support tests of uniqueness and the acquisition of associated metadata. Further, permanent and robust resolution services need to be available. The TDWG Globally Unique Identifiers Task Group (TDWG GUID), after meeting twice in 2006, recommended the use of the Life Sciences Identifiers (LSID) to uniquely identify shared data objects in the biodiversity domain.|True|False|[http://www.tdwg.org/standards/150](http://www.tdwg.org/standards/150)||[https://github.com/tdwg/guid-as](https://github.com/tdwg/guid-as)|[STANDARDSDATASTANDARDORTOOL:145](https://w3id.org/bridge2ai/standards-datastandardortool-schema/145)|[BiomedicalStandard](BiomedicalStandard)|GUID-AS|GUID and Life Sciences Identifiers Applicability Statements||
| minimuminformationschema| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)||A minimum information checklist creating a consistent framework to transparently report the purpose, methods and results of the therapeutic experiments|True|False||[doi:10.1186/1756-0500-5-10](doi:10.1186/1756-0500-5-10)||[STANDARDSDATASTANDARDORTOOL:146](https://w3id.org/bridge2ai/standards-datastandardortool-schema/146)|[BiomedicalStandard](BiomedicalStandard)|GIATE|Guidelines for Information About Therapy Experiments||
| policy| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:39](STANDARDSORGANIZATION:39)|The Health Insurance Portability and Accountability Act of 1996 (HIPAA) is a federal law that required the creation of national standards to protect sensitive patient health information from being disclosed without the patient’s consent or knowledge. The US Department of Health and Human Services (HHS) issued the HIPAA Privacy Rule to implement the requirements of HIPAA. The HIPAA Security Rule protects a subset of information covered by the Privacy Rule.|True|False|[https://www.hhs.gov/hipaa/index.html](https://www.hhs.gov/hipaa/index.html)||[https://aspe.hhs.gov/reports/health-insurance-portability-accountability-act-1996](https://aspe.hhs.gov/reports/health-insurance-portability-accountability-act-1996)|[STANDARDSDATASTANDARDORTOOL:147](https://w3id.org/bridge2ai/standards-datastandardortool-schema/147)|[BiomedicalStandard](BiomedicalStandard)|HIPAA|Health Insurance Portability and Accountability Act of 1996||
| codesystem| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:17](STANDARDSORGANIZATION:17)|Code set for items and supplies and non-physician services not covered by the American Medical Association's Current Procedural Terminology-4 (CPT-4) codes; Medicare, Medicaid, and private health insurers use HCPCS procedure and modifier codes for claims processing.|True|False|[https://www.cms.gov/Medicare/Coding/HCPCSReleaseCodeSets](https://www.cms.gov/Medicare/Coding/HCPCSReleaseCodeSets)|||[STANDARDSDATASTANDARDORTOOL:148](https://w3id.org/bridge2ai/standards-datastandardortool-schema/148)|[BiomedicalStandard](BiomedicalStandard)|HCPCS|Healthcare Common Procedure Coding System||
||| [STANDARDSORGANIZATION:93](STANDARDSORGANIZATION:93)|The 'Herbarium Information Standards and Protocols for Interchange of Data' (HISPID) is a standard format for the interchange of electronic herbarium specimen information. HISPID has been developed by a committee of representatives from all major Australian herbaria. This interchange standard was first published in 1989, with a revised version published in 1993./nHISPID3 (version 3) is an accession-based interchange standard. Although many fields refer to attributes of the taxon they should be construed as applying to the specimen represented by the record, not to the taxon per se. The interchange of taxonomic, nomenclatural, bibliographic, typification, rare and endangered plant conservation, and other related information is not dealt with in this standard, unless it specifically refers to a particular accession (record). While this standard is still in use, it is no longer actively maintained (labelled as prior on the TDWG website).|True|False|[https://www.tdwg.org/standards/hispid3/](https://www.tdwg.org/standards/hispid3/)|||[STANDARDSDATASTANDARDORTOOL:149](https://w3id.org/bridge2ai/standards-datastandardortool-schema/149)|[BiomedicalStandard](BiomedicalStandard)|HISPID3|Herbarium Information Standards and Protocols for Interchange of Data||
| markuplanguage|||Histoimmunogenetics Markup Language (HML) is intended as a potentially general-purpose XML format for exchanging genetic typing data. This format supports NGS based genotyping methods, raw sequence reads, registered methodologies, reference data, complete reporting of allele and genotype ambiguity and MIRING compliant reporting.|True|False|[https://bioinformatics.bethematchclinical.org/hla-resources/hml/](https://bioinformatics.bethematchclinical.org/hla-resources/hml/)||[https://github.com/nmdp-bioinformatics/hml](https://github.com/nmdp-bioinformatics/hml)|[STANDARDSDATASTANDARDORTOOL:150](https://w3id.org/bridge2ai/standards-datastandardortool-schema/150)|[BiomedicalStandard](BiomedicalStandard)|HML|Histoimmunogenetics Markup Language||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|The Arden Syntax for Medical Logic Systems Version 2.10 is the latest version of a formalism for clinical knowledge representation that can be used by clinicians, knowledge engineers, administrators and others to implement clinical decision support (CDS) solutions to help improve the quality and safety of care. Arden Syntax can be used to create a knowledge base for CDS systems that, when coupled with patient data, can generate patient-specific CDS interventions for improving patient care. The key change in Version 2.10 over Version 2.9 is inclusion of a normative XML representation for Arden Syntax. This was done because the use of XML facilitates the development of tools such as syntax checkers and editors that can help increase the correctness of executable knowledge modules, and this in turn will foster the augmentation of the development and production environments for Arden, thereby increasing its utility.|True|True|[http://www.hl7.org/implement/standards/product_brief.cfm?product_id=372](http://www.hl7.org/implement/standards/product_brief.cfm?product_id=372)|[doi:10.1016/j.jbi.2012.02.001](doi:10.1016/j.jbi.2012.02.001)|[https://www.hl7.org/login/index.cfm?next=/implement/standards/product_brief.cfm?product_id=2](https://www.hl7.org/login/index.cfm?next=/implement/standards/product_brief.cfm?product_id=2)|[STANDARDSDATASTANDARDORTOOL:151](https://w3id.org/bridge2ai/standards-datastandardortool-schema/151)|[BiomedicalStandard](BiomedicalStandard)|Arden|HL7 Arden Syntax||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|Guidance and templates for basic provenance information about clinical (and other care related information), who created it, when was it created, where was it created, how it was created, and why it was created.|True|True|[http://www.hl7.org/implement/standards/product_brief.cfm?product_id=420](http://www.hl7.org/implement/standards/product_brief.cfm?product_id=420)|||[STANDARDSDATASTANDARDORTOOL:152](https://w3id.org/bridge2ai/standards-datastandardortool-schema/152)|[BiomedicalStandard](BiomedicalStandard)|HL7 CDA Data Provenance|HL7 Clinical Document Architecture Implementation Guide - Data Provenance||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|Resource for findings and interpretation of diagnostic tests performed on patients, groups of patients, devices, and locations, and/or specimens derived from these. The report includes clinical context such as requesting and provider information, and some mix of atomic results, images, textual and coded interpretations, and formatted representation of diagnostic reports.|True|False|[http://hl7.org/fhir/diagnosticreport.html](http://hl7.org/fhir/diagnosticreport.html)||[http://hl7.org/fhir/diagnosticreport-definitions.html](http://hl7.org/fhir/diagnosticreport-definitions.html)|[STANDARDSDATASTANDARDORTOOL:153](https://w3id.org/bridge2ai/standards-datastandardortool-schema/153)|[BiomedicalStandard](BiomedicalStandard)|DiagnosticReport|HL7 FHIR Resource DiagnosticReport||
|| [STANDARDSDATATOPIC:9, Genome](STANDARDSDATATOPIC:9, Genome)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|GenomicStudy resource aims at delineating relevant information of a genomic study. A genomic study might comprise one or more analyses, each serving a specific purpose. These analyses may vary in method (e.g., karyotyping, CNV, or SNV detection), performer, software, devices used, or regions targeted.|True|False|[https://build.fhir.org/genomicstudy.html](https://build.fhir.org/genomicstudy.html)||[https://build.fhir.org/genomicstudy-definitions.html](https://build.fhir.org/genomicstudy-definitions.html)|[STANDARDSDATASTANDARDORTOOL:154](https://w3id.org/bridge2ai/standards-datastandardortool-schema/154)|[BiomedicalStandard](BiomedicalStandard)|GenomicStudy|HL7 FHIR Resource GenomicStudy||
|| [STANDARDSDATATOPIC:4, Molecular Biology](STANDARDSDATATOPIC:4, Molecular Biology)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|Resource for raw data describing a biological sequence.|True|False|[http://hl7.org/implement/standards/fhir/molecularsequence.html](http://hl7.org/implement/standards/fhir/molecularsequence.html)||[http://hl7.org/implement/standards/fhir/molecularsequence-definitions.html](http://hl7.org/implement/standards/fhir/molecularsequence-definitions.html)|[STANDARDSDATASTANDARDORTOOL:155](https://w3id.org/bridge2ai/standards-datastandardortool-schema/155)|[BiomedicalStandard](BiomedicalStandard)|MolecularSequence|HL7 FHIR Resource MolecularSequence||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|Resource for measurements and simple assertions made about a patient, device or other subject.|True|False|[http://hl7.org/implement/standards/fhir/observation.html](http://hl7.org/implement/standards/fhir/observation.html)||[http://hl7.org/implement/standards/fhir/observation-definitions.html](http://hl7.org/implement/standards/fhir/observation-definitions.html)|[STANDARDSDATASTANDARDORTOOL:156](https://w3id.org/bridge2ai/standards-datastandardortool-schema/156)|[BiomedicalStandard](BiomedicalStandard)|Observation|HL7 FHIR Resource Observation||
|| [Demographics](Demographics) [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|Resource for demographics and other administrative information about an individual or animal receiving care or other health-related services.|True|False|[http://hl7.org/implement/standards/fhir/patient.html](http://hl7.org/implement/standards/fhir/patient.html)||[http://hl7.org/implement/standards/fhir/patient-definitions.html](http://hl7.org/implement/standards/fhir/patient-definitions.html)|[STANDARDSDATASTANDARDORTOOL:157](https://w3id.org/bridge2ai/standards-datastandardortool-schema/157)|[BiomedicalStandard](BiomedicalStandard)|Patient|HL7 FHIR Resource Patient||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|Resource for any material sample taken from a biological entity, living or dead, or taken from a physical object or the environment.|True|False|[http://hl7.org/fhir/specimen.html](http://hl7.org/fhir/specimen.html)||[http://hl7.org/fhir/specimen-definitions.html](http://hl7.org/fhir/specimen-definitions.html)|[STANDARDSDATASTANDARDORTOOL:158](https://w3id.org/bridge2ai/standards-datastandardortool-schema/158)|[BiomedicalStandard](BiomedicalStandard)|Specimen|HL7 FHIR Resource Specimen||
|| [Demographics](Demographics)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|Currently, it is common that a single data element is used to capture both sex and gender information, often assuming these two items are one unified idea. This specification challenges that notion and proposes that independent consideration of sex and gender, and the assessment of their differences promotes the health of women, men, and people of diverse gender identities of all ages, avoiding systematic errors that generate results with a low validity (if any) in clinical studies. The Gender Harmony model describes an approach that can improve data accuracy for sex and gender information in health care systems.|True|True|[http://www.hl7.org/implement/standards/product_brief.cfm?product_id=564](http://www.hl7.org/implement/standards/product_brief.cfm?product_id=564)|[doi:10.1093/jamia/ocab196](doi:10.1093/jamia/ocab196)||[STANDARDSDATASTANDARDORTOOL:159](https://w3id.org/bridge2ai/standards-datastandardortool-schema/159)|[BiomedicalStandard](BiomedicalStandard)|GHP|HL7 Gender Harmony Project||
| fileformat| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|The HUPO PSI Mass Spectrometry Standards Working Group (MSS WG) has developed a specification for a standardized format for the exchange and transmission of transition lists for selected reaction monitoring (SRM) experiments.|True|False|[https://www.psidev.info/traml](https://www.psidev.info/traml)|||[STANDARDSDATASTANDARDORTOOL:160](https://w3id.org/bridge2ai/standards-datastandardortool-schema/160)|[BiomedicalStandard](BiomedicalStandard)|TraML|HUPO-PSI TraML format||
|| [STANDARDSDATATOPIC:18](STANDARDSDATATOPIC:18)| [IEEE](IEEE)|An overview, terminology, and categorization for Wearable Consumer Electronic Devices (Wearables). It further outlines an architecture for a series of standard specifications that define technical requirements and testing methods for different aspects of Wearables, from basic security and suitableness of wearing to various functional areas like health, fitness, and infotainment, etc.|False|True|[https://standards.ieee.org/ieee/360/6244/](https://standards.ieee.org/ieee/360/6244/)|||[STANDARDSDATASTANDARDORTOOL:161](https://w3id.org/bridge2ai/standards-datastandardortool-schema/161)|[BiomedicalStandard](BiomedicalStandard)|IEEE P360|IEEE 360-2022 IEEE Standard for Wearable Consumer Electronic Devices||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [IHE](IHE)|A mechanism to record the patient privacy consent(s) and a method for Content Consumers to use to enforce the privacy consent appropriate to the use.|True|False|||[https://profiles.ihe.net/ITI/TF/Volume1/ch-19.html](https://profiles.ihe.net/ITI/TF/Volume1/ch-19.html)|[STANDARDSDATASTANDARDORTOOL:162](https://w3id.org/bridge2ai/standards-datastandardortool-schema/162)|[BiomedicalStandard](BiomedicalStandard)|BPPC|IHE Basic Patient Privacy Consents||
||| [IHE](IHE)|Profile for Clinical Decision Support and Appropriate Use Criteria (AUC) information as received from the CDS Mechanism 145 (CDSM) on the order and charge transaction to the revenue cycle application that is responsible to create a claim.|True|False|[https://www.ihe.net/uploadedFiles/Documents/Radiology/IHE_Rad_Suppl_CDS-OAT.pdf](https://www.ihe.net/uploadedFiles/Documents/Radiology/IHE_Rad_Suppl_CDS-OAT.pdf)|||[STANDARDSDATASTANDARDORTOOL:163](https://w3id.org/bridge2ai/standards-datastandardortool-schema/163)|[BiomedicalStandard](BiomedicalStandard)|IHE CDS-OAT|IHE Clinical Decision Support Order Appropriateness Tracking||
||| [IHE](IHE)|The Clinical Research Document Profile (CRD) specifies a standard way to generate a clinical research document from EHR data provided in the CDA standard.|True|False|||[https://www.ihe.net/uploadedFiles/Documents/QRPH/IHE_QRPH_Suppl_CRD.pdf](https://www.ihe.net/uploadedFiles/Documents/QRPH/IHE_QRPH_Suppl_CRD.pdf)|[STANDARDSDATASTANDARDORTOOL:164](https://w3id.org/bridge2ai/standards-datastandardortool-schema/164)|[BiomedicalStandard](BiomedicalStandard)|CRD|IHE Clinical Research Document standard||
||| [IHE](IHE)|Standardized means to locate communities that hold patient relevant health data and the translation of patient identifiers across communities holding the same patient’s data.|True|False|[https://profiles.ihe.net/ITI/TF/Volume1/ch-27.html](https://profiles.ihe.net/ITI/TF/Volume1/ch-27.html)|||[STANDARDSDATASTANDARDORTOOL:165](https://w3id.org/bridge2ai/standards-datastandardortool-schema/165)|[BiomedicalStandard](BiomedicalStandard)|IHE XCPD|IHE Cross-Community Patient Discovery Profile||
||| [IHE](IHE)|Technical profiles and definitions for IT use cases, transactions, content, and metadata.|True|False|[https://profiles.ihe.net/ITI/index.html](https://profiles.ihe.net/ITI/index.html)||[https://profiles.ihe.net/ITI/TF/index.html](https://profiles.ihe.net/ITI/TF/index.html)|[STANDARDSDATASTANDARDORTOOL:166](https://w3id.org/bridge2ai/standards-datastandardortool-schema/166)|[BiomedicalStandard](BiomedicalStandard)|IHE ITI|IHE IT Infrastructure Technical Framework||
||| [IHE](IHE)|Profile to support the analytical workflow between analyzers of the clinical laboratory and the IT systems managing their work|True|False|[https://www.ihe.net/resources/technical_frameworks/#PaLM](https://www.ihe.net/resources/technical_frameworks/#PaLM)||[https://www.ihe.net/uploadedFiles/Documents/PaLM/IHE_PaLM_TF_Vol1.pdf](https://www.ihe.net/uploadedFiles/Documents/PaLM/IHE_PaLM_TF_Vol1.pdf)|[STANDARDSDATASTANDARDORTOOL:167](https://w3id.org/bridge2ai/standards-datastandardortool-schema/167)|[BiomedicalStandard](BiomedicalStandard)|LAW|IHE Laboratory Analytical Workflow||
||| [IHE](IHE)|Standards for medical device communication.|True|False|[https://wiki.ihe.net/index.php?title=PCD_Profiles](https://wiki.ihe.net/index.php?title=PCD_Profiles)|||[STANDARDSDATASTANDARDORTOOL:168](https://w3id.org/bridge2ai/standards-datastandardortool-schema/168)|[BiomedicalStandard](BiomedicalStandard)|IHE PCD|IHE Patient Care Device Profiles||
||| [IHE](IHE)|Standardized ways for multiple distributed applications to query a patient information server for a list of patients, based on user-defined search criteria, and retrieve a patient’s demographic (and, optionally, visit or visit-related) information directly into the application.|True|False|[https://profiles.ihe.net/ITI/TF/Volume1/ch-8.html](https://profiles.ihe.net/ITI/TF/Volume1/ch-8.html)|||[STANDARDSDATASTANDARDORTOOL:169](https://w3id.org/bridge2ai/standards-datastandardortool-schema/169)|[BiomedicalStandard](BiomedicalStandard)|IHE PDQ|IHE Patient Demographics Query Integration Profile||
||| [IHE](IHE)|The RFD Profile provides a generic polling mechanism to allow an external agency to indicate issues with data that have been captured and enable the healthcare provider to correct the data. The profile does not dictate the mechanism employed or content required to achieve such corrections.|True|False|[https://profiles.ihe.net/ITI/TF/Volume1/ch-17.html](https://profiles.ihe.net/ITI/TF/Volume1/ch-17.html)|||[STANDARDSDATASTANDARDORTOOL:170](https://w3id.org/bridge2ai/standards-datastandardortool-schema/170)|[BiomedicalStandard](BiomedicalStandard)|RFD|IHE Retrieve Form for Data Capture||
||| [STANDARDSORGANIZATION:53](STANDARDSORGANIZATION:53)|Industry-defined format to facilitate the publication and exchange of LOINC codes for vendor IVD test results.|True|False|[https://ivdconnectivity.org/livd/](https://ivdconnectivity.org/livd/)|||[STANDARDSDATASTANDARDORTOOL:171](https://w3id.org/bridge2ai/standards-datastandardortool-schema/171)|[BiomedicalStandard](BiomedicalStandard)|LIVD|IICC Digital Format for Publication of LOINC to Vendor IVD Test Results||
| fileformat| [STANDARDSDATATOPIC:19](STANDARDSDATATOPIC:19)||The Image Cytometry Standard (ICS) is a digital multidimensional image file format used in life sciences microscopy. It stores not only the image data, but also the microscopic parameters describing the optics during the acquisition.|True|False|[https://en.wikipedia.org/wiki/Image_Cytometry_Standard](https://en.wikipedia.org/wiki/Image_Cytometry_Standard)|[doi:10.1002/cyto.990110502](doi:10.1002/cyto.990110502)||[STANDARDSDATASTANDARDORTOOL:172](https://w3id.org/bridge2ai/standards-datastandardortool-schema/172)|[BiomedicalStandard](BiomedicalStandard)|ICS|Image Cytometry Standard||
| fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15) [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)| [COMPUTIS](COMPUTIS)|The purpose of imzML is to facilitate the exchange and processing of mass spectrometry imaging data. This website is intended to provide all information neccesary to implement imzML.imzML was developed in the framework of the EU funded project COMPUTIS. The main goals during the development were complete description of MS imaging experiments and efficient storage of (very large) data sets. imzML is it not limited to MS imaging, but is also useful for other MS applications generating large data sets such as LC-FTMS. The current version is mzML 1.1.0. The metadata part of imzML is based on the mzML format by HUPO-PSI|True|False|[https://ms-imaging.org/imzml/](https://ms-imaging.org/imzml/)|[doi:10.1016/j.jprot.2012.07.026](doi:10.1016/j.jprot.2012.07.026)||[STANDARDSDATASTANDARDORTOOL:173](https://w3id.org/bridge2ai/standards-datastandardortool-schema/173)|[BiomedicalStandard](BiomedicalStandard)|imzML|imzML format||
| codesystem| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:14](STANDARDSORGANIZATION:14)|Diseases and diagnostic categories|True|False|[https://www.cdc.gov/nchs/icd/icd-10-cm.htm](https://www.cdc.gov/nchs/icd/icd-10-cm.htm)|||[STANDARDSDATASTANDARDORTOOL:174](https://w3id.org/bridge2ai/standards-datastandardortool-schema/174)|[BiomedicalStandard](BiomedicalStandard)|ICD-10-CM|International Classification of Diseases 10th Revision Clinical Modification||
| codesystem| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:100](STANDARDSORGANIZATION:100)|Diseases and diagnostic categories|True|False|[https://icd.who.int/en](https://icd.who.int/en)|||[STANDARDSDATASTANDARDORTOOL:175](https://w3id.org/bridge2ai/standards-datastandardortool-schema/175)|[BiomedicalStandard](BiomedicalStandard)|ICD-11|International Classification of Diseases 11th Revision||
| codesystem| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:14](STANDARDSORGANIZATION:14)|Diseases and diagnostic categories|True|False|[https://www.cdc.gov/nchs/icd/icd9cm.htm](https://www.cdc.gov/nchs/icd/icd9cm.htm)|||[STANDARDSDATASTANDARDORTOOL:176](https://w3id.org/bridge2ai/standards-datastandardortool-schema/176)|[BiomedicalStandard](BiomedicalStandard)|ICD-9-CM|International Classification of Diseases 9th Revision Clinical Modification||
| guidelines| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||A design directive for transparent ML systems in medical image analysis. The INTRPRT guideline suggests human-centered design principles, recommending formative user research as the first step to understand user needs and domain requirements.|True|False||[doi:10.1038/s41746-022-00699-2](doi:10.1038/s41746-022-00699-2)||[STANDARDSDATASTANDARDORTOOL:177](https://w3id.org/bridge2ai/standards-datastandardortool-schema/177)|[BiomedicalStandard](BiomedicalStandard)|INTRPRT|INTRPRT guidelines for transparent machine learning for medical image analysis||
|| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||Alignment can be interpreted as a set of uni-directional mappings for transforming input RDF graph into output RDF graph. It is persisted in IPSM Alignment Format (IPSM-AF) that is based on a well known Alignment API Format.|True|False|[https://inter-iot.readthedocs.io/projects/ipsm/en/latest/Configuration/Alignment-format/IPSM-alignment-format/](https://inter-iot.readthedocs.io/projects/ipsm/en/latest/Configuration/Alignment-format/IPSM-alignment-format/)||[https://github.com/INTER-IoT/ipsm-alignments](https://github.com/INTER-IoT/ipsm-alignments)|[STANDARDSDATASTANDARDORTOOL:178](https://w3id.org/bridge2ai/standards-datastandardortool-schema/178)|[BiomedicalStandard](BiomedicalStandard)|IPSM-AF|IPSM Alignment Format||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:47](STANDARDSORGANIZATION:47)|ISA-TAB-Nano specifies the format for representing and sharing information about nanomaterials, small molecules and biological specimens along with their assay characterization data (including metadata, and summary data) using spreadsheet or TAB-delimited files.|True|False|[https://wiki.nci.nih.gov/display/icr/isa-tab-nano](https://wiki.nci.nih.gov/display/icr/isa-tab-nano)|[doi:10.1186/1472-6750-13-2](doi:10.1186/1472-6750-13-2)||[STANDARDSDATASTANDARDORTOOL:179](https://w3id.org/bridge2ai/standards-datastandardortool-schema/179)|[BiomedicalStandard](BiomedicalStandard)|ISA-TAB-Nano|ISA-Tab-Nano format||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:49](STANDARDSORGANIZATION:49)|A means for communicating part or all of the electronic health record (EHR) of one or more identified subjects of care between EHR systems, or between EHR systems and a centralised EHR data repository. It can also be used for EHR communication between an EHR system or repository and clinical applications or middleware components (such as decision support components), or personal health applications and devices, that need to access or provide EHR data, or as the representation of EHR data within a distributed (federated) record system.|False|True|[http://www.en13606.org/](http://www.en13606.org/)||[https://www.iso.org/standard/67868.html](https://www.iso.org/standard/67868.html)|[STANDARDSDATASTANDARDORTOOL:180](https://w3id.org/bridge2ai/standards-datastandardortool-schema/180)|[BiomedicalStandard](BiomedicalStandard)|EN13606|ISO 13606 standard for Electronic Health Record Communication||
||| [STANDARDSORGANIZATION:50](STANDARDSORGANIZATION:50)|Standards for medical device communication.|True|False|[https://www.itu.int/en/ITU-T/studygroups/2013-2016/16/Pages/rm/ehealth.aspx](https://www.itu.int/en/ITU-T/studygroups/2013-2016/16/Pages/rm/ehealth.aspx)|||[STANDARDSDATASTANDARDORTOOL:181](https://w3id.org/bridge2ai/standards-datastandardortool-schema/181)|[BiomedicalStandard](BiomedicalStandard)|ITU-T E-health|ITU H.810, H.811, H.812, H.812.5, and H.813||
| fileformat|| [STANDARDSORGANIZATION:51](STANDARDSORGANIZATION:51)|The JCAMP-DX was one of the earliest specifications providing a standard file format for data exchange in mass spectrometry. It was initially developed for infrared spectrometry and related chemical and physical information between spectrometer data systems of different manufacture. It was also used later for nuclear magnetic resonance spectroscopy. JCAMP-DX is an ASCII based format and therefore not very compact even though it includes standards for file compression. All data are stored as labeled fields of variable length using printable ASCII characters. JCAMP-DX was officially released in 1988. JCAMP-DX was found impractical for today's large MS data sets, but it is still used for exchanging moderate numbers of spectra. IUPAC is currently in charge of its maintenance and the latest protocol is from 2005.|True|False|[https://iupac.org/what-we-do/digital-standards/jcamp-dx/](https://iupac.org/what-we-do/digital-standards/jcamp-dx/)|||[STANDARDSDATASTANDARDORTOOL:182](https://w3id.org/bridge2ai/standards-datastandardortool-schema/182)|[BiomedicalStandard](BiomedicalStandard)|JCAMP-DX|Joint Committee on Atomic and Molecular Physical Data standard||
| fileformat|||A format used by the khmer tool to represent k-mer counts and their occurences.|True|False|[https://khmer.readthedocs.io/en/v2.0/dev/binary-file-formats.html#countgraph](https://khmer.readthedocs.io/en/v2.0/dev/binary-file-formats.html#countgraph)|[doi:10.12688/f1000research.6924.1](doi:10.12688/f1000research.6924.1)||[STANDARDSDATASTANDARDORTOOL:183](https://w3id.org/bridge2ai/standards-datastandardortool-schema/183)|[BiomedicalStandard](BiomedicalStandard)|Countgraph|K-mer countgraph||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||A standard way of measuring the ability of cancer patients to perform ordinary tasks. The Karnofsky Performance Status scores range from 0 to 100. A higher score means the patient is better able to carry out daily activities. Karnofsky Performance Status may be used to determine a patient's prognosis, to measure changes in a patient’s ability to function, or to decide if a patient could be included in a clinical trial. Also called KPS.|True|False|[http://www.npcrc.org/files/news/karnofsky_performance_scale.pdf](http://www.npcrc.org/files/news/karnofsky_performance_scale.pdf)|[doi:10.1200/JCO.1984.2.3.187](doi:10.1200/JCO.1984.2.3.187)||[STANDARDSDATASTANDARDORTOOL:184](https://w3id.org/bridge2ai/standards-datastandardortool-schema/184)|[BiomedicalStandard](BiomedicalStandard)|KPS|Karnofsky Performance Scale||
| markuplanguage| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)| [STANDARDSORGANIZATION:52](STANDARDSORGANIZATION:52)|The KEGG Markup Language (KGML) is an exchange format of the KEGG pathway maps, which is converted from internally used KGML+ (KGML+SVG) format.|True|False|[https://www.kegg.jp/kegg/xml/](https://www.kegg.jp/kegg/xml/)|||[STANDARDSDATASTANDARDORTOOL:185](https://w3id.org/bridge2ai/standards-datastandardortool-schema/185)|[BiomedicalStandard](BiomedicalStandard)|KGML|KEGG Markup Language||
| deprecated| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20)||The LS DAM v2.2.1 is comprised of 130 classes and covers several core areas including Experiment, Molecular Biology, Molecular Databases and Specimen. Nearly half of these classes originate from the BRIDG model, emphasizing the semantic harmonization between these models. Validation of the LS DAM against independently derived information models, research scenarios and reference databases supports its general applicability to represent life sciences research.|True|False||[doi:10.1136/amiajnl-2011-000763](doi:10.1136/amiajnl-2011-000763)||[STANDARDSDATASTANDARDORTOOL:186](https://w3id.org/bridge2ai/standards-datastandardortool-schema/186)|[BiomedicalStandard](BiomedicalStandard)|LS-DAM|Life sciences domain analysis model||
| codesystem| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:53](STANDARDSORGANIZATION:53)|Tests, observations, diagnostics, and other clinical procedures.|True|True|[loinc.org](loinc.org)|||[STANDARDSDATASTANDARDORTOOL:187](https://w3id.org/bridge2ai/standards-datastandardortool-schema/187)|[BiomedicalStandard](BiomedicalStandard)|LOINC|Logical Observation Identifier Names and Codes||
| fileformat| [STANDARDSDATATOPIC:27](STANDARDSDATATOPIC:27)| [STANDARDSORGANIZATION:82](STANDARDSORGANIZATION:82)|PDBx/mmCIF became the standard PDB archive format in 2014. All PDB data processing and annotation will be performed using PDBx/mmCIF at all wwPDB sites. PDBx/mmCIF consists of categories of information represented as tables and keyword value pairs.|True|False|[https://mmcif.wwpdb.org/](https://mmcif.wwpdb.org/)|||[STANDARDSDATASTANDARDORTOOL:188](https://w3id.org/bridge2ai/standards-datastandardortool-schema/188)|[BiomedicalStandard](BiomedicalStandard)|mmCIF|Macromolecular Crystallographic Information File||
| markuplanguage| [STANDARDSDATATOPIC:23](STANDARDSDATATOPIC:23)||MSAML was formulated to make manipulation and extraction of multiple sequence alignment information easier by logically defining the parts of an alignment for use in an XML conformant application.|True|False|[http://xml.coverpages.org/msaml-desc-dec.html](http://xml.coverpages.org/msaml-desc-dec.html)|||[STANDARDSDATASTANDARDORTOOL:189](https://w3id.org/bridge2ai/standards-datastandardortool-schema/189)|[BiomedicalStandard](BiomedicalStandard)|MSAML|Markup Components for Describing Multiple Sequence Alignments||
| fileformat| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3) [STANDARDSDATATOPIC:27](STANDARDSDATATOPIC:27)||An MDL Molfile is a file format for holding information about the atoms, bonds, connectivity and coordinates of a molecule.|True|False|[https://en.wikipedia.org/wiki/Chemical_table_file](https://en.wikipedia.org/wiki/Chemical_table_file)|||[STANDARDSDATASTANDARDORTOOL:190](https://w3id.org/bridge2ai/standards-datastandardortool-schema/190)|[BiomedicalStandard](BiomedicalStandard)|MDL|MDL molfile Format||
| fileformat| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)||The MDL reaction format is used to store information on chemical reactions.|True|False|[https://open-babel.readthedocs.io/en/latest/FileFormats/MDL_RXN_format.html](https://open-babel.readthedocs.io/en/latest/FileFormats/MDL_RXN_format.html)|||[STANDARDSDATASTANDARDORTOOL:191](https://w3id.org/bridge2ai/standards-datastandardortool-schema/191)|[BiomedicalStandard](BiomedicalStandard)|RXN|MDL reaction Format||
| guidelines| [Demographics](Demographics) [STANDARDSDATATOPIC:31](STANDARDSDATATOPIC:31)| [STANDARDSORGANIZATION:60](STANDARDSORGANIZATION:60)|Measuring Sex, Gender Identity, and Sexual Orientation recommends that the National Institutes of Health (NIH) adopt new practices for collecting data on sex, gender, and sexual orientation - including collecting gender data by default, and not conflating gender with sex as a biological variable. The report recommends standardized language to be used in survey questions that ask about a respondent's sex, gender identity, and sexual orientation. Better measurements will improve data quality, as well as the NIH's ability to identify LGBTQI+ populations and understand the challenges they face.|True|False|[https://nap.nationalacademies.org/catalog/26424/measuring-sex-gender-identity-and-sexual-orientation](https://nap.nationalacademies.org/catalog/26424/measuring-sex-gender-identity-and-sexual-orientation)|[doi:10.17226/26424](doi:10.17226/26424)||[STANDARDSDATASTANDARDORTOOL:192](https://w3id.org/bridge2ai/standards-datastandardortool-schema/192)|[BiomedicalStandard](BiomedicalStandard)||Measuring Sex, Gender Identity, and Sexual Orientation||
| fileformat| [STANDARDSDATATOPIC:22](STANDARDSDATATOPIC:22)||A system for flexible, self-documenting representation of neuroscientific imaging data with arbitrary orientation and dimensionality.|True|False|[https://en.wikibooks.org/wiki/MINC/SoftwareDevelopment/MINC2.0_File_Format_Reference](https://en.wikibooks.org/wiki/MINC/SoftwareDevelopment/MINC2.0_File_Format_Reference)|[doi:10.3389/fninf.2016.00035](doi:10.3389/fninf.2016.00035)||[STANDARDSDATASTANDARDORTOOL:193](https://w3id.org/bridge2ai/standards-datastandardortool-schema/193)|[BiomedicalStandard](BiomedicalStandard)|MNC|Medical Imaging NetCDF (Minc) format||
| codesystem| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:17](STANDARDSORGANIZATION:17)|Medical cases in the US are classified into Medicare Severity Diagnosis Related Groups (MS-DRGs) for payment based on the following information reported by the hospital - the principal diagnosis, up to 24 additional diagnoses, and up to 25 procedures performed during the stay. In a small number of MS-DRGs, classification is also based on the age, sex, and discharge status of the patient. Effective October 1, 2015, the diagnosis and procedure information is reported by the hospital using codes from the International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM) and the International Classification of Diseases, Tenth Revision, Procedure Coding System (ICD-10-PCS).|True|False|[https://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/AcuteInpatientPPS/MS-DRG-Classifications-and-Software](https://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/AcuteInpatientPPS/MS-DRG-Classifications-and-Software)|||[STANDARDSDATASTANDARDORTOOL:194](https://w3id.org/bridge2ai/standards-datastandardortool-schema/194)|[BiomedicalStandard](BiomedicalStandard)|MS-DRG|Medicare Severity Diagnosis Related Groups codes||
| datamodel| [STANDARDSDATATOPIC:11](STANDARDSDATATOPIC:11)||MEDIN is a list of information that accompanies a data set and allows other people to find out what the data set contains, where it was collected and how they can get hold of it. It is a standard for marine metadata and a set of tools to create metadata records that comply with the MEDIN Metadata Standard|True|False|[https://www.medin.org.uk/medin-discovery-metadata-standard](https://www.medin.org.uk/medin-discovery-metadata-standard)||[https://github.com/medin-marine/Discovery-Standard-public-content](https://github.com/medin-marine/Discovery-Standard-public-content)|[STANDARDSDATASTANDARDORTOOL:195](https://w3id.org/bridge2ai/standards-datastandardortool-schema/195)|[BiomedicalStandard](BiomedicalStandard)|MEDIN|MEDIN Discovery Metadata Standard||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||The Memorial Symptom Assessment Scale (MSAS) is a new patient-rated instrument that was developed to provide multidimensional information about a diverse group of common symptoms.|True|False|[http://www.npcrc.org/files/news/memorial_symptom_assessment_scale.pdf](http://www.npcrc.org/files/news/memorial_symptom_assessment_scale.pdf)|[doi:10.1016/0959-8049(94)90182-1](doi:10.1016/0959-8049(94)90182-1)||[STANDARDSDATASTANDARDORTOOL:196](https://w3id.org/bridge2ai/standards-datastandardortool-schema/196)|[BiomedicalStandard](BiomedicalStandard)|MSAS|Memorial Symptom Assessment Scale||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28) [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||The conceptual and procedural meta-omics schema is developed as part of the MOD-CO project. It is entitled with "MOD-CO schema – a conceptual schema for processing sample data in meta’omics research" and published in various kind of schema representations. With that, the MOD-CO schema is a generic and comprehensive schema providing specifications useful for later software implementation and facilitates international standardisation processes.|True|False|[https://www.mod-co.net/wiki/Schema_Representations](https://www.mod-co.net/wiki/Schema_Representations)|||[STANDARDSDATASTANDARDORTOOL:197](https://w3id.org/bridge2ai/standards-datastandardortool-schema/197)|[BiomedicalStandard](BiomedicalStandard)|MOD-CO|Meta-omics Data and Collection Objects||
| fileformat|| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|MINiML (MIAME Notation in Markup Language, pronounced 'minimal') is a data exchange format optimized for microarray gene expression data, as well as many other types of high-throughput molecular abundance data. MINiML assumes only very basic relations between objects - Platform (e.g., array), Sample (e.g., hybridization), and Series (experiment). MINiML captures all components of the MIAME checklist, as well as any additional information that the submitter wants to provide. MINiML uses XML Schema as syntax.|True|False|[https://www.ncbi.nlm.nih.gov/geo/info/MINiML.html](https://www.ncbi.nlm.nih.gov/geo/info/MINiML.html)|||[STANDARDSDATASTANDARDORTOOL:198](https://w3id.org/bridge2ai/standards-datastandardortool-schema/198)|[BiomedicalStandard](BiomedicalStandard)|MINiML|MIAME Notation in Markup Language||
| markuplanguage| [STANDARDSDATATOPIC:33](STANDARDSDATATOPIC:33) [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||This document is a standard that addresses the representation of gene expression data and relevant annotations, as well as mechanisms for exchanging these data. The field of gene expression experiments has several distinct technologies that a standard must include (e.g., single vs. dual channel experiments, cDNA vs. oligonucleotides). Because of these different technologies and different types of gene expression experiments, it is not expected that all aspects of the standard will be used by all organizations. With the acceptance of XML Metadata Interchange as an OMG standard it is possible to specify a normative UML model using a tool such as Rational Rose that describes the data structures for Gene Expression|True|False|[http://scgap.systemsbiology.net/standards/mage_miame.php](http://scgap.systemsbiology.net/standards/mage_miame.php)|||[STANDARDSDATASTANDARDORTOOL:199](https://w3id.org/bridge2ai/standards-datastandardortool-schema/199)|[BiomedicalStandard](BiomedicalStandard)|MAGE-ML|MicroArray Gene Expression Markup Language||
| fileformat| [STANDARDSDATATOPIC:33](STANDARDSDATATOPIC:33) [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||Sharing of microarray data within the research community has been greatly facilitated by the development of the disclosure and communication standards MIAME and MAGE-ML by the FGED Society. However, the complexity of the MAGE-ML format has made its use impractical for laboratories lacking dedicated bioinformatics support. We propose a simple tab-delimited, spreadsheet-based format, MAGE-TAB, which will become a part of the MAGE microarray data standard and can be used for annotating and communicating microarray data in a MIAME compliant fashion. MAGE-TAB will enable laboratories without bioinformatics experience or support to manage, exchange and submit well-annotated microarray data in a standard format using a spreadsheet. The MAGE-TAB format is self-contained, and does not require an understanding of MAGE-ML or XML|True|False|[http://scgap.systemsbiology.net/standards/mage_miame.php](http://scgap.systemsbiology.net/standards/mage_miame.php)|||[STANDARDSDATASTANDARDORTOOL:200](https://w3id.org/bridge2ai/standards-datastandardortool-schema/200)|[BiomedicalStandard](BiomedicalStandard)|MAGE-TAB|MicroArray Gene Expression Markup Language Tab format||
| markuplanguage| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)||MCL is a data exchange standard for microbiological information. In short, MCL defines terms which can be used to reference and describe microorganisms. It is designed to form a simple and generic framework leveraging the electronical exchange of information about microorganisms. MCL is loosely coupled from its actual representation technologies and is currently used to structure XML and RDF files (see examples).|True|False||[doi:10.1016/j.resmic.2010.02.005](doi:10.1016/j.resmic.2010.02.005)||[STANDARDSDATASTANDARDORTOOL:201](https://w3id.org/bridge2ai/standards-datastandardortool-schema/201)|[BiomedicalStandard](BiomedicalStandard)|MCL|Microbiological Common Language||
|| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)| [STANDARDSORGANIZATION:57](STANDARDSORGANIZATION:57)|Format for MIMIC Waveform Database records.|True|False|[https://wfdb.io/mimic_wfdb_tutorials/mimic/formatting.html](https://wfdb.io/mimic_wfdb_tutorials/mimic/formatting.html)|||[STANDARDSDATASTANDARDORTOOL:202](https://w3id.org/bridge2ai/standards-datastandardortool-schema/202)|[BiomedicalStandard](BiomedicalStandard)|WFDB Format|MIMIC Waveform Database Format||
| minimuminformationschema| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||Information needed to enable the unambiguous interpretation and facilitate reproduction of the results of a high throughput sequencing experiment.|True|False|[https://zenodo.org/record/5706412](https://zenodo.org/record/5706412)||[https://drive.google.com/file/d/1YyvWT02puzMG_UgNmfAEJwVr60-pMvIE/view?usp=sharing](https://drive.google.com/file/d/1YyvWT02puzMG_UgNmfAEJwVr60-pMvIE/view?usp=sharing)|[STANDARDSDATASTANDARDORTOOL:203](https://w3id.org/bridge2ai/standards-datastandardortool-schema/203)|[BiomedicalStandard](BiomedicalStandard)|MINSEQE|Minimal Information about a high throughput SEQuencing Experiment||
| minimuminformationschema|||This is a reporting guideline for self-monitoring and quantified-self experiments and their use for research purposes.|False|False||[doi:10.3233/978-1-61499-423-7-79](doi:10.3233/978-1-61499-423-7-79)||[STANDARDSDATASTANDARDORTOOL:204](https://w3id.org/bridge2ai/standards-datastandardortool-schema/204)|[BiomedicalStandard](BiomedicalStandard)|MISME|Minimal Information about a Self-Monitoring Experiment||
| minimuminformationschema|||A set of guidelines for the consistent annotation and curation of computational models in biology.|True|False|[http://co.mbine.org/standards/miriam](http://co.mbine.org/standards/miriam)|||[STANDARDSDATASTANDARDORTOOL:205](https://w3id.org/bridge2ai/standards-datastandardortool-schema/205)|[BiomedicalStandard](BiomedicalStandard)|MIRIAM|Minimal Information Required In the Annotation of Models||
| minimuminformationschema| [STANDARDSDATATOPIC:2](STANDARDSDATATOPIC:2)||The fundamental tenet of scientific research is that the published results of any study have to be open to independent validation or refutation. The Minimum Information about a Flow Cytometry Experiment (MIFlowCyt) establishes criteria for recording and reporting information about the flow cytometry experiment overview, samples, instrumentation and data analysis. It promotes consistent annotation of clinical, biological and technical issues surrounding a flow cytometry experiment by specifying the requirements for data content and by providing a structured framework for capturing information.|True|False|[https://isac-net.org/page/MIFlowCyt](https://isac-net.org/page/MIFlowCyt)|[doi:10.1002/cyto.a.20623](doi:10.1002/cyto.a.20623)||[STANDARDSDATASTANDARDORTOOL:206](https://w3id.org/bridge2ai/standards-datastandardortool-schema/206)|[BiomedicalStandard](BiomedicalStandard)|MIFlowCyt|Minimum Information about a Flow Cytometry Experiment||
| minimuminformationschema| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|Information from whole proteomics experiments; where samples came from, and how analyses of them were performed.|True|False|[https://www.psidev.info/miape](https://www.psidev.info/miape)|||[STANDARDSDATASTANDARDORTOOL:207](https://w3id.org/bridge2ai/standards-datastandardortool-schema/207)|[BiomedicalStandard](BiomedicalStandard)|MIAPE|Minimum Information About a Proteomics Experiment||
| minimuminformationschema|||Minimum Information About an RNAi Experiment (MIARE) is a set of reporting guidelines that describes the minimum information that should be reported about an RNAi experiment to enable the unambiguous interpretation and reproduction of the results. MIARE forms part of a larger effort to develop RNAi data standards that include a data model, data exchange format, controlled vocabulary and supporting software tools.|True|False|[http://miare.sourceforge.net/HomePage](http://miare.sourceforge.net/HomePage)|||[STANDARDSDATASTANDARDORTOOL:208](https://w3id.org/bridge2ai/standards-datastandardortool-schema/208)|[BiomedicalStandard](BiomedicalStandard)|MIARE|Minimum Information About a RNAi Experiment||
| minimuminformationschema|| [STANDARDSORGANIZATION:38](STANDARDSORGANIZATION:38)|The minimum information about any (x) sequence (MIxS) is.a unified standard for describing sequence data and to provide a single point of entry for the scientific community to access and learn about the Genomic Standards Consortium (GSC) checklists.|True|False|[https://genomicsstandardsconsortium.github.io/mixs/](https://genomicsstandardsconsortium.github.io/mixs/)|[doi:10.1038/nbt.1823](doi:10.1038/nbt.1823)|[https://github.com/GenomicsStandardsConsortium/mixs/](https://github.com/GenomicsStandardsConsortium/mixs/)|[STANDARDSDATASTANDARDORTOOL:209](https://w3id.org/bridge2ai/standards-datastandardortool-schema/209)|[BiomedicalStandard](BiomedicalStandard)|MIxS|Minimum information about any sequence||
| minimuminformationschema|||A reporting guideline for plant phenotyping experiments. Comprises a checklist, i.e., a list of attributes that may be necessary to fully describe an experiment so that it is understandable and replicable. Should be consulted by people recording and depositing the data. Covers description of the following aspects of plant phenotyping experiment - study, environment, experimental design, sample management, biosource, treatment and phenotype. To read more, please visit http://cropnet.pl/phenotypes|True|False|[https://www.miappe.org/](https://www.miappe.org/)|||[STANDARDSDATASTANDARDORTOOL:210](https://w3id.org/bridge2ai/standards-datastandardortool-schema/210)|[BiomedicalStandard](BiomedicalStandard)|MIAPPE|Minimum Information About Plant Phenotyping Experiments||
| minimuminformationschema| [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)||MIASM was developed for the collection of somatic variations to promote standards for annotations of somatic variation data, and to promote data integration with other data resources.|True|False|[http://structure.bmc.lu.se/MIASM/miasm.html](http://structure.bmc.lu.se/MIASM/miasm.html)|[doi:10.1002/humu.20832](doi:10.1002/humu.20832)||[STANDARDSDATASTANDARDORTOOL:211](https://w3id.org/bridge2ai/standards-datastandardortool-schema/211)|[BiomedicalStandard](BiomedicalStandard)|MIASM|Minimum Information About Somatic Mutation||
| minimuminformationschema|||The MIQAS set of rules accompanied with the standardized XML and tab-delimited file formats will serve two goals - to encourage research groups that wish to publish a QTL paper to provide and submit the necessary information that would make meta-analysis possible. to allow easy interchange of data between different QTL and association analysis databases. Databases that implement the standardized XML format will typically write an import and an export filter to read data from and dump data into that an XML file. This is the same approach as used for the exchange of sequences between NCBI, Ensembl and DDBJ at the early stages of the Human Genome Project.|True|False|[http://miqas.sourceforge.net/](http://miqas.sourceforge.net/)|||[STANDARDSDATASTANDARDORTOOL:212](https://w3id.org/bridge2ai/standards-datastandardortool-schema/212)|[BiomedicalStandard](BiomedicalStandard)|MIQAS|Minimum Information for QTLs and Association Studies||
| minimuminformationschema|||MIABIS represents the minimum information required to initiate collaborations between biobanks and to enable the exchange of biological samples and data. The aim is to facilitate the reuse of bio-resources and associated data by harmonizing biobanking and biomedical research.|True|False||[doi:10.1089/bio.2015.0070](doi:10.1089/bio.2015.0070)||[STANDARDSDATASTANDARDORTOOL:213](https://w3id.org/bridge2ai/standards-datastandardortool-schema/213)|[BiomedicalStandard](BiomedicalStandard)|MIABIS|Minimum information required to initiate collaborations between biobanks||
| minimuminformationschema| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|This module identifies the minimum information required to report the use of quantification techniques in a proteomics experiment, sufficient to support both the effective interpretation and assessment of the data and the potential recreation of the results of the data analysis.|True|False|[https://www.psidev.info/attachments/miape-quant-091-documents](https://www.psidev.info/attachments/miape-quant-091-documents)|||[STANDARDSDATASTANDARDORTOOL:214](https://w3id.org/bridge2ai/standards-datastandardortool-schema/214)|[BiomedicalStandard](BiomedicalStandard)|MIAPE-Quant|Minimum information required to report the use of quantification techniques in a proteomics experiment||
|| [STANDARDSDATATOPIC:27](STANDARDSDATATOPIC:27)||An extension of the Protein Data Bank Exchange / macromolecular Crystallographic Information Framework (PDBx/mmCIF); provides an extensible data representation for deposition, archiving, and public dissemination of predicted 3D models of proteins.|True|False||[doi:10.1101/2022.12.06.518550](doi:10.1101/2022.12.06.518550)|[http://github.com/ihmwg/ModelCIF](http://github.com/ihmwg/ModelCIF)|[STANDARDSDATASTANDARDORTOOL:215](https://w3id.org/bridge2ai/standards-datastandardortool-schema/215)|[BiomedicalStandard](BiomedicalStandard)|ModelCIF|ModelCIF||
| multimodal|||The Multilevel Healthcare Information Modeling (MLHIM) specifications enables the exchange of syntactically and semantically interoperable data extracts between distributed, independently developed, biomedical databases and clinical applications, promoting syntactic and semantic integration of Translational Research data. The Semantic MedWeb is an implementation of a MLHIM-based database development platform (open source code available at https://github.com/mlhim/SemanticMedWeb)|True|False|[https://mlhim-specifications.readthedocs.io/en/master/](https://mlhim-specifications.readthedocs.io/en/master/)|||[STANDARDSDATASTANDARDORTOOL:216](https://w3id.org/bridge2ai/standards-datastandardortool-schema/216)|[BiomedicalStandard](BiomedicalStandard)|MLHIM|Multilevel Healthcare Information Modeling specifications||
| fileformat| [STANDARDSDATATOPIC:23](STANDARDSDATATOPIC:23)||The multiple alignment format stores a series of multiple alignments in a format that is easy to parse and relatively easy to read. This format stores multiple alignments at the DNA level between entire genomes. Previously used formats are suitable for multiple alignments of single proteins or regions of DNA without rearrangements, but would require considerable extension to cope with genomic issues such as forward and reverse strand directions, multiple pieces to the alignment, and so forth.|True|False|[http://genome.ucsc.edu/FAQ/FAQformat.html#format5](http://genome.ucsc.edu/FAQ/FAQformat.html#format5)|||[STANDARDSDATASTANDARDORTOOL:217](https://w3id.org/bridge2ai/standards-datastandardortool-schema/217)|[BiomedicalStandard](BiomedicalStandard)|MAF|Multiple Alignment Format||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||mz5 is a complete reimplementation of the mzML ontology that is based on the efficient, industrial strength storage backend HDF5.|True|False||[doi:10.1074/mcp.O111.011379](doi:10.1074/mcp.O111.011379)||[STANDARDSDATASTANDARDORTOOL:218](https://w3id.org/bridge2ai/standards-datastandardortool-schema/218)|[BiomedicalStandard](BiomedicalStandard)|mz5|mz5 format||
| fileformat| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|mzData is an XML format for representing mass spectrometry data in such a way as to completely describe the instrumental aspects of the experiment. This format is deprecated and has been superseded by mzML.|True|False|[https://psidev.info/mass-spectrometry-workgroup#mzdata](https://psidev.info/mass-spectrometry-workgroup#mzdata)|||[STANDARDSDATASTANDARDORTOOL:219](https://w3id.org/bridge2ai/standards-datastandardortool-schema/219)|[BiomedicalStandard](BiomedicalStandard)|mzData|mzData format||
| fileformat| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|A large number of different proteomics search engines are available that produce output in a variety of different formats. It is intended that mzIdentML will provide a common format for the export of identification results from any search engine. The format was originally developed under the name AnalysisXML as a format for several types of computational analyses performed over mass spectra in the proteomics context.|True|False|[https://www.psidev.info/mzidentml](https://www.psidev.info/mzidentml)|||[STANDARDSDATASTANDARDORTOOL:220](https://w3id.org/bridge2ai/standards-datastandardortool-schema/220)|[BiomedicalStandard](BiomedicalStandard)|mzIndentML|mzIndentML format||
| fileformat| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|From 2005-2008 there has existed two separate XML formats for encoding raw spectrometer output, mzData developed by the PSI and mzXML developed at the Seattle Proteome Center at the Institute for Systems Biology. It was recognized that the existence of two separate formats for essentially the same thing generated confusion and required extra programming effort. Therefore the PSI, with full participation by ISB, has developed a new format by taking the best aspects of each of the precursor formats to form a single one. It is intended to replace the previous two formats. This new format was originally given a working name of dataXML. The final name is mzML.|True|False|[https://psidev.info/mzML](https://psidev.info/mzML)|[doi:10.1007/978-1-60761-444-9_22](doi:10.1007/978-1-60761-444-9_22)|[http://www.peptideatlas.org/tmp/mzML1.1.0.html](http://www.peptideatlas.org/tmp/mzML1.1.0.html)|[STANDARDSDATASTANDARDORTOOL:221](https://w3id.org/bridge2ai/standards-datastandardortool-schema/221)|[BiomedicalStandard](BiomedicalStandard)|mzML|mzML format||
| fileformat| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|The mzQuantML standard format is intended to store the systematic description of workflows quantifying molecules (principly peptides and proteins) by mass spectrometry. A large number of different software packages are available that produce output in a variety of different formats. It is intended that mzQuantML will provide a common format for the export of identification results from any software package. The format was originally developed under the name AnalysisXML as a format for several types of computational analyses performed over mass spectra in the proteomics context. It has been decided to split development into two formats, mzIdentML for peptide and protein identification and mzQuantML (described here), covering quantitative proteomic data derived from MS. The development of mzQuantML is driven by some general principles, specific use cases and the goal of supporting specific techniques, as listed below. These were discussed and agreed at the development meeting in Tubingen in July 2011.|True|False|[https://www.psidev.info/mzquantml](https://www.psidev.info/mzquantml)|||[STANDARDSDATASTANDARDORTOOL:222](https://w3id.org/bridge2ai/standards-datastandardortool-schema/222)|[BiomedicalStandard](BiomedicalStandard)|mzQuantML|mzQuantML format||
| deprecated fileformat| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)||mzXML an open, generic XML (extensible markup language) representation of MS data. This format is now deprecated and it has been superseded by mzML.|True|False||[doi:10.1038/nbt1031](doi:10.1038/nbt1031)||[STANDARDSDATASTANDARDORTOOL:223](https://w3id.org/bridge2ai/standards-datastandardortool-schema/223)|[BiomedicalStandard](BiomedicalStandard)|mzXML|mzXML format||
||| [STANDARDSORGANIZATION:71](STANDARDSORGANIZATION:71)|Terminology content, tools, and services to accurately code, analyze and share cancer and biomedical research, clinical and public health information. Includes NCI Thesaurus and Metathesaurus.|True|True|[https://evs.nci.nih.gov/](https://evs.nci.nih.gov/)|||[STANDARDSDATASTANDARDORTOOL:224](https://w3id.org/bridge2ai/standards-datastandardortool-schema/224)|[BiomedicalStandard](BiomedicalStandard)|NCI EVS|National Cancer Institute Enterprise Vocabulary Service||
||| [NHTSA](NHTSA)|Standard for the collection and transmission of emergency medical services (EMS) operations and patient care data.|True|False|[https://nemsis.org/technical-resources/](https://nemsis.org/technical-resources/)|||[STANDARDSDATASTANDARDORTOOL:225](https://w3id.org/bridge2ai/standards-datastandardortool-schema/225)|[BiomedicalStandard](BiomedicalStandard)|NEMSIS|National Emergency Medical Services Information System||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:81](STANDARDSORGANIZATION:81)|This guiding principle is expressed in the CDM design through prioritization of analytic functionality, and a parsimonious approach based upon analytic utility. At times, this results in decisions that are not based in relational database modeling principles such as normalization. The model is designed to facilitate routine and rapid execution of distributed complex analytics. To meet this design requirement, some fields are duplicated across multiple tables to support faster analytic operations for distributed querying. The PCORnet CDM is based on the FDA Mini-Sentinel CDM. This allows PCORnet to more easily leverage the large array of analytic tools and expertise developed for the MSCDM v4.0, including data characterization approaches and the various tools for complex distributed analytics.|True|False|[http://pcornet.org/pcornet-common-data-model/](http://pcornet.org/pcornet-common-data-model/)||[https://pcornet.org/wp-content/uploads/2022/01/PCORnet-Common-Data-Model-v60-2020_10_221.pdf](https://pcornet.org/wp-content/uploads/2022/01/PCORnet-Common-Data-Model-v60-2020_10_221.pdf)|[STANDARDSDATASTANDARDORTOOL:226](https://w3id.org/bridge2ai/standards-datastandardortool-schema/226)|[BiomedicalStandard](BiomedicalStandard)|PCORNet CDM|National Patient-Centered Clinical Research Network Common Data Model||
||| [STANDARDSORGANIZATION:93](STANDARDSORGANIZATION:93)|Natural Collections Description (NCD) (A data standard for exchanging data describing natural history collections) is a proposed data standard for describing collections of natural history materials at the collection level; one NCD record describes one entire collection. Collection descriptions are electronic records that document the holdings of an organisation as groups of items, which complement the more traditional item-level records such as are produced for a single specimen or a library book. NCD is tailored to natural history. It lies between general resource discovery standards such as Dublin Core (DC) and rich collection description standards such as the Encoded Archival Description (EAD). The NCD standard covers all types of natural history collections, such as specimens, original artwork, archives, observations, library materials, datasets, photographs or mixed collections such as those that result from expeditions and voyages of discovery.|True|False|[https://www.tdwg.org/standards/ncd/](https://www.tdwg.org/standards/ncd/)|||[STANDARDSDATASTANDARDORTOOL:227](https://w3id.org/bridge2ai/standards-datastandardortool-schema/227)|[BiomedicalStandard](BiomedicalStandard)|NCD|Natural Collections Description standard||
| datamodel| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|This is a XML Schema specification of BioProject data. A BioProject is a collection of biological data related to a single initiative, originating from a single organization or from a consortium. A BioProject record provides users a single place to find links to the diverse data types generated for that project.|True|False||[doi:10.1093/nar/gkr1163](doi:10.1093/nar/gkr1163)|[https://www.ncbi.nlm.nih.gov/data_specs/schema/other/bioproject/](https://www.ncbi.nlm.nih.gov/data_specs/schema/other/bioproject/)|[STANDARDSDATASTANDARDORTOOL:228](https://w3id.org/bridge2ai/standards-datastandardortool-schema/228)|[BiomedicalStandard](BiomedicalStandard)|BioProject Schema|NCBI BioProject XML Schema||
||| [STANDARDSORGANIZATION:63](STANDARDSORGANIZATION:63)|Allows pharmacy benefit payers to communicate formulary and benefit Information to prescriber systems.|False|True|[https://standards.ncpdp.org/Access-to-Standards.aspx](https://standards.ncpdp.org/Access-to-Standards.aspx)|||[STANDARDSDATASTANDARDORTOOL:229](https://w3id.org/bridge2ai/standards-datastandardortool-schema/229)|[BiomedicalStandard](BiomedicalStandard)|NCPDP F&B|NCPDP Formulary and Benefit Standard||
| guidelines|| [STANDARDSORGANIZATION:64](STANDARDSORGANIZATION:64)|Guiding principles and a foundation for the capture and use of high-quality data for post-market evaluation of medical devices|True|True|[https://nestcc.org/data-quality-and-methods/](https://nestcc.org/data-quality-and-methods/)||[https://mdic.org/wp-content/uploads/2020/02/NESTcc-Data-Quality-Framework.pdf](https://mdic.org/wp-content/uploads/2020/02/NESTcc-Data-Quality-Framework.pdf)|[STANDARDSDATASTANDARDORTOOL:230](https://w3id.org/bridge2ai/standards-datastandardortool-schema/230)|[BiomedicalStandard](BiomedicalStandard)|NESTcc DQF|NESTcc Data Quality Framework||
||||A data standard for neurophysiology, providing neuroscientists with a common standard to share, archive, use, and build analysis tools for neurophysiology data.|True|False|[https://www.nwb.org/](https://www.nwb.org/)|[doi:10.1101/523035](doi:10.1101/523035)|[https://github.com/NeurodataWithoutBorders](https://github.com/NeurodataWithoutBorders)|[STANDARDSDATASTANDARDORTOOL:231](https://w3id.org/bridge2ai/standards-datastandardortool-schema/231)|[BiomedicalStandard](BiomedicalStandard)|NWB|Neurodata Without Borders||
| datamodel| [STANDARDSDATATOPIC:22](STANDARDSDATATOPIC:22)| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|The Neuroimaging Data Model (NIDM) is a collection of specification documents and examples that outline a domain specific extension to the W3C Provenance Data Model (PROV-DM) for the exchange and sharing of human brain imaging data. The goal of the data model is to capture data, information about the data and processes that generated the data (i.e. provenance). This information can be converted to RDF and therefore queried using SPARQL. This representation allows machine accessible representations of brain imaging data and will provide links to related resources such as publications, virtual machines, people and funding agencies.|True|False|[http://nidm.nidash.org/](http://nidm.nidash.org/)|||[STANDARDSDATASTANDARDORTOOL:232](https://w3id.org/bridge2ai/standards-datastandardortool-schema/232)|[BiomedicalStandard](BiomedicalStandard)|NIDM|Neuroimaging Data Model||
| fileformat| [STANDARDSDATATOPIC:22](STANDARDSDATATOPIC:22)||The Neuroimaging Informatics Technology Initiative (nifti) file format was envisioned about a decade ago as a replacement to the then widespread, yet problematic, analyze 7.5 file format. The main problem with the previous format was perhaps the lack of adequate information about orientation in space, such that the stored data could not be unambiguously interpreted. Although the file was used by many different imaging software, the lack of adequate information on orientation obliged some, most notably spm, to include, for every analyze file, an accompanying file describing the orientation, such as a file with extension .mat.|True|False|[https://nifti.nimh.nih.gov/](https://nifti.nimh.nih.gov/)||[https://nifti.nimh.nih.gov/nifti-2](https://nifti.nimh.nih.gov/nifti-2)|[STANDARDSDATASTANDARDORTOOL:233](https://w3id.org/bridge2ai/standards-datastandardortool-schema/233)|[BiomedicalStandard](BiomedicalStandard)|NIFTI|Neuroimaging Informatics Technology Initiative file format||
| markuplanguage|||NeuroML is a model description language developed in XML (extensible Markup Language) that was created to facilitate data archiving, data and model exchange, database creation, and model publication in the neurosciences. One of the goals of the NeuroML project is to develop standards for model specification that will allow for greater simulator interoperability and model exchange.|True|False|[https://neuroml.org/](https://neuroml.org/)|||[STANDARDSDATASTANDARDORTOOL:234](https://w3id.org/bridge2ai/standards-datastandardortool-schema/234)|[BiomedicalStandard](BiomedicalStandard)|NeuroML|NeuroML||
| fileformat|| [STANDARDSORGANIZATION:11](STANDARDSORGANIZATION:11)|The purpose of the Neurophysiology Data Translation Format (NDF) is to provide a means of sharing neurophysiology experimental data and derived data between services and tools developed within the CARMEN project (www.carmen.org.uk). This document specifes the NDF. The specification supports the types of data that are currently used by members of the CARMEN consortium and provides a capability to support future data types. It is capable of accommodating external data file formats as well as metadata such as user defined experimental descriptions and the history (provenance) of derived data.|True|False||[doi:10.3389/conf.fnins.2010.13.00118](doi:10.3389/conf.fnins.2010.13.00118)||[STANDARDSDATASTANDARDORTOOL:235](https://w3id.org/bridge2ai/standards-datastandardortool-schema/235)|[BiomedicalStandard](BiomedicalStandard)|NDF|Neurophysiology Data Translation Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)||NHX is based on the New Hampshire (NH) standard (also called "Newick tree format").|True|False|[http://www.phylosoft.org/NHX/](http://www.phylosoft.org/NHX/)|||[STANDARDSDATASTANDARDORTOOL:236](https://w3id.org/bridge2ai/standards-datastandardortool-schema/236)|[BiomedicalStandard](BiomedicalStandard)|NHX|New Hampshire eXtended Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)||The Newick Standard for representing trees in computer-readable form makes use of the correspondence between trees and nested parentheses, noticed in 1857 by the famous English mathematician Arthur Cayley.|True|False|[http://evolution.genetics.washington.edu/phylip/newicktree.html](http://evolution.genetics.washington.edu/phylip/newicktree.html)|||[STANDARDSDATASTANDARDORTOOL:237](https://w3id.org/bridge2ai/standards-datastandardortool-schema/237)|[BiomedicalStandard](BiomedicalStandard)|Newick|Newick tree Format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25) [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)||To facilitate interoperability in evolutionary comparative analysis, we present NeXML, an XML standard (inspired by the current standard, NEXUS) that supports exchange of richly annotated comparative data. NeXML defines syntax for operational taxonomic units, character-state matrices, and phylogenetic trees and networks. Documents can be validated unambiguously. Importantly, any data element can be annotated, to an arbitrary degree of richness, using a system that is both flexible and rigorous. We describe how the use of NeXML by the TreeBASE and Phenoscape projects satisfies user needs that cannot be satisfied with other available file formats|True|False|[http://www.nexml.org/](http://www.nexml.org/)||[https://github.com/nexml/nexml](https://github.com/nexml/nexml)|[STANDARDSDATASTANDARDORTOOL:238](https://w3id.org/bridge2ai/standards-datastandardortool-schema/238)|[BiomedicalStandard](BiomedicalStandard)|NeML|NeXML format||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12)||A sequence file. The .nib format packs 2 bases per byte and handles one record per nib file.|True|False|[https://genomebrowser.wustl.edu/goldenPath/help/blatSpec.html](https://genomebrowser.wustl.edu/goldenPath/help/blatSpec.html)|||[STANDARDSDATASTANDARDORTOOL:239](https://w3id.org/bridge2ai/standards-datastandardortool-schema/239)|[BiomedicalStandard](BiomedicalStandard)|nib|Nibble sequence format||
| fileformat|| [STANDARDSORGANIZATION:9](STANDARDSORGANIZATION:9)|Format and ontology used to represent experiments, spectral and derived data, and supporting metadata.|True|False|[https://bmrb.io/standards/](https://bmrb.io/standards/)|[doi:10.1007/s10858-018-0220-3](doi:10.1007/s10858-018-0220-3)||[STANDARDSDATASTANDARDORTOOL:240](https://w3id.org/bridge2ai/standards-datastandardortool-schema/240)|[BiomedicalStandard](BiomedicalStandard)|NMR-STAR|NMR Self-defining Text Archive and Retrieval format||
| markuplanguage| [STANDARDSDATATOPIC:17](STANDARDSDATATOPIC:17)| [STANDARDSORGANIZATION:21](STANDARDSORGANIZATION:21)|nmrML is an open mark-up language for NMR data. It is currently under heavy development and is not yet ready for public use. The development of this standard is coordinated by Workpackage 2 of the COSMOS - COordination Of Standards In MetabOlomicS Project. COSMOS is a global effort to enable free and open sharing of metabolomics data. Coordinated by Dr Christoph Steinbeck of the EMBL-European Bioinformatics Institute, COSMOS brings together European data providers to set and promote community standards that will make it easier to disseminate metabolomics data through life science e-infrastructures. This Coordination Action has been financed with €2 million by the European Commission's Seventh Framework Programme. The nmrML data standard will be approved by the Metabolomics Standards Initiative and was derived from an earlier nmrML that was developed by the Metabolomics Innovation Centre (TMIC).|True|False|[https://nmrml.org/](https://nmrml.org/)|||[STANDARDSDATASTANDARDORTOOL:241](https://w3id.org/bridge2ai/standards-datastandardortool-schema/241)|[BiomedicalStandard](BiomedicalStandard)|nmrML|nmrML||
| fileformat| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)||Observ-Tab is a simple spreadsheet format to represent and exchange phenotype data.|True|False||[doi:10.1002/humu.22070](doi:10.1002/humu.22070)||[STANDARDSDATASTANDARDORTOOL:242](https://w3id.org/bridge2ai/standards-datastandardortool-schema/242)|[BiomedicalStandard](BiomedicalStandard)|Observ-Tab|Observ-Tab format||
| datamodel| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|Open community data standard designed to standardize the structure and content of observational data and to enable efficient analyses that can produce reliable evidence.|True|False|[https://ohdsi.github.io/CommonDataModel/](https://ohdsi.github.io/CommonDataModel/)|[doi:10.3233/978-1-61499-564-7-574](doi:10.3233/978-1-61499-564-7-574)|[https://github.com/OHDSI/CommonDataModel](https://github.com/OHDSI/CommonDataModel)|[STANDARDSDATASTANDARDORTOOL:243](https://w3id.org/bridge2ai/standards-datastandardortool-schema/243)|[BiomedicalStandard](BiomedicalStandard)|OMOP CDM|Observational Medical Outcomes Partnership Common Data Model||
| datamodel| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|An improved replacement to the previously reported LAERTES system. One of the initial uses of CEM has been its use in generating lists of negative control concepts to be used in empirical calibration.|True|False|[https://github.com/OHDSI/CommonEvidenceModel/wiki/Postprocessing-Negative-Controls](https://github.com/OHDSI/CommonEvidenceModel/wiki/Postprocessing-Negative-Controls)|[doi:10.1007/s40264-014-0189-0](doi:10.1007/s40264-014-0189-0)|[https://github.com/OHDSI/CommonEvidenceModel](https://github.com/OHDSI/CommonEvidenceModel)|[STANDARDSDATASTANDARDORTOOL:244](https://w3id.org/bridge2ai/standards-datastandardortool-schema/244)|[BiomedicalStandard](BiomedicalStandard)|OMOP CEM|Observational Medical Outcomes Partnership Common Evidence Model||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A biology-oriented language for building ontologies, based on OWL.|True|False|[https://owlcollab.github.io/oboformat/doc/GO.format.obo-1_4.html](https://owlcollab.github.io/oboformat/doc/GO.format.obo-1_4.html)||[https://owlcollab.github.io/oboformat/doc/obo-syntax.html](https://owlcollab.github.io/oboformat/doc/obo-syntax.html)|[STANDARDSDATASTANDARDORTOOL:245](https://w3id.org/bridge2ai/standards-datastandardortool-schema/245)|[BiomedicalStandard](BiomedicalStandard)|OBO|Open Biomedical Ontology Flat File Format||
|| [STANDARDSDATATOPIC:18](STANDARDSDATATOPIC:18)||Data standards and tools for standardizing, storing, and visualizing mobile health data, including integration with FHIR standards.|True|False|[https://www.openmhealth.org/](https://www.openmhealth.org/)||[https://github.com/openmhealth](https://github.com/openmhealth)|[STANDARDSDATASTANDARDORTOOL:246](https://w3id.org/bridge2ai/standards-datastandardortool-schema/246)|[BiomedicalStandard](BiomedicalStandard)|Open mHealth|Open mHealth||
| fileformat| [STANDARDSDATATOPIC:19](STANDARDSDATATOPIC:19)| [STANDARDSORGANIZATION:77](STANDARDSORGANIZATION:77)|multi-spectral imaging data|True|False|[https://docs.openmicroscopy.org/ome-model/5.6.3/ome-tiff/#](https://docs.openmicroscopy.org/ome-model/5.6.3/ome-tiff/#)|||[STANDARDSDATASTANDARDORTOOL:247](https://w3id.org/bridge2ai/standards-datastandardortool-schema/247)|[BiomedicalStandard](BiomedicalStandard)|OME-TIFF|Open Microscopy Environment TIFF specification||
| fileformat| [STANDARDSDATATOPIC:19](STANDARDSDATATOPIC:19)| [STANDARDSORGANIZATION:77](STANDARDSORGANIZATION:77)|OME-XML is a file format for storing microscopy information (both pixels and metadata) using the OME Data Model.|True|False|[https://docs.openmicroscopy.org/ome-model/5.6.3/ome-xml/](https://docs.openmicroscopy.org/ome-model/5.6.3/ome-xml/)|[doi:10.1186/gb-2005-6-5-r47](doi:10.1186/gb-2005-6-5-r47)||[STANDARDSDATASTANDARDORTOOL:248](https://w3id.org/bridge2ai/standards-datastandardortool-schema/248)|[BiomedicalStandard](BiomedicalStandard)|OME-XML|Open Microscopy Environment XML format||
| fileformat| [STANDARDSDATATOPIC:27](STANDARDSDATATOPIC:27)| [COMBINE](COMBINE)|A compressed file that contains all the information needed to describe a modeling and simulation experiment.|True|False|||[http://co.mbine.org/specifications/omex.version-1.pdf](http://co.mbine.org/specifications/omex.version-1.pdf)|[STANDARDSDATASTANDARDORTOOL:249](https://w3id.org/bridge2ai/standards-datastandardortool-schema/249)|[BiomedicalStandard](BiomedicalStandard)|OMEX|Open Modeling EXchange format||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:54](STANDARDSORGANIZATION:54)|OpenICE is an initiative to create a community implementation of an Integrated Clinical Environment. The initiative encompasses not only software implementation but also an architecture for a wider clinical ecosystem to enable new avenues of clinical research. OpenICE seeks to integrate an inclusive framework of healthcare devices and clinical applications to existing Healthcare IT ecosystems.|True|False|[https://www.openice.info/](https://www.openice.info/)||[https://github.com/mdpnp/mdpnp](https://github.com/mdpnp/mdpnp)|[STANDARDSDATASTANDARDORTOOL:250](https://w3id.org/bridge2ai/standards-datastandardortool-schema/250)|[BiomedicalStandard](BiomedicalStandard)|OpenICE|Open-Source Integrated Clinical Environment Standard||
| datamodel| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:79](STANDARDSORGANIZATION:79)|This document contains the definitive statement of archetype semantics, in the form of an object model for archetypes. The model presented here can be used as a basis for building software that processes archetypes, independent of their persistent representation; equally, it can be used to develop the output side of parsers that process archetypes in a linguistic format, such as the openEHR Archetype Definition Language (ADL), XML-instance and so on. As a specification, it can be treated as an API for archetypes.|True|False|||[https://specifications.openehr.org/releases/AM/latest/AOM1.4.html](https://specifications.openehr.org/releases/AM/latest/AOM1.4.html)|[STANDARDSDATASTANDARDORTOOL:251](https://w3id.org/bridge2ai/standards-datastandardortool-schema/251)|[BiomedicalStandard](BiomedicalStandard)|AOM14|openEHR Archetype Object Model||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:79](STANDARDSORGANIZATION:79)|openEHR' is the name of a technology for e-health, consisting of open specifications, clinical models and software that can be used to create standards, and build information and interoperability solutions for healthcare. The various artefacts of openEHR are produced by the openEHR community and managed by openEHR International, an international non-profit organisation originally established in 2003 and previously managed by the openEHR Foundation.|True|False|[https://www.openehr.org/about/what_is_openehr](https://www.openehr.org/about/what_is_openehr)||[https://specifications.openehr.org/releases/BASE/latest/architecture_overview.html](https://specifications.openehr.org/releases/BASE/latest/architecture_overview.html)|[STANDARDSDATASTANDARDORTOOL:252](https://w3id.org/bridge2ai/standards-datastandardortool-schema/252)|[BiomedicalStandard](BiomedicalStandard)|openEHR|openEHR Architecture||
| guidelines|||The quality of research in hospital epidemiology (infection control) must be improved to be robust enough to influence policy and practice. In order to raise the standards of research and publication, a CONSORT equivalent for these largely quasi-experimental studies has been prepared by the authors of two relevant systematic reviews undertaken for the HTA and the Cochrane Collaboration. The statement was revised following widespread consultation with learned societies, editors of journals and researchers. It consists of a 22 item checklist, and a summary table. The emphasis is on transparency to improve the quality of reporting and on the use of appropriate statistical techniques.The statement has been endorsed and welcomed by a number of professional special interest groups and societies including the Association of Medical Microbiologists (AMM), Bristish Society for Antimicrobial Chemotherapy (BSAC) and the Infection Control Nurses' Association (ICNA) Research and Development Group. Like CONSORT, ORION considers itself a work in progress, which requires ongoing dialogue for successful promotion and dissemination. The statement is therefore offered for further public discussion and journals are encouraged to trial it as part of their reviewing and editing process and feedback to the authors.|True|False|[https://www.ucl.ac.uk/antimicrobial-resistance/reporting-guidelines/orion-statement-consort-equivalent-infection-control-intervention-studies](https://www.ucl.ac.uk/antimicrobial-resistance/reporting-guidelines/orion-statement-consort-equivalent-infection-control-intervention-studies)|[doi:10.1016/S1473-3099(07)70082-8](doi:10.1016/S1473-3099(07)70082-8)|[https://www.ucl.ac.uk/drupal/site_antimicrobial-resistance/sites/antimicrobial-resistance/files/checklist_authors.pdf](https://www.ucl.ac.uk/drupal/site_antimicrobial-resistance/sites/antimicrobial-resistance/files/checklist_authors.pdf)|[STANDARDSDATASTANDARDORTOOL:253](https://w3id.org/bridge2ai/standards-datastandardortool-schema/253)|[BiomedicalStandard](BiomedicalStandard)|ORION|Outbreak Reports and Intervention Studies Of Nosocomial infection||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:54](STANDARDSORGANIZATION:54)|This standard specifies the characteristics necessary for the safe integration of MEDICAL DEVICES and other equipment, via an electronic interface, from different MANUFACTURERS into a single medical system for the care of a single high acuity PATIENT. This standard establishes requirements for a medical system that is intended to have greater error resistance and improved PATIENT safety, treatment efficacy and workflow efficiency than can be achieved with independently used MEDICAL DEVICES.|False|False|[https://mdpnp.org/mdice.html](https://mdpnp.org/mdice.html)||[https://www.astm.org/f2761-09r13.html](https://www.astm.org/f2761-09r13.html)|[STANDARDSDATASTANDARDORTOOL:254](https://w3id.org/bridge2ai/standards-datastandardortool-schema/254)|[BiomedicalStandard](BiomedicalStandard)|ICE|Patient-Centric Integrated Clinical Environment Standard||
| fileformat| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)||The profile HMM calculated from multiple sequnce alignment data in this service is stored in Profile HMM save format (usually with ".hmm" extension). It is an ASCII file containing a lot of header and descriptive records followed by large numerical matrix which holds probabilistic model of the motif. The file of this format is useful to search against sequnce databases to find out other proteins which share the same motif. This HMM file should not be edited manually (especially the matrix part) because it contains consistent numerical model as a whole.|True|False|[http://hmmer.org/](http://hmmer.org/)||[https://www.genome.jp/tools/motif/hmmformat.htm](https://www.genome.jp/tools/motif/hmmformat.htm)|[STANDARDSDATASTANDARDORTOOL:255](https://w3id.org/bridge2ai/standards-datastandardortool-schema/255)|[BiomedicalStandard](BiomedicalStandard)|HMMER Format|Pfam / HMMER Profile file format||
| datamodel| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34) [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|Patient phenotypes.|True|False|[http://phenopackets.org/](http://phenopackets.org/)||[https://github.com/phenopackets/phenopacket-schema](https://github.com/phenopackets/phenopacket-schema)|[STANDARDSDATASTANDARDORTOOL:256](https://w3id.org/bridge2ai/standards-datastandardortool-schema/256)|[BiomedicalStandard](BiomedicalStandard)|Phenopackets|Phenopackets schema||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|An HL7 messaging and content reference standard for national, syndromic surveillance electronic health record technology certification; A basis for local and state syndromic surveillance messaging implementation guides; A resource for planning for the increasing use of electronic health record technology and for providing details on health data elements that may become a part of future public health syndromic surveillance messaging requirements; Optional elements of interest for adding laboratory results to syndromic surveillance messages using ORU^R01 message structure (see details in the PHIN messaging Standard, National Condition Reporting case Notification, ORU^R01 message Structure Specification profile, Version 2.1, 2014)|True|False|[https://knowledgerepository.syndromicsurveillance.org/hl7-version-251-phin-messaging-guide-syndromic-surveillance-emergency-department-urgent-care-and](https://knowledgerepository.syndromicsurveillance.org/hl7-version-251-phin-messaging-guide-syndromic-surveillance-emergency-department-urgent-care-and)||[https://www.cdc.gov/nssp/documents/guides/syndrsurvmessagguide2_messagingguide_phn.pdf](https://www.cdc.gov/nssp/documents/guides/syndrsurvmessagguide2_messagingguide_phn.pdf)|[STANDARDSDATASTANDARDORTOOL:257](https://w3id.org/bridge2ai/standards-datastandardortool-schema/257)|[BiomedicalStandard](BiomedicalStandard)|PHIN Guide|PHIN Messaging Guide for Syndromic Surveillance Emergency Department, Urgent Care, Inpatient and Ambulatory Care Settings||
| markuplanguage| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5) [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12)||phyloXML (example) is an XML language designed to describe phylogenetic trees (or networks) and associated data. PhyloXML provides elements for commonly used features, such as taxonomic information, gene names and identifiers, branch lengths, support values, and gene duplication and speciation events.|True|False|[http://www.phyloxml.org/](http://www.phyloxml.org/)|[doi:10.1186/1471-2105-10-356](doi:10.1186/1471-2105-10-356)||[STANDARDSDATASTANDARDORTOOL:258](https://w3id.org/bridge2ai/standards-datastandardortool-schema/258)|[BiomedicalStandard](BiomedicalStandard)|phyloXML|phyloXML||
|| [STANDARDSDATATOPIC:18](STANDARDSDATATOPIC:18)| [STANDARDSORGANIZATION:4](STANDARDSORGANIZATION:4)|Definitions and performance criteria for measuring step counting on consumer wearable or app-based physical activity monitoring devices.|True|True|[https://webstore.ansi.org/standards/ansi/cta20562016ansi](https://webstore.ansi.org/standards/ansi/cta20562016ansi)|||[STANDARDSDATASTANDARDORTOOL:259](https://w3id.org/bridge2ai/standards-datastandardortool-schema/259)|[BiomedicalStandard](BiomedicalStandard)|ANSI/CTA-2056|Physical Activity Monitoring for Fitness Wearables Step Counting||
|| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)||A formal specification for biological sample metadata structure. The PEP specification accommodates typical features of data-intensive bioinformatics projects with many biological samples.|True|False|[http://pep.databio.org/](http://pep.databio.org/)|[doi:10.1093/gigascience/giab077](doi:10.1093/gigascience/giab077)|[https://github.com/pepkit/pepspec](https://github.com/pepkit/pepspec)|[STANDARDSDATASTANDARDORTOOL:260](https://w3id.org/bridge2ai/standards-datastandardortool-schema/260)|[BiomedicalStandard](BiomedicalStandard)|PEP|Portable Encapsulated Project specification||
| fileformat| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)||A self-describing serialized format for bulk biomedical data called the Portable Format for Biomedical (PFB) data. The Portable Format for Biomedical data is based upon Avro and encapsulates a data model, a data dictionary, the data itself, and pointers to third party controlled vocabularies. In general, each data element in the data dictionary is associated with a third party controlled vocabulary to make it easier for applications to harmonize two or more PFB files.|True|False|[https://anvilproject.org/ncpi/technologies#portable-format-for-bioinformatics-pfb](https://anvilproject.org/ncpi/technologies#portable-format-for-bioinformatics-pfb)|[doi:10.1101/2022.07.19.500678](doi:10.1101/2022.07.19.500678)|[https://github.com/uc-cdis/pypfb](https://github.com/uc-cdis/pypfb)|[STANDARDSDATASTANDARDORTOOL:261](https://w3id.org/bridge2ai/standards-datastandardortool-schema/261)|[BiomedicalStandard](BiomedicalStandard)|PFB|Portable Format for Bioinformatics||
| guidelines|||An evidence-based minimum set of items for reporting in systematic reviews and meta-analyses.The aim of the PRISMA Statement is to help authors improve the reporting of systematic reviews and meta-analyses. We have focused on randomized trials, but PRISMA can also be used as a basis for reporting systematic reviews of other types of research, particularly evaluations of interventions. PRISMA may also be useful for critical appraisal of published systematic reviews, although it is not a quality assessment instrument to gauge the quality of a systematic review.|True|False|[https://www.prisma-statement.org/](https://www.prisma-statement.org/)|[doi:10.1136/bmj.n71](doi:10.1136/bmj.n71)||[STANDARDSDATASTANDARDORTOOL:262](https://w3id.org/bridge2ai/standards-datastandardortool-schema/262)|[BiomedicalStandard](BiomedicalStandard)|PRISMA|Preferred Reporting Items for Systematic Reviews and Meta-Analyses||
| fileformat| [STANDARDSDATATOPIC:27](STANDARDSDATATOPIC:27)| [STANDARDSORGANIZATION:82](STANDARDSORGANIZATION:82)|An exchange format for reporting experimentally determined three-dimensional structures of biological macromolecules that serves a global community of researchers, educators, and students. The data contained in the archive include atomic coordinates, bibliographic citations, primary and secondary structure, information, and crystallographic structure factors and NMR experimental data|True|False|[https://www.cgl.ucsf.edu/chimera/docs/UsersGuide/tutorials/pdbintro.html](https://www.cgl.ucsf.edu/chimera/docs/UsersGuide/tutorials/pdbintro.html)|||[STANDARDSDATASTANDARDORTOOL:263](https://w3id.org/bridge2ai/standards-datastandardortool-schema/263)|[BiomedicalStandard](BiomedicalStandard)|PDB|Protein Data Bank Format||
| fileformat| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|The work on PSI-PAR was initiated as part of the ProteomeBinders project and carried out by EMBL-EBI and the PSI-MI work group. The Proteomics Standards Initiative (PSI) aims to define community standards for data representation in proteomics to facilitate data comparison, exchange and verification. For detailed information on all PSI activities, please see PSI Home Page. The PSI-PAR format is a standardized means of representing protein affinity reagent data and is designed to facilitate the exchange of information between different databases and/or LIMS systems. PSI-PAR is not a proposed database structure. The PSI-PAR format consists of the PSI-MI XML2.5 schema (originally designed for molecular interactions) and the PSI-PAR controlled vocabulary. In addition, PSI-PAR documentation and examples are available on this web page. The scope of PSI-PAR is PAR and target protein production and characterization.|True|False|[https://www.psidev.info/psi-par](https://www.psidev.info/psi-par)|[doi:10.1074/mcp.M900185-MCP200](doi:10.1074/mcp.M900185-MCP200)||[STANDARDSDATASTANDARDORTOOL:264](https://w3id.org/bridge2ai/standards-datastandardortool-schema/264)|[BiomedicalStandard](BiomedicalStandard)|PSI-PAR|Proteomics Standards Initiative Protein Affinity Reagent format||
| fileformat| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|GelML is a data exchange format for describing the results of gel electrophoresis experiments. GelML is developed as a HUPO-PSI working group.|True|False|[https://www.psidev.info/gelml/1.0](https://www.psidev.info/gelml/1.0)|||[STANDARDSDATASTANDARDORTOOL:265](https://w3id.org/bridge2ai/standards-datastandardortool-schema/265)|[BiomedicalStandard](BiomedicalStandard)|PSI GelML|PSI GelML||
| fileformat| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|The PSI-MI XML 2.5 is a community standard for molecular interactions which has been jointly developed by major data providers (BIND, CellZome, DIP, GSK, HPRD, Hybrigenics, IntAct, MINT, MIPS, Serono, U. Bielefeld, U. Bordeaux, U. Cambridge, and others).This format is stable and used for several years now - published in October 2007 (Broadening the Horizon Ð Level 2.5 of the HUPO-PSI Format for Molecular Interactions; Samuel Kerrien et al. BioMed Central. 2007.), it has been adapted for many different usages. It can be used for storing any kind of molecular interaction data - complexes and binary interactions not only protein-protein interactions, can describe nucleic acids interactions and others hierarchical complexes modelling by using interactionRef in participants instead of an interactor Data representation in PSI-MI 2.5 XML relies heavily on the use of controlled vocabularies. They can be accessed easily via the Ontology Lookup Service, PSI-MI, PSI-MOD.|True|False|[https://www.psidev.info/mif](https://www.psidev.info/mif)|||[STANDARDSDATASTANDARDORTOOL:266](https://w3id.org/bridge2ai/standards-datastandardortool-schema/266)|[BiomedicalStandard](BiomedicalStandard)|PSI-MI XML|PSI-MI XML||
| fileformat| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)||An XML format for quality-related data of mass spectrometry and other high-throughput experiments. Quality control is increasingly recognized as a crucial aspect of mass spectrometry based proteomics. Several recent papers discuss relevant parameters for quality control and present applications to extract these from the instrumental raw data. What has been missing, however, is a standard data exchange format for reporting these performance metrics. We therefore developed the qcML format, an XML-based standard that follows the design principles of the related mzML, mzIdentML, mzQuantML, and TraML standards from the HUPO-PSI (Proteomics Standards Initiative). In addition to the XML format, we also provide tools for the calculation of a wide range of quality metrics as well as a database format and interconversion tools, so that existing LIMS systems can easily add relational storage of the quality control data to their existing schema. We here describe the qcML specification, along with possible use cases and an illustrative example of the subsequent analysis possibilities. All information about qcML is available at http://code.google.com/p/qcml|True|False||[doi:10.1074/mcp.M113.035907](doi:10.1074/mcp.M113.035907)||[STANDARDSDATASTANDARDORTOOL:267](https://w3id.org/bridge2ai/standards-datastandardortool-schema/267)|[BiomedicalStandard](BiomedicalStandard)|qcML|qcML format||
| markuplanguage| [STANDARDSDATATOPIC:33](STANDARDSDATATOPIC:33)||The RDML file format is developed by the RDML consortium (http://www.rdml.org) and can be used free of charge. The RDML file format was created to encourage the exchange, publication, revision and re-analysis of raw qPCR data. The core of an RDML file is an experiment, not a PCR run. Therefore all the information is collected which is required to understand an experiment. The structure of the file format was inspired by a database structure. In the file are several master elements, which are then referred to in other parts of the file. This structure allows to reduce the amount of redundant information and encourages the user to provide useful information. The Real-time PCR Data Markup Language (RDML) is a structured and universal data standard for exchanging quantitative PCR (qPCR) data. The data standard should contain sufficient information to understand the experimental setup, re-analyse the data and interpret the results. The data standard is a compressed text file in Extensible Markup Language (XML) and enables transparent exchange of annotated qPCR data between instrument software and third-party data analysis packages, between colleagues and collaborators, and between authors, peer reviewers, journals and readers. To support the public acceptance of this standard, both an on-line RDML file generator is available for end users, as well as RDML software libraries to be used by software developers, enabling import and export of RDML data files.|True|False|[http://www.rdml.org](http://www.rdml.org)|||[STANDARDSDATASTANDARDORTOOL:268](https://w3id.org/bridge2ai/standards-datastandardortool-schema/268)|[BiomedicalStandard](BiomedicalStandard)|RDML|Real-time PCR Data Markup Language||
| guidelines|||REFLECT stands for Reporting guidElines For randomized controLled trials for livEstoCk and food safeTy. It is an evidence-based minimum set of items for trials reporting production, health, and food-safety outcomes.The aim of the REFLECT Statement is to help authors improve the reporting livestock trials with production, health, and food-safety outcomes. We have focused on both types of randomized trials, field trials and challenge studies in livestock, and the interventions may be therapeutic or preventive. The REFLECT Statement consists of a 22-item checklist (MS Word version ; PDF word version). It is an evolving document that is subject to change periodically as new evidence emerges. This website contains the current definitive version of the REFLECT Statement.|True|False|[https://meridian.cvm.iastate.edu/reflect/](https://meridian.cvm.iastate.edu/reflect/)|[doi:10.4315/0362-028x-73.3.579](doi:10.4315/0362-028x-73.3.579)||[STANDARDSDATASTANDARDORTOOL:269](https://w3id.org/bridge2ai/standards-datastandardortool-schema/269)|[BiomedicalStandard](BiomedicalStandard)|REFLECT|Reporting guidelines for randomized controlled trials for livestock and food safety||
| guidelines|||Despite years of research and hundreds of reports on tumor markers in oncology, the number of markers that have emerged as clinically useful is pitifully small. Often initially reported studies of a marker show great promise, but subsequent studies on the same or related markers yield inconsistent conclusions or stand in direct contradiction to the promising results. It is imperative that we attempt to understand the reasons why multiple studies of the same marker lead to differing conclusions. A variety of methodological problems have been cited to explain these discrepancies. Unfortunately, many tumor marker studies have not been reported in a rigorous fashion, and published articles often lack sufficient information to allow adequate assessment of the quality of the study or the generalizability of study results. The development of guidelines for the reporting of tumor marker studies was a major recommendation of the National Cancer Institute-European Organisation for Research and Treatment of Cancer (NCI-EORTC) First International Meeting on Cancer Diagnostics in 2000. As for the successful CONSORT initiative for randomized trials and for the STARD statement for diagnostic studies, we suggest guidelines to provide relevant information about the study design, preplanned hypotheses, patient and specimen characteristics, assay methods, and statistical analysis methods. In addition, the guidelines provide helpful suggestions on how to present data and important elements to include in discussions. The goal of these guidelines is to encourage transparent and complete reporting so that the relevant information will be available to others to help them to judge the usefulness of the data and understand the context in which the conclusions apply.|True|False|[https://www.equator-network.org/reporting-guidelines/reporting-recommendations-for-tumour-marker-prognostic-studies-remark/](https://www.equator-network.org/reporting-guidelines/reporting-recommendations-for-tumour-marker-prognostic-studies-remark/)|[doi:10.1038/sj.bjc.6602678](doi:10.1038/sj.bjc.6602678)|[https://www.equator-network.org/wp-content/uploads/2016/10/REMARK-checklist-for-EQUATOR-website-002.docx](https://www.equator-network.org/wp-content/uploads/2016/10/REMARK-checklist-for-EQUATOR-website-002.docx)|[STANDARDSDATASTANDARDORTOOL:270](https://w3id.org/bridge2ai/standards-datastandardortool-schema/270)|[BiomedicalStandard](BiomedicalStandard)|REMARK|Reporting recommendations for tumour Marker prognostic studies||
|| [STANDARDSDATATOPIC:31](STANDARDSDATATOPIC:31)||A common schema that encodes how the different elements of assessment data and / or the metadata relate to one another.|True|False|[https://www.repronim.org/reproschema/](https://www.repronim.org/reproschema/)||[https://github.com/ReproNim/reproschema](https://github.com/ReproNim/reproschema)|[STANDARDSDATASTANDARDORTOOL:271](https://w3id.org/bridge2ai/standards-datastandardortool-schema/271)|[BiomedicalStandard](BiomedicalStandard)|ReproSchema|ReproSchema||
| datamodel| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [Sentinel](Sentinel)|A standard data structure that allows Sentinel Data Partners to quickly execute distributed programs against local data.|True|False|[https://www.sentinelinitiative.org/methods-data-tools/sentinel-common-data-model](https://www.sentinelinitiative.org/methods-data-tools/sentinel-common-data-model)||[https://dev.sentinelsystem.org/projects/SCDM/repos/sentinel_common_data_model/browse](https://dev.sentinelsystem.org/projects/SCDM/repos/sentinel_common_data_model/browse)|[STANDARDSDATASTANDARDORTOOL:272](https://w3id.org/bridge2ai/standards-datastandardortool-schema/272)|[BiomedicalStandard](BiomedicalStandard)|SCDM|Sentinel Common Data Model||
| fileformat|||The Sequence Alignment/Map (SAM) format is a TAB-delimited text format consisting of a header section, which is optional, and an alignment section.|True|False|[http://samtools.sourceforge.net/](http://samtools.sourceforge.net/)|[doi:10.1093/bioinformatics/btp352](doi:10.1093/bioinformatics/btp352)||[STANDARDSDATASTANDARDORTOOL:273](https://w3id.org/bridge2ai/standards-datastandardortool-schema/273)|[BiomedicalStandard](BiomedicalStandard)|SAM|Sequence Alignment/Map Format||
| datamodel| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:33](STANDARDSDATATOPIC:33)| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|Used by The Sequence Read Archive (SRA) and the European Nucleotide Archive (ENA) to store raw sequencing data from the next generation of sequencing platforms including Roche 454 GS System, Illumina Genome Analyzer, Applied Biosystems SOLiD System, Helicos Heliscope, Complete Genomics, and Pacific Biosciences SMRT.|True|False|[https://www.ncbi.nlm.nih.gov/sra/docs/submitmeta/](https://www.ncbi.nlm.nih.gov/sra/docs/submitmeta/)|[doi:10.1093/nar/gkq1019](doi:10.1093/nar/gkq1019)||[STANDARDSDATASTANDARDORTOOL:274](https://w3id.org/bridge2ai/standards-datastandardortool-schema/274)|[BiomedicalStandard](BiomedicalStandard)|SRA-XML|Sequence Read Archive Metadata XML||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Simple Omnibus Format in Text (SOFT) is designed for rapid batch submission (and download) of data. SOFT is a simple line-based, plain text format, meaning that SOFT files may be readily generated from common spreadsheet and database applications. A single SOFT file can hold both data tables and accompanying descriptive information for multiple, concatenated Platforms, Samples, and/or Series records.|True|False|[https://www.ncbi.nlm.nih.gov/geo/info/soft-seq.html](https://www.ncbi.nlm.nih.gov/geo/info/soft-seq.html)|||[STANDARDSDATASTANDARDORTOOL:275](https://w3id.org/bridge2ai/standards-datastandardortool-schema/275)|[BiomedicalStandard](BiomedicalStandard)|SOFT|Simple Omnibus Format in Text||
| fileformat| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)||A typographical line notation for specifying chemical structure.|True|False|[http://opensmiles.org/](http://opensmiles.org/)||[http://opensmiles.org/opensmiles.html](http://opensmiles.org/opensmiles.html)|[STANDARDSDATASTANDARDORTOOL:276](https://w3id.org/bridge2ai/standards-datastandardortool-schema/276)|[BiomedicalStandard](BiomedicalStandard)|SMILES|Simplified Molecular Input Line Entry Specification Format||
| markuplanguage| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||SED-ML is an XML-based format for encoding simulation setups, to ensure exchangeability and reproducibility of simulation experiments. It follows the requirements defined in the MIASE guidelines.|True|False|[https://sed-ml.org/](https://sed-ml.org/)|||[STANDARDSDATASTANDARDORTOOL:277](https://w3id.org/bridge2ai/standards-datastandardortool-schema/277)|[BiomedicalStandard](BiomedicalStandard)|SED-ML|Simulation Experiment Description Markup Language||
| datamodel| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|Sequence variant data model. Represents all variants as a sequence of four operations. Start at the boundary before the first nucleotide in the sequence S, advance P nucleotides, delete D nucleotides, then Insert the nucleotides in the string.|True|False||[doi:10.1093/bioinformatics/btz856](doi:10.1093/bioinformatics/btz856)||[STANDARDSDATASTANDARDORTOOL:278](https://w3id.org/bridge2ai/standards-datastandardortool-schema/278)|[BiomedicalStandard](BiomedicalStandard)|SPDI|SPDI data model||
|| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)||A new and more flexible data structure, named the Standard EEG Data Structure (SEDS), was proposed to meet the needs of both small-scale EEG data batch processing in single-site studies and large-scale EEG data sharing and analysis in single-/multisite studies (especially on cloud platforms).|False|False||[doi:10.1016/j.softx.2021.100933](doi:10.1016/j.softx.2021.100933)||[STANDARDSDATASTANDARDORTOOL:279](https://w3id.org/bridge2ai/standards-datastandardortool-schema/279)|[BiomedicalStandard](BiomedicalStandard)|SEDS|Standard EEG Data Structure||
| codesystem| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [ISBER](ISBER)|The ISBER Biospecimen Science Working Group has developed a SPREC that identifies and records the main pre-analytical factors that may have impact on the integrity of sampled clinical fluids and solid biospecimens and their simple derivatives during collection, processing and storage. SPREC comprises 7 elements for both fluid and solid samples, defining the sample and primary container type, periods of cold and warm ischemia, and subsequent handling steps including speed and temperature of centrifugation and final storage temperature. The ability to manage and track pre-analytical variations impacting biospecimen integrity is fundamental to the provision of high quality tissue samples for research, and the effective and efficient interconnectivity and interoperability between national and international Biobanks.|True|False|[https://www.isber.org/page/SPREC](https://www.isber.org/page/SPREC)|[doi:10.1089/bio.2017.0109](doi:10.1089/bio.2017.0109)||[STANDARDSDATASTANDARDORTOOL:280](https://w3id.org/bridge2ai/standards-datastandardortool-schema/280)|[BiomedicalStandard](BiomedicalStandard)|SPREC|Standard PREanalytical Code||
| guidelines|||The objective of the STARD initiative is to improve the accuracy and completeness of reporting of studies of diagnostic accuracy, to allow readers to assess the potential for bias in the study (internal validity) and to evaluate its generalisability (external validity).The STARD statement consist of a checklist of 25 items and recommends the use of a flow diagram which describe the design of the study and the flow of patients.|True|False|[https://www.equator-network.org/reporting-guidelines/stard/](https://www.equator-network.org/reporting-guidelines/stard/)|[doi:10.1136/bmjopen-2016-012799](doi:10.1136/bmjopen-2016-012799)||[STANDARDSDATASTANDARDORTOOL:281](https://w3id.org/bridge2ai/standards-datastandardortool-schema/281)|[BiomedicalStandard](BiomedicalStandard)|STARD|Standards for Reporting of Diagnostic Accuracy Studies||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)||A system for marking up features in a multiple alignment.|True|False|[https://sonnhammer.sbc.su.se/Stockholm.html](https://sonnhammer.sbc.su.se/Stockholm.html)|||[STANDARDSDATASTANDARDORTOOL:282](https://w3id.org/bridge2ai/standards-datastandardortool-schema/282)|[BiomedicalStandard](BiomedicalStandard)|Stockholm|Stockholm Multiple Alignment Format||
| guidelines|||Making sense of rapidly evolving evidence on genetic associations is crucial to making genuine advances in human genomics and the eventual integration of this information in the practice of medicine and public health. Assessment of the strengths and weaknesses of this evidence, and hence the ability to synthesize it, has been limited by inadequate reporting of results. The STrengthening the REporting of Genetic Association studies (STREGA) initiative builds on the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) Statement and provides additions to 12 of the 22 items on the STROBE checklist. The additions concern population stratification, genotyping errors, modelling haplotype variation, Hardy-Weinberg equilibrium, replication, selection of participants, rationale for choice of genes and variants, treatment effects in studying quantitative traits, statistical methods, relatedness, reporting of descriptive and outcome data, and the volume of data issues that are important to consider in genetic association studies. The STREGA recommendations do not prescribe or dictate how a genetic association study should be designed but seek to enhance the transparency of its reporting, regardless of choices made during design, conduct, or analysis.|True|False|[https://www.equator-network.org/reporting-guidelines/strobe-strega/](https://www.equator-network.org/reporting-guidelines/strobe-strega/)|[doi:10.1002/gepi.20410](doi:10.1002/gepi.20410)||[STANDARDSDATASTANDARDORTOOL:283](https://w3id.org/bridge2ai/standards-datastandardortool-schema/283)|[BiomedicalStandard](BiomedicalStandard)|STREGA|Strengthening the Reporting of Genetic Association studies||
| guidelines|| [STROBE](STROBE)|STROBE stands for an international, collaborative initiative of epidemiologists, methodologists, statisticians, researchers and journal editors involved in the conduct and dissemination of observational studies, with the common aim of STrengthening the Reporting of OBservational studies in Epidemiology. The STROBE Statement is being endorsed by a growing number of biomedical journals. Incomplete and inadequate reporting of research hampers the assessment of the strengths and weaknesses of the studies reported in the medical literature. Readers need to know what was planned (and what was not), what was done, what was found, and what the results mean. Recommendations on the reporting of studies that are endorsed by leading medical journals can improve the quality of reporting.Observational research comprises several study designs and many topic areas. We aimed to establish a checklist of items that should be included in articles reporting such research - the STROBE Statement. We considered it reasonable to initially restrict the recommendations to the three main analytical designs that are used in observational research - cohort, case-control, and cross-sectional studies. We want to provide guidance on how to report observational research well. Our recommendations are not prescriptions for designing or conducting studies. Also, the checklist is not an instrument to evaluate the quality of observational research.|True|False|[https://www.strobe-statement.org/](https://www.strobe-statement.org/)|[doi:10.1016/j.jclinepi.2007.11.008](doi:10.1016/j.jclinepi.2007.11.008)||[STANDARDSDATASTANDARDORTOOL:284](https://w3id.org/bridge2ai/standards-datastandardortool-schema/284)|[BiomedicalStandard](BiomedicalStandard)|STROBE|Strengthening the Reporting of Observational studies in Epidemiology||
| fileformat| [STANDARDSDATATOPIC:27](STANDARDSDATATOPIC:27)||SDF is one of a family of chemical-data file formats developed by MDL; it is intended especially for structural information. "SDF" stands for structure-data file, and SDF files actually wrap the molfile (MDL Molfile) format.|True|False|[https://en.wikipedia.org/wiki/Chemical_table_file#SDF](https://en.wikipedia.org/wiki/Chemical_table_file#SDF)|||[STANDARDSDATASTANDARDORTOOL:285](https://w3id.org/bridge2ai/standards-datastandardortool-schema/285)|[BiomedicalStandard](BiomedicalStandard)|SDF|Structure Data Format||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||The SummarizedExperiment container contains one or more assays, each represented by a matrix-like object of numeric or other mode. The rows typically represent genomic ranges of interest and the columns represent samples.|True|False|[https://bioconductor.org/packages/release/bioc/html/SummarizedExperiment.html](https://bioconductor.org/packages/release/bioc/html/SummarizedExperiment.html)||[https://github.com/Bioconductor/SummarizedExperiment](https://github.com/Bioconductor/SummarizedExperiment)|[STANDARDSDATASTANDARDORTOOL:286](https://w3id.org/bridge2ai/standards-datastandardortool-schema/286)|[BiomedicalStandard](BiomedicalStandard)|SummarizedExperiment|SummarizedExperiment container||
| markuplanguage| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)||Standard for in silico representation of genetic designs. SBOL is designed to allow synthetic biologists and genetic engineers to electronically exchange designs . Send and receive genetic designs to and from biofabrication centers. Facilitate storage of genetic designs in repositories Embed genetic designs in publications.|True|False|[https://sbolstandard.org/](https://sbolstandard.org/)||[https://sbolstandard.org/#specifications](https://sbolstandard.org/#specifications)|[STANDARDSDATASTANDARDORTOOL:287](https://w3id.org/bridge2ai/standards-datastandardortool-schema/287)|[BiomedicalStandard](BiomedicalStandard)|SBOL|Synthetic Biology Open Language||
|| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)||An effort to standardize the graphical notation used in maps of biological processes.|True|False|[https://sbgn.github.io/](https://sbgn.github.io/)|[doi:10.1038/nbt.1558](doi:10.1038/nbt.1558)|[https://sbgn.github.io/downloads/specifications/pd_level1_version2.pdf](https://sbgn.github.io/downloads/specifications/pd_level1_version2.pdf)|[STANDARDSDATASTANDARDORTOOL:288](https://w3id.org/bridge2ai/standards-datastandardortool-schema/288)|[BiomedicalStandard](BiomedicalStandard)|SBGN|Systems Biology Graphical Notation||
| markuplanguage| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)| [COMBINE](COMBINE)|The Systems Biology Markup Language (SBML) is a machine-readable exchange format for computational models of biological processes. Its strength is in representating phenomena at the scale of biochemical reactions, but it is not limited to that. By supporting SBML as an input and output format, different software tools can operate on the same representation of a model, removing chances for errors in translation and assuring a common starting point for analyses and simulations.|True|False|[http://sbml.org/](http://sbml.org/)|[doi:10.1515/jib-2017-0081](doi:10.1515/jib-2017-0081)||[STANDARDSDATASTANDARDORTOOL:289](https://w3id.org/bridge2ai/standards-datastandardortool-schema/289)|[BiomedicalStandard](BiomedicalStandard)|SBML|Systems Biology Markup Language||
| markuplanguage| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)||Systems Biology has benefited tremendously from the development and use of SBML, which is a markup language to specify models composed of molecular species, and their interactions (including reactions). SBML is a common format that many systems biology software understand and thus it has become the way in which models are shared and communicated. Despite the popularity of SBML, that has resulted in many models being available in electronic format, there is currently no standard way of communicating the results of the operations carried out with such models (e.g. simulations). Here we propose a new markup language which is complementary to SBML and which is intended to specify results from operations carried out on models SBRML. In fact, this markup language is useful also to communicate experimental data as long as it is possible to express the data in terms of a reference SBML model. Thus SBRML is a means of specifying quantitative results in the context of a systems biology model.|False|False|[https://sbrml.sourceforge.net/SBRML/Welcome.html](https://sbrml.sourceforge.net/SBRML/Welcome.html)|||[STANDARDSDATASTANDARDORTOOL:290](https://w3id.org/bridge2ai/standards-datastandardortool-schema/290)|[BiomedicalStandard](BiomedicalStandard)|SBRML|Systems Biology Results Markup Language||
| fileformat| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A tab-delimited genome position index file format. The format can handle individual chromosomes up to 512 Mbp (2^29 bases) in length.|True|False|[http://www.htslib.org/doc/tabix.html](http://www.htslib.org/doc/tabix.html)|[doi:10.1093/bioinformatics/btq671](doi:10.1093/bioinformatics/btq671)|[https://samtools.github.io/hts-specs/tabix.pdf](https://samtools.github.io/hts-specs/tabix.pdf)|[STANDARDSDATASTANDARDORTOOL:291](https://w3id.org/bridge2ai/standards-datastandardortool-schema/291)|[BiomedicalStandard](BiomedicalStandard)|Tabix|Tabix index file format||
| datamodel|| [STANDARDSORGANIZATION:93](STANDARDSORGANIZATION:93)|The development of an abstract model for a taxonomic concept, which can capture the various models represented and understood by the various data providers, is central to this project. This model is presented as an XML schema document that is proposed as a standard to allow exchange of data between different data models. It aims to capture data as understood by the data owners without distortion, and facilitate the query of different data resources according to the common schema model. The TCS schema was conceived to allow the representation of taxonomic concepts as defined in published taxonomic classifications, revisions and databases. As such, it specifies the structure for XML documents to be used for the transfer of defined concepts. Valid transfer documents may either explicitly detail the defining components of taxon concepts, transfer GUIDs referring to defined taxon concepts (if and when these are available) or a mixture of the two.|True|False|[http://www.tdwg.org/standards/117](http://www.tdwg.org/standards/117)||[https://github.com/tdwg/tcs](https://github.com/tdwg/tcs)|[STANDARDSDATASTANDARDORTOOL:292](https://w3id.org/bridge2ai/standards-datastandardortool-schema/292)|[BiomedicalStandard](BiomedicalStandard)|TCS|Taxonomic Concept Transfer Schema||
||| [STANDARDSORGANIZATION:93](STANDARDSORGANIZATION:93)|This document defines how TDWG standards should be presented. Each standard is a logical directory or folder containing two or more files - a cover page outlining basic meta data for the standard and one or more normative files specifying the standard itself. Rules are specified for the naming of standards and files. Human readable files should be in English, follow basic layout principles and be marked up in XHTML. The legal statements that all documents must contain are defined.|True|False|[http://www.tdwg.org/standards/147](http://www.tdwg.org/standards/147)|||[STANDARDSDATASTANDARDORTOOL:293](https://w3id.org/bridge2ai/standards-datastandardortool-schema/293)|[BiomedicalStandard](BiomedicalStandard)|TDWG SDS|Taxonomic Databases Working Group Standards Documentation Standard||
| fileformat| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)||ToxML is an open data exchange standard that allows the representation and communication of toxicological and related data in a well-structured electronic format.|True|False||[doi:10.1080/1062936X.2013.783506](doi:10.1080/1062936X.2013.783506)||[STANDARDSDATASTANDARDORTOOL:294](https://w3id.org/bridge2ai/standards-datastandardortool-schema/294)|[BiomedicalStandard](BiomedicalStandard)|ToxML|ToxML standard||
| guidelines|| [CDC](CDC)|Evidence-based public health decisions are based on evaluations of intervention studies with randomized and nonrandomized designs. Transparent reporting is crucial for assessing the validity and efficacy of these intervention studies, and, it facilitates synthesis of the findings for evidence-based recommendations. Therefore, the mission of the Transparent Reporting of Evaluations with Nonrandomized Designs (TREND) group is to improve the reporting standards of nonrandomized evaluations of behavioral and public health intervention|True|False|[https://www.cdc.gov/trendstatement/index.html](https://www.cdc.gov/trendstatement/index.html)|[doi:10.2105/ajph.94.3.361](doi:10.2105/ajph.94.3.361)|[https://www.cdc.gov/trendstatement/pdf/trendstatement_TREND_Checklist.pdf](https://www.cdc.gov/trendstatement/pdf/trendstatement_TREND_Checklist.pdf)|[STANDARDSDATASTANDARDORTOOL:295](https://w3id.org/bridge2ai/standards-datastandardortool-schema/295)|[BiomedicalStandard](BiomedicalStandard)|TREND|Transparent Reporting of Evaluations with Nonrandomized Designs||
||| [STANDARDSORGANIZATION:26](STANDARDSORGANIZATION:26)|Trusted Instant Messaging (TIM+) defines a protocol that facilitates real-time communication and incorporates secure messaging concepts to ensure information is transmitted securely between known, trusted entities both within and across enterprises. TIM+ will determine the availability or presence of trusted endpoints and support text-based communication and file transfers.|True|False|||[https://directtrust.app.box.com/s/p3vp3g4bv52cyi4nbpyfpdal6t7z2qdz](https://directtrust.app.box.com/s/p3vp3g4bv52cyi4nbpyfpdal6t7z2qdz)|[STANDARDSDATASTANDARDORTOOL:296](https://w3id.org/bridge2ai/standards-datastandardortool-schema/296)|[BiomedicalStandard](BiomedicalStandard)|TIM+|Trusted Instant Messaging Plus Applicability Statement||
| markuplanguage| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)||Originally developed as part of the FP7 Transatlantic Tumor Model Repositories project, TumorML has been developed as an XML-based domain-specific vocabulary that includes elements from existing vocabularies, to deal with storing and transmitting existing cancer models among research communities.|True|False||[doi:10.1145/2544063.2544064](doi:10.1145/2544063.2544064)||[STANDARDSDATASTANDARDORTOOL:297](https://w3id.org/bridge2ai/standards-datastandardortool-schema/297)|[BiomedicalStandard](BiomedicalStandard)|TumorML|TumorML standard||
| codesystem| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)| [STANDARDSORGANIZATION:31](STANDARDSORGANIZATION:31)|An alphanumeric identifier based on a substance's molecular structure and/or descriptive information.|True|False|[https://precision.fda.gov/uniisearch](https://precision.fda.gov/uniisearch)|||[STANDARDSDATASTANDARDORTOOL:298](https://w3id.org/bridge2ai/standards-datastandardortool-schema/298)|[BiomedicalStandard](BiomedicalStandard)|UNII|Unique Ingredient Identifiers||
| fileformat| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)||Variant Call Format (VCF) is a text file format (most likely stored in a compressed manner). It contains meta-information lines, a header line, and then data lines each containing information about a position in the genome.|True|False|[https://en.wikipedia.org/wiki/Variant_Call_Format](https://en.wikipedia.org/wiki/Variant_Call_Format)||[https://github.com/samtools/hts-specs](https://github.com/samtools/hts-specs)|[STANDARDSDATASTANDARDORTOOL:299](https://w3id.org/bridge2ai/standards-datastandardortool-schema/299)|[BiomedicalStandard](BiomedicalStandard)|VCF|Variant Call Format||
| fileformat|| [STANDARDSORGANIZATION:29](STANDARDSORGANIZATION:29)|A text format devised by Ensembl for the eponymous Variant Effect Predictor tool.|True|False|[https://useast.ensembl.org/info/docs/tools/vep/vep_formats.html](https://useast.ensembl.org/info/docs/tools/vep/vep_formats.html)|||[STANDARDSDATASTANDARDORTOOL:300](https://w3id.org/bridge2ai/standards-datastandardortool-schema/300)|[BiomedicalStandard](BiomedicalStandard)|VEP|Variant Effect Predictor format||
||| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|variant representation|True|False|[https://vrs.ga4gh.org/en/latest/index.html](https://vrs.ga4gh.org/en/latest/index.html)|[doi:10.1016/j.xgen.2021.100027](doi:10.1016/j.xgen.2021.100027)||[STANDARDSDATASTANDARDORTOOL:301](https://w3id.org/bridge2ai/standards-datastandardortool-schema/301)|[BiomedicalStandard](BiomedicalStandard)|VRS|Variation Representation Specification||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)||A Locus-specific Database (LSDB) describes the variants discovered on a single gene or members of a gene family and other related functional elements. LSDBs are curated by experts on their respective loci, and as such are typically the best resources of such information available. But LSDBs vary widely in format and completeness, making data integration and exchange among them difficult and time-consuming. To address these difficulties, the VarioML format has been developed for the full range of variation data use-cases, providing semantically well-defined components which can be easily composed to fit specific needs. Using VarioML, data owners can now efficiently enable the integration, federation, and exchange of their variant data. The discoverabiliaty, extensibility, and quality of variation data is immediately enhanced. Critical new avenues of research and knowledge discovery are opened, as data using the VarioML standard can be integrated with the global library of purely genetic data. VarioML is a central prerequisite for effective modelling of phenotype data and genotype-to-phenotype relationships. It removes the long-standing technical obstacles to the effective passing of variant data from discovery laboratories into the biomedical database world. Now all that is needed is the broad participation of the genotype-to-phenotype research community.|True|False|||[https://github.com/VarioML/VarioML](https://github.com/VarioML/VarioML)|[STANDARDSDATASTANDARDORTOOL:302](https://w3id.org/bridge2ai/standards-datastandardortool-schema/302)|[BiomedicalStandard](BiomedicalStandard)|VarioML|VarioML format||
||| [STANDARDSORGANIZATION:93](STANDARDSORGANIZATION:93)|TDWG vocabularies are a collection of standardized terms and their definitions. Vocabulary standards differ from other Biodiversity Information Standards (TDWG) standards in that they are likely to change more often over time as they evolve to meet the changing needs of the biodiversity informatics community. These changes may be incremental, making it impractical to apply the full TDWG standards process to every change. The TDWG Vocabulary Maintenance Specification details the categories of changes that can be made to a TDWG vocabulary standard, the mechanisms used to achieve those changes, and the entities that are responsible for shepherding those changes through the process.|True|False|[https://www.tdwg.org/standards/vms/](https://www.tdwg.org/standards/vms/)|||[STANDARDSDATASTANDARDORTOOL:303](https://w3id.org/bridge2ai/standards-datastandardortool-schema/303)|[BiomedicalStandard](BiomedicalStandard)|VMS|Vocabulary Maintenance Standard||
| diagnosticinstrument| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||A statistically robust Voice Handicap Index (VHI). An 85-item version of this instrument was administered to 65 consecutive patients seen in the Voice Clinic at Henry Ford Hospital. The data were subjected to measures of internal consistency reliability and the initial 85-item version was reduced to a 30-item final version. This final version was administered to 63 consecutive patients on two occasions in an attempt to assess test-retest stability, which proved to be strong. The findings of the latter analysis demonstrated that a change between two administrations of 18 points represents a significant shift in psychosocial function.|False|False||[doi:10.1044/1058-0360.0603.66](doi:10.1044/1058-0360.0603.66)||[STANDARDSDATASTANDARDORTOOL:304](https://w3id.org/bridge2ai/standards-datastandardortool-schema/304)|[BiomedicalStandard](BiomedicalStandard)|VHI|Voice Handicap Index||
||| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|Access to consistent, high-quality metadata is critical to finding, understanding, and reusing scientific data. This document describes a consensus among participating stakeholders in the Health Care and the Life Sciences domain on the description of datasets using the Resource Description Framework (RDF). This specification meets key functional requirements, reuses existing vocabularies to the extent that it is possible, and addresses elements of data description, versioning, provenance, discovery, exchange, query, and retrieval.|True|False|[https://www.w3.org/TR/hcls-dataset/](https://www.w3.org/TR/hcls-dataset/)|||[STANDARDSDATASTANDARDORTOOL:305](https://w3id.org/bridge2ai/standards-datastandardortool-schema/305)|[BiomedicalStandard](BiomedicalStandard)|HCLS|W3C HCLS Dataset Description||
| fileformat| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||Wiggle files and its bedgraph variant allow you to plot quantitative data as either shades of color (dense mode) or bars of varying height (full and pack mode) on the genome.|True|False|[https://genome.ucsc.edu/goldenPath/help/wiggle.html](https://genome.ucsc.edu/goldenPath/help/wiggle.html)|||[STANDARDSDATASTANDARDORTOOL:306](https://w3id.org/bridge2ai/standards-datastandardortool-schema/306)|[BiomedicalStandard](BiomedicalStandard)|WIG|Wiggle Format||
| audiovisual fileformat| [STANDARDSDATATOPIC:19](STANDARDSDATATOPIC:19)| [STANDARDSORGANIZATION:101](STANDARDSORGANIZATION:101)|A proprietary image format based on TIFF.|False|False|[https://openwetware.org/wiki/Dissecting_LSM_files](https://openwetware.org/wiki/Dissecting_LSM_files)|||[STANDARDSDATASTANDARDORTOOL:307](https://w3id.org/bridge2ai/standards-datastandardortool-schema/307)|[BiomedicalStandard](BiomedicalStandard)|LSM|Zeiss LSM series confocal microscope image||
| audiovisual| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)||Audio data compression scheme optimized for speech coding, adopted in October 1998 as the standard speech codec by 3GPP (3d Generation Partnership Project) and now widely used in GSM (Global System for Mobile Communications).|True|False|[https://www.loc.gov/preservation/digital/formats/fdd/fdd000254.shtml](https://www.loc.gov/preservation/digital/formats/fdd/fdd000254.shtml)|||[STANDARDSDATASTANDARDORTOOL:308](https://w3id.org/bridge2ai/standards-datastandardortool-schema/308)|[DataStandard](DataStandard)|AMR|Adaptive Multi-Rate Speech Codec||
| fileformat| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)||Mass spectra output format used by AB SCIEX intstruments.|False|False||[doi:10.1074/mcp.R112.019695](doi:10.1074/mcp.R112.019695)||[STANDARDSDATASTANDARDORTOOL:309](https://w3id.org/bridge2ai/standards-datastandardortool-schema/309)|[DataStandard](DataStandard)|WIFF|Analyst native acquisition file format||
| fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||Analyze 7.5 can store voxel-based volumes and consists of two files - One file with the actual data in a binary format with the filename extension .img and another file (header with filename extension .hdr) with information about the data such as voxel size and number of voxel in each dimension.|True|False|||[https://analyzedirect.com/documents/AD_AnalyzeImage75_File_Format.pdf](https://analyzedirect.com/documents/AD_AnalyzeImage75_File_Format.pdf)|[STANDARDSDATASTANDARDORTOOL:310](https://w3id.org/bridge2ai/standards-datastandardortool-schema/310)|[DataStandard](DataStandard)|HDR/IMG|Analyze file format||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:5](STANDARDSORGANIZATION:5)|A language-independent columnar memory format for flat and hierarchical data, organized for efficient analytic operations on modern hardware like CPUs and GPUs. The Arrow memory format also supports zero-copy reads for lightning-fast data access without serialization overhead.|True|False|[https://arrow.apache.org/](https://arrow.apache.org/)||[https://github.com/apache/arrow](https://github.com/apache/arrow)|[STANDARDSDATASTANDARDORTOOL:311](https://w3id.org/bridge2ai/standards-datastandardortool-schema/311)|[DataStandard](DataStandard)|Arrow|Apache Arrow||
| fileformat|| [STANDARDSORGANIZATION:5](STANDARDSORGANIZATION:5)|Avro is a row-oriented remote procedure call and data serialization framework developed within Apache's Hadoop project. It uses JSON for defining data types and protocols, and serializes data in a compact binary format.|True|False|[https://avro.apache.org/](https://avro.apache.org/)||[https://github.com/apache/avro](https://github.com/apache/avro)|[STANDARDSDATASTANDARDORTOOL:312](https://w3id.org/bridge2ai/standards-datastandardortool-schema/312)|[DataStandard](DataStandard)|Avro|Apache Avro||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|ADMS is a profile of DCAT, used to describe semantic assets (or just 'Assets'), defined as highly reusable metadata (e.g. xml schemata, generic data models) and reference data (e.g. code lists, taxonomies, dictionaries, vocabularies) that are used for eGovernment system development.|True|False|[https://www.w3.org/TR/vocab-adms/](https://www.w3.org/TR/vocab-adms/)|||[STANDARDSDATASTANDARDORTOOL:313](https://w3id.org/bridge2ai/standards-datastandardortool-schema/313)|[DataStandard](DataStandard)|ADMS|Asset Description Metadata Schema||
| audiovisual fileformat| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)||File format for sound that wraps various sound bitstreams, ranging from uncompressed waveform to MIDI.|True|False|[https://www.loc.gov/preservation/digital/formats/fdd/fdd000005.shtml](https://www.loc.gov/preservation/digital/formats/fdd/fdd000005.shtml)|||[STANDARDSDATASTANDARDORTOOL:314](https://w3id.org/bridge2ai/standards-datastandardortool-schema/314)|[DataStandard](DataStandard)|AIFF|Audio Interchange File Format||
| audiovisual fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15) [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)||AVI files can contain both audio and video data in a file container that allows synchronous audio-with-video playback.|True|False|[https://en.wikipedia.org/wiki/Audio_Video_Interleave](https://en.wikipedia.org/wiki/Audio_Video_Interleave)|||[STANDARDSDATASTANDARDORTOOL:315](https://w3id.org/bridge2ai/standards-datastandardortool-schema/315)|[DataStandard](DataStandard)|AVI|Audio Video Interleave digital multimedia container format||
| audiovisual fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||A bitmap image format.|True|False|[https://en.wikipedia.org/wiki/BMP_file_format](https://en.wikipedia.org/wiki/BMP_file_format)|||[STANDARDSDATASTANDARDORTOOL:316](https://w3id.org/bridge2ai/standards-datastandardortool-schema/316)|[DataStandard](DataStandard)|BMP|Bitmap format||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Cap’n Proto is an insanely fast data interchange format and capability-based RPC system. Think JSON, except binary. Or think Protocol Buffers, except faster.|True|False|[https://capnproto.org/](https://capnproto.org/)||[https://github.com/capnproto/capnproto](https://github.com/capnproto/capnproto)|[STANDARDSDATASTANDARDORTOOL:317](https://w3id.org/bridge2ai/standards-datastandardortool-schema/317)|[DataStandard](DataStandard)|Cap'n'Proto|Cap'n'Proto||
| markuplanguage| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||CellML language is an open standard based on the XML markup language. CellML is being developed by the Auckland Bioengineering Institute at the University of Auckland and affiliated research groups. The purpose of CellML is to store and exchange computer-based mathematical models. CellML allows scientists to share models even if they are using different model-building software. It also enables them to reuse components from one model in another, thus accelerating model building.|True|False|[https://www.cellml.org/](https://www.cellml.org/)|[doi:10.1186/1471-2105-11-178](doi:10.1186/1471-2105-11-178)||[STANDARDSDATASTANDARDORTOOL:318](https://w3id.org/bridge2ai/standards-datastandardortool-schema/318)|[DataStandard](DataStandard)|CellML|CellML language||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A file format for providing citation metadata for software or datasets in plaintext files that are easy to read by both humans and machines.|True|False|[https://citation-file-format.github.io/](https://citation-file-format.github.io/)||[https://github.com/citation-file-format/citation-file-format](https://github.com/citation-file-format/citation-file-format)|[STANDARDSDATASTANDARDORTOOL:319](https://w3id.org/bridge2ai/standards-datastandardortool-schema/319)|[DataStandard](DataStandard)|CFF|citation-file-format||
| workflowlanguage|||specification for describing data analysis workflows and tools|True|False|[https://www.commonwl.org/](https://www.commonwl.org/)|[doi:10.48550/arXiv.2105.07028](doi:10.48550/arXiv.2105.07028)|[https://github.com/common-workflow-language/common-workflow-language](https://github.com/common-workflow-language/common-workflow-language)|[STANDARDSDATASTANDARDORTOOL:320](https://w3id.org/bridge2ai/standards-datastandardortool-schema/320)|[DataStandard](DataStandard)|CWL|Common Workflow Language||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||The CURATE(D) steps are a teaching and representation tool. This model is useful for onboarding data curators and orienting researchers preparing to share their data. It serves as a demonstration for the type of work involved in robust data curation, and was created to fit within institution-specific data repository workflows.|True|False|[https://datacurationnetwork.org/outputs/workflows/](https://datacurationnetwork.org/outputs/workflows/)||[https://docs.google.com/document/d/1RWt2obXOOeJRRFmVo9VAkl4h41cL33Zm5YYny3hbPZ8/edit](https://docs.google.com/document/d/1RWt2obXOOeJRRFmVo9VAkl4h41cL33Zm5YYny3hbPZ8/edit)|[STANDARDSDATASTANDARDORTOOL:321](https://w3id.org/bridge2ai/standards-datastandardortool-schema/321)|[DataStandard](DataStandard)|CURATE(D)|CURATE(D) Checklists||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:22](STANDARDSORGANIZATION:22)|Reference guide for processes, best practices, and principles in data management.|False|True|[https://www.dama.org/cpages/body-of-knowledge](https://www.dama.org/cpages/body-of-knowledge)|||[STANDARDSDATASTANDARDORTOOL:322](https://w3id.org/bridge2ai/standards-datastandardortool-schema/322)|[DataStandard](DataStandard)|DAMA-DMBOK|DAMA Data Management Body of Knowledge||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|An RDF vocabulary designed to facilitate interoperability between data catalogs published on the Web.|True|False|[https://www.w3.org/TR/vocab-dcat-1/](https://www.w3.org/TR/vocab-dcat-1/)|||[STANDARDSDATASTANDARDORTOOL:323](https://w3id.org/bridge2ai/standards-datastandardortool-schema/323)|[DataStandard](DataStandard)|DCAT|Data Catalog Vocabulary||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||The DataCite Metadata Schema is a list of core metadata properties chosen for the accurate and consistent identification of a resource for citation and retrieval purposes, along with recommended use instructions. The resource that is being identified can be of any kind, but it is typically a dataset. We use the term ‘dataset’ in its broadest sense. We mean it to include not only numerical data, but any other research data outputs.|True|False|[https://schema.datacite.org/](https://schema.datacite.org/)||[https://schema.datacite.org/meta/kernel-4.3/metadata.xsd](https://schema.datacite.org/meta/kernel-4.3/metadata.xsd)|[STANDARDSDATASTANDARDORTOOL:324](https://w3id.org/bridge2ai/standards-datastandardortool-schema/324)|[DataStandard](DataStandard)|DataCite|DataCite Metadata Schema||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Describe datasets.|True|False|[https://huggingface.co/docs/datasets/dataset_card](https://huggingface.co/docs/datasets/dataset_card)|||[STANDARDSDATASTANDARDORTOOL:325](https://w3id.org/bridge2ai/standards-datastandardortool-schema/325)|[DataStandard](DataStandard)|Dataset Cards|Dataset Cards||
| datasheets| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||...we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on.|True|False||[https://arxiv.org/abs/1803.09010](https://arxiv.org/abs/1803.09010)||[STANDARDSDATASTANDARDORTOOL:326](https://w3id.org/bridge2ai/standards-datastandardortool-schema/326)|[DataStandard](DataStandard)|Datasheets|Datasheets for Datasets||
| markuplanguage| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||eXtensible Graph Markup and Modeling Language is an XML application based on GML which is used for graph description. XGMML uses tags to describe nodes and edges of a graph. The purpose of XGMML is to make possible the exchange of graphs between differents authoring and browsing tools for graphs.|True|False|[http://xml.coverpages.org/xgmml.html](http://xml.coverpages.org/xgmml.html)|||[STANDARDSDATASTANDARDORTOOL:327](https://w3id.org/bridge2ai/standards-datastandardortool-schema/327)|[DataStandard](DataStandard)|XGMML|eXtensible Graph Markup and Modeling Language||
| guidelines| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:83](STANDARDSORGANIZATION:83)|Simple and research software appropriate goalposts to inform those who publish and/or preserve research software.|True|False|[https://www.rd-alliance.org/group/fair-research-software-fair4rs-wg/outcomes/fair-principles-research-software-fair4rs](https://www.rd-alliance.org/group/fair-research-software-fair4rs-wg/outcomes/fair-principles-research-software-fair4rs)|[doi:10.1038/s41597-022-01710-x](doi:10.1038/s41597-022-01710-x)||[STANDARDSDATASTANDARDORTOOL:328](https://w3id.org/bridge2ai/standards-datastandardortool-schema/328)|[DataStandard](DataStandard)|FAIR4RS|FAIR Principles for Research Software||
| codesystem deprecated|||FIPS codes are numbers which uniquely identify geographic areas. As of database version 55, FIPS has been merged with the Geographic Names Information System (GNIS).|True|False|||[https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt](https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt)|[STANDARDSDATASTANDARDORTOOL:329](https://w3id.org/bridge2ai/standards-datastandardortool-schema/329)|[DataStandard](DataStandard)|FIPS|Federal Information Processing System Codes for States and Counties||
| markuplanguage| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||FieldML is a declarative language for building hierarchical models represented by generalized mathematical fields. FieldML is developed as a data model and accompanying API. Find out more about the FieldML API, where to get the latest release and how to contribute to its development. FieldML is a declarative language for representing hierarchical models using generalized mathematical fields. FieldML can be used to represent the dynamic 3D geometry and solution fields from computational models of cells, tissues and organs. It enables model interchange for the bioengineering and general engineering analysis communities. Example uses are models of tissue structure, the distribution of proteins and other biochemical compounds, anatomical annotation, and other biological annotation.|True|False||[doi:10.1007/s11517-013-1097-7](doi:10.1007/s11517-013-1097-7)||[STANDARDSDATASTANDARDORTOOL:330](https://w3id.org/bridge2ai/standards-datastandardortool-schema/330)|[DataStandard](DataStandard)|FieldML|FieldML||
| audiovisual fileformat| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)||FLAC (Free Lossless Audio Codec) is an audio coding format for lossless compression of digital audio.|True|False|[https://en.wikipedia.org/wiki/FLAC](https://en.wikipedia.org/wiki/FLAC)||[https://xiph.org/flac/format.html](https://xiph.org/flac/format.html)|[STANDARDSDATASTANDARDORTOOL:331](https://w3id.org/bridge2ai/standards-datastandardortool-schema/331)|[DataStandard](DataStandard)|FLAC|Free Lossless Audio Codec||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Describe datasets.|True|False|[https://specs.frictionlessdata.io/data-package/](https://specs.frictionlessdata.io/data-package/)||[https://github.com/frictionlessdata/specs](https://github.com/frictionlessdata/specs)|[STANDARDSDATASTANDARDORTOOL:332](https://w3id.org/bridge2ai/standards-datastandardortool-schema/332)|[DataStandard](DataStandard)|Frictionless|Frictionless Data Package||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|Provides a way for an API to expose a set of metadata to help discovery and aggregation of services via computational methods.|True|False|[https://github.com/ga4gh-discovery/ga4gh-service-info](https://github.com/ga4gh-discovery/ga4gh-service-info)|||[STANDARDSDATASTANDARDORTOOL:333](https://w3id.org/bridge2ai/standards-datastandardortool-schema/333)|[DataStandard](DataStandard)|serviceinfo|GA4GH serviceinfo||
| workflowlanguage| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20)||A schema moving Galaxy's workflow description language toward standards such as the Common Workflow Language.|True|False|||[https://github.com/galaxyproject/gxformat2](https://github.com/galaxyproject/gxformat2)|[STANDARDSDATASTANDARDORTOOL:334](https://w3id.org/bridge2ai/standards-datastandardortool-schema/334)|[DataStandard](DataStandard)|gxformat2|Galaxy workflow Format 2||
|| [STANDARDSDATATOPIC:14](STANDARDSDATATOPIC:14)| [STANDARDSORGANIZATION:98](STANDARDSORGANIZATION:98)|The Geographic Names Information System (GNIS) is the Federal and national standard for geographic nomenclature. The U.S. Geological Survey's National Geospatial Program developed the GNIS in support of the U.S. Board on Geographic Names as the official repository of domestic geographic names data, the official vehicle for geographic names use by all departments of the Federal Government, and the source for applying geographic names to Federal electronic and printed products.|True|False|[https://www.usgs.gov/us-board-on-geographic-names/domestic-names](https://www.usgs.gov/us-board-on-geographic-names/domestic-names)||[https://www.usgs.gov/u.s.-board-on-geographic-names/download-gnis-data](https://www.usgs.gov/u.s.-board-on-geographic-names/download-gnis-data)|[STANDARDSDATASTANDARDORTOOL:335](https://w3id.org/bridge2ai/standards-datastandardortool-schema/335)|[DataStandard](DataStandard)|GNIS ID|Geographic Names Information System Feature IDs||
| codesystem| [STANDARDSDATATOPIC:6](STANDARDSDATATOPIC:6)||The GENC Standard specifies a profile of ISO 3166 codes for the representation of names of countries and their subdivisions.|True|False|[https://www.dni.gov/index.php/who-we-are/organizations/ic-cio/ic-cio-related-menus/ic-cio-related-links/ic-technical-specifications/geopolitical-entities-names-and-codes](https://www.dni.gov/index.php/who-we-are/organizations/ic-cio/ic-cio-related-menus/ic-cio-related-links/ic-technical-specifications/geopolitical-entities-names-and-codes)||[https://evs.nci.nih.gov/ftp1/GENC/](https://evs.nci.nih.gov/ftp1/GENC/)|[STANDARDSDATASTANDARDORTOOL:336](https://w3id.org/bridge2ai/standards-datastandardortool-schema/336)|[DataStandard](DataStandard)|GENC|Geopolitical Entities, Names, and Codes||
| fileformat markuplanguage| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||An XML file format and language for describing graphs.|True|False|[http://graphml.graphdrawing.org/specification.html](http://graphml.graphdrawing.org/specification.html)|||[STANDARDSDATASTANDARDORTOOL:337](https://w3id.org/bridge2ai/standards-datastandardortool-schema/337)|[DataStandard](DataStandard)|GraphML|Graph Markup Language||
| fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||A bitmap image format.|True|False|[https://en.wikipedia.org/wiki/GIF](https://en.wikipedia.org/wiki/GIF)|||[STANDARDSDATASTANDARDORTOOL:338](https://w3id.org/bridge2ai/standards-datastandardortool-schema/338)|[DataStandard](DataStandard)|GIF|Graphics Interchange Format||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||HDF5 is a data model, library, and file format for storing and managing data. It supports an unlimited variety of datatypes, and is designed for flexible and efficient I/O and for high volume and complex data. HDF5 is portable and is extensible, allowing applications to evolve in their use of HDF5. The HDF5 Technology suite includes tools and applications for managing, manipulating, viewing, and analyzing data in the HDF5 format.|True|False|[https://www.hdfgroup.org/solutions/hdf5/](https://www.hdfgroup.org/solutions/hdf5/)|||[STANDARDSDATASTANDARDORTOOL:339](https://w3id.org/bridge2ai/standards-datastandardortool-schema/339)|[DataStandard](DataStandard)|HDF5|HDF5 format||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||HDF5 is a data model, library, and file format for storing and managing data. It supports an unlimited variety of datatypes, and is designed for flexible and efficient I/O and for high volume and complex data. HDF5 is portable and is extensible, allowing applications to evolve in their use of HDF5. The HDF5 Technology suite includes tools and applications for managing, manipulating, viewing, and analyzing data in the HDF5 format.|True|False|[https://hdmf-common-schema.readthedocs.io/en/latest/format.html](https://hdmf-common-schema.readthedocs.io/en/latest/format.html)|[doi:10.1109/bigdata47090.2019.9005648](doi:10.1109/bigdata47090.2019.9005648)|[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8500680/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8500680/)|[STANDARDSDATASTANDARDORTOOL:340](https://w3id.org/bridge2ai/standards-datastandardortool-schema/340)|[DataStandard](DataStandard)|HDMF|HDMF format||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:47](STANDARDSORGANIZATION:47)|General-purpose ISA-Tab file format - an extensible, hierarchical structure that focuses on the description of the experimental metadata (i.e. sample characteristics, technology and measurement types, sample-to-data relationships).|True|False|[https://isa-specs.readthedocs.io/en/latest/isatab.html](https://isa-specs.readthedocs.io/en/latest/isatab.html)||[https://github.com/ISA-tools/ISAdatasets](https://github.com/ISA-tools/ISAdatasets)|[STANDARDSDATASTANDARDORTOOL:341](https://w3id.org/bridge2ai/standards-datastandardortool-schema/341)|[DataStandard](DataStandard)|ISA-Tab|ISA-Tab format||
| codesystem| [STANDARDSDATATOPIC:6](STANDARDSDATATOPIC:6)| [STANDARDSORGANIZATION:49](STANDARDSORGANIZATION:49)|The purpose of ISO 3166 is to define internationally recognized codes of letters and/or numbers that we can use when we refer to countries and their subdivisions. However, it does not define the names of countries – this information comes from United Nations sources (Terminology Bulletin Country Names and the Country and Region Codes for Statistical Use maintained by the United Nations Statistics Divisions).|True|False|[https://www.iso.org/iso-3166-country-codes.html](https://www.iso.org/iso-3166-country-codes.html)||[https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes](https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes)|[STANDARDSDATASTANDARDORTOOL:342](https://w3id.org/bridge2ai/standards-datastandardortool-schema/342)|[DataStandard](DataStandard)|ISO 3166|ISO 3166 Country Codes||
||| [STANDARDSORGANIZATION:49](STANDARDSORGANIZATION:49)|A way of presenting dates and times that is clearly defined and understandable to both people and machines.|True|False|[https://www.iso.org/iso-8601-date-and-time-format.html](https://www.iso.org/iso-8601-date-and-time-format.html)|||[STANDARDSDATASTANDARDORTOOL:343](https://w3id.org/bridge2ai/standards-datastandardortool-schema/343)|[DataStandard](DataStandard)|ISO 8601|ISO 8601 Date and time format||
| audiovisual fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||A method of lossy compression for digital images.|True|False|[https://en.wikipedia.org/wiki/JPEG](https://en.wikipedia.org/wiki/JPEG)|||[STANDARDSDATASTANDARDORTOOL:344](https://w3id.org/bridge2ai/standards-datastandardortool-schema/344)|[DataStandard](DataStandard)|JPEG|Joint Photographic Experts Group Format||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||JSON validation|True|False|[https://json-schema.org/](https://json-schema.org/)||[https://github.com/json-schema-org/json-schema-spec](https://github.com/json-schema-org/json-schema-spec)|[STANDARDSDATASTANDARDORTOOL:345](https://w3id.org/bridge2ai/standards-datastandardortool-schema/345)|[DataStandard](DataStandard)|JSON-schema|JSON-schema||
| fileformat| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||linked knowledge|True|False|[https://github.com/biolink/kgx/blob/master/specification/kgx-format.md](https://github.com/biolink/kgx/blob/master/specification/kgx-format.md)|||[STANDARDSDATASTANDARDORTOOL:346](https://w3id.org/bridge2ai/standards-datastandardortool-schema/346)|[DataStandard](DataStandard)|KGX|Knowledge Graph Exchange||
| markuplanguage| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||LinkML is a flexible modeling language that allows you to author schemas in YAML that describe the structure of your data. Additionally, it is a framework for working with and validating data in a variety of formats (JSON, RDF, TSV), with generators for compiling LinkML schemas to other frameworks.|True|False|[https://linkml.io/linkml](https://linkml.io/linkml)||[https://github.com/linkml/linkml](https://github.com/linkml/linkml)|[STANDARDSDATASTANDARDORTOOL:347](https://w3id.org/bridge2ai/standards-datastandardortool-schema/347)|[DataStandard](DataStandard)|LinkML|LinkML||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|A product of the W3C Math Working Group, MathML is a low-level specification for describing mathematics as a basis for machine to machine communication which provides a much needed foundation for the inclusion of mathematical expressions in Web pages. It is also important in publishing workflows for science and technology and wherever mathematics has to be handled by software.|True|False|[https://www.w3.org/Math/whatIsMathML.html](https://www.w3.org/Math/whatIsMathML.html)|||[STANDARDSDATASTANDARDORTOOL:348](https://w3id.org/bridge2ai/standards-datastandardortool-schema/348)|[DataStandard](DataStandard)|MathML|MathML||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:56](STANDARDSORGANIZATION:56)|Format used by Microsoft Excel spreadsheet software.|False|False|||[https://www.iso.org/standard/71691.html](https://www.iso.org/standard/71691.html)|[STANDARDSDATASTANDARDORTOOL:349](https://w3id.org/bridge2ai/standards-datastandardortool-schema/349)|[DataStandard](DataStandard)|xlsx|Microsoft Excel spreadsheet container file||
| modelcards| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:37](STANDARDSORGANIZATION:37)|Structured documentation detailing performance characteristics of machine learning models.|True|False|[https://modelcards.withgoogle.com/about](https://modelcards.withgoogle.com/about)|[https://arxiv.org/abs/1810.03993](https://arxiv.org/abs/1810.03993)|[https://github.com/tensorflow/model-card-toolkit/blob/master/model_card_toolkit/schema/v0.0.2/model_card.schema.json](https://github.com/tensorflow/model-card-toolkit/blob/master/model_card_toolkit/schema/v0.0.2/model_card.schema.json)|[STANDARDSDATASTANDARDORTOOL:350](https://w3id.org/bridge2ai/standards-datastandardortool-schema/350)|[DataStandard](DataStandard)|Model Cards|Model Cards||
| audiovisual fileformat| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)||MP3 (formally MPEG-1 Audio Layer III or MPEG-2 Audio Layer III) is a coding format for digital audio.|True|False|[https://en.wikipedia.org/wiki/MP3](https://en.wikipedia.org/wiki/MP3)||[https://www.iso.org/standard/26797.html](https://www.iso.org/standard/26797.html)|[STANDARDSDATASTANDARDORTOOL:351](https://w3id.org/bridge2ai/standards-datastandardortool-schema/351)|[DataStandard](DataStandard)|MP3|MPEG-1 Audio Layer 3 | MPEG-2 Audio Layer 3||
| audiovisual fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15) [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)| [STANDARDSORGANIZATION:49](STANDARDSORGANIZATION:49)|A digital multimedia container format most commonly used to store video and audio, but it can also be used to store other data such as subtitles and still images. Like most modern container formats, it allows streaming over the Internet.|True|False|[https://en.wikipedia.org/wiki/MP4_file_format](https://en.wikipedia.org/wiki/MP4_file_format)||[https://www.loc.gov/preservation/digital/formats/fdd/fdd000155.shtml](https://www.loc.gov/preservation/digital/formats/fdd/fdd000155.shtml)|[STANDARDSDATASTANDARDORTOOL:352](https://w3id.org/bridge2ai/standards-datastandardortool-schema/352)|[DataStandard](DataStandard)|MPEG-4|MPEG-4 Part 14 digital multimedia container format||
| fileformat|| [STANDARDSORGANIZATION:8](STANDARDSORGANIZATION:8)|A standardized format for chromatographic data representation.|True|False|[https://www.unidata.ucar.edu/software/netcdf/](https://www.unidata.ucar.edu/software/netcdf/)||[https://www.astm.org/e1947-98r14.html](https://www.astm.org/e1947-98r14.html)|[STANDARDSDATASTANDARDORTOOL:353](https://w3id.org/bridge2ai/standards-datastandardortool-schema/353)|[DataStandard](DataStandard)|netCDF|Network Common Data Form||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||An exchange format for neural network models produced using Torch, Caffe, TensorFlow, Theano, Chainer, Caffe2, PyTorch, or MXNet.|True|False|[https://www.khronos.org/nnef](https://www.khronos.org/nnef)||[https://github.com/KhronosGroup/NNEF-Tools](https://github.com/KhronosGroup/NNEF-Tools)|[STANDARDSDATASTANDARDORTOOL:354](https://w3id.org/bridge2ai/standards-datastandardortool-schema/354)|[DataStandard](DataStandard)|NNEF|Neural Network Exchange Format||
| markuplanguage| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:49](STANDARDSORGANIZATION:49)|This standard specifies an XML implementation for the OGC and ISO Observations and Measurements (O&M) conceptual model (OGC Observations and Measurements v2.0 also published as ISO/DIS 19156), including a schema for Sampling Features. This encoding is an essential dependency for the OGC Sensor Observation Service (SOS) Interface Standard. More specifically, this standard defines XML schemas for observations, and for features involved in sampling when making observations. These provide document models for the exchange of information describing observation acts and their results, both within and between different scientific and technical communities.|True|False|[https://www.ogc.org/standards/om](https://www.ogc.org/standards/om)|||[STANDARDSDATASTANDARDORTOOL:355](https://w3id.org/bridge2ai/standards-datastandardortool-schema/355)|[DataStandard](DataStandard)|OMXML|OGC and ISO Observations and Measurements standard in XML||
| audiovisual fileformat| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)||File format and bitstream encoding for for spoken content, targeted at a wide range of devices other than mobile phones.|True|False|[https://speex.org/docs/manual/speex-manual/node8.html](https://speex.org/docs/manual/speex-manual/node8.html)|||[STANDARDSDATASTANDARDORTOOL:356](https://w3id.org/bridge2ai/standards-datastandardortool-schema/356)|[DataStandard](DataStandard)|OGG Speex|Ogg Speex Audio Format||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||ONNX is an open format built to represent machine learning models.|True|False|[https://onnx.ai/](https://onnx.ai/)||[https://github.com/onnx/onnx/blob/main/docs/IR.md](https://github.com/onnx/onnx/blob/main/docs/IR.md)|[STANDARDSDATASTANDARDORTOOL:357](https://w3id.org/bridge2ai/standards-datastandardortool-schema/357)|[DataStandard](DataStandard)|ONNX|Open Neural Network Exchange||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Standard for describing program interfaces.|True|False|[https://spec.openapis.org/oas/latest.html](https://spec.openapis.org/oas/latest.html)||[https://github.com/OAI/OpenAPI-Specification/](https://github.com/OAI/OpenAPI-Specification/)|[STANDARDSDATASTANDARDORTOOL:358](https://w3id.org/bridge2ai/standards-datastandardortool-schema/358)|[DataStandard](DataStandard)|OpenAPI|OpenAPI Specification||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Apache Parquet is a free and open-source column-oriented data storage format in the Apache Hadoop ecosystem.|True|False|[https://parquet.apache.org/](https://parquet.apache.org/)|||[STANDARDSDATASTANDARDORTOOL:359](https://w3id.org/bridge2ai/standards-datastandardortool-schema/359)|[DataStandard](DataStandard)|parquet|Parquet||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [IA](IA)|PURLs are Web addresses or Uniform Resource Locators (URLs) that act as permanent identifiers in the face of a dynamic and changing Web infrastructure. Instead of resolving directly to Web resources (documents, data, services, people, etc.) PURLs provide a level of indirection that allows the underlying Web addresses of resources to change over time without negatively affecting systems that depend on them. This capability provides continuity of references to network resources that may migrate from machine to machine for business, social or technical reasons.|True|False|[https://sites.google.com/site/persistenturls/](https://sites.google.com/site/persistenturls/)||[https://code.google.com/archive/p/persistenturls/](https://code.google.com/archive/p/persistenturls/)|[STANDARDSDATASTANDARDORTOOL:360](https://w3id.org/bridge2ai/standards-datastandardortool-schema/360)|[DataStandard](DataStandard)|PURL|Persistent Uniform Resource Locator||
| fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15) [STANDARDSDATATOPIC:32](STANDARDSDATATOPIC:32)||A file format to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.|True|False|[https://en.wikipedia.org/wiki/PDF](https://en.wikipedia.org/wiki/PDF)|||[STANDARDSDATASTANDARDORTOOL:361](https://w3id.org/bridge2ai/standards-datastandardortool-schema/361)|[DataStandard](DataStandard)|PDF|Portable Document Format||
| audiovisual fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||A raster-graphics file format that supports lossless data compression.|True|False|[https://en.wikipedia.org/wiki/Portable_Network_Graphics](https://en.wikipedia.org/wiki/Portable_Network_Graphics)|||[STANDARDSDATASTANDARDORTOOL:362](https://w3id.org/bridge2ai/standards-datastandardortool-schema/362)|[DataStandard](DataStandard)|PNG|Portable Network Graphics||
| fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15) [STANDARDSDATATOPIC:32](STANDARDSDATATOPIC:32)||A page description language.|True|False|[https://en.wikipedia.org/wiki/PostScript](https://en.wikipedia.org/wiki/PostScript)|||[STANDARDSDATASTANDARDORTOOL:363](https://w3id.org/bridge2ai/standards-datastandardortool-schema/363)|[DataStandard](DataStandard)|PS|Postscript Format||
| markuplanguage| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||PMML (Predictive Model Markup Language) uses XML to represent mining models. The structure of the models is described by an XML Schema. One or more mining models can be contained in a PMML document. A PMML document is an XML document with a root element of type PMML|True|False|||[https://dmg.org/pmml/v4-4-1/GeneralStructure.html](https://dmg.org/pmml/v4-4-1/GeneralStructure.html)|[STANDARDSDATASTANDARDORTOOL:364](https://w3id.org/bridge2ai/standards-datastandardortool-schema/364)|[DataStandard](DataStandard)|PMML|Predictive Model Markup Language||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:37](STANDARDSORGANIZATION:37)|Protocol Buffers (a.k.a., protobuf) are Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data.|True|False|[https://developers.google.com/protocol-buffers/](https://developers.google.com/protocol-buffers/)||[https://github.com/protocolbuffers/protobuf](https://github.com/protocolbuffers/protobuf)|[STANDARDSDATASTANDARDORTOOL:365](https://w3id.org/bridge2ai/standards-datastandardortool-schema/365)|[DataStandard](DataStandard)|protobuf|Protocol Buffers||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|The PROV Family of Documents defines a model, corresponding serializations and other supporting definitions to enable the inter-operable interchange of provenance information in heterogeneous environments such as the Web.|True|False|[https://www.w3.org/TR/prov-overview/](https://www.w3.org/TR/prov-overview/)|||[STANDARDSDATASTANDARDORTOOL:366](https://w3id.org/bridge2ai/standards-datastandardortool-schema/366)|[DataStandard](DataStandard)|PROV|Provenance||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Serialization format for a Python object structure. “Pickling” is the process whereby a Python object hierarchy is converted into a byte stream, and “unpickling” is the inverse operation, whereby a byte stream (from a binary file or bytes-like object) is converted back into an object hierarchy.|True|False|[https://docs.python.org/3.8/library/pickle.html](https://docs.python.org/3.8/library/pickle.html)||[https://github.com/python/cpython/blob/3.8/Lib/pickle.py](https://github.com/python/cpython/blob/3.8/Lib/pickle.py)|[STANDARDSDATASTANDARDORTOOL:367](https://w3id.org/bridge2ai/standards-datastandardortool-schema/367)|[DataStandard](DataStandard)|pickle|Python pickle format||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [UKDA](UKDA)|The Qualitative Data Exchange Schema (QuDEx) allows users to discover, find, retrieve and cite complex qualitative data collections in context.|True|False|[https://www.data-archive.ac.uk/managing-data/standards-and-procedures/metadata-standards/qudex/](https://www.data-archive.ac.uk/managing-data/standards-and-procedures/metadata-standards/qudex/)||[https://dam.data-archive.ac.uk/standards/qudex_v03_01.xsd](https://dam.data-archive.ac.uk/standards/qudex_v03_01.xsd)|[STANDARDSDATASTANDARDORTOOL:368](https://w3id.org/bridge2ai/standards-datastandardortool-schema/368)|[DataStandard](DataStandard)|QuDEx|Qualitative Data Exchange Schema||
| guidelines| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [RDA](RDA)|A framework for implementing effective curation workflows for achieving greater FAIR-ness and long-term usability of research data and code.|True|False|[https://www.rd-alliance.org/group/cure-fair-wg/outcomes/10-things-curating-reproducible-and-fair-research](https://www.rd-alliance.org/group/cure-fair-wg/outcomes/10-things-curating-reproducible-and-fair-research)||[https://curating4reproducibility.org/10things/](https://curating4reproducibility.org/10things/)|[STANDARDSDATASTANDARDORTOOL:369](https://w3id.org/bridge2ai/standards-datastandardortool-schema/369)|[DataStandard](DataStandard)|RDA 10 Things|RDA CURE-FAIR 10 Things for Curating Reproducible and FAIR Research||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|RDF Schema (RDFS) is the RDF vocabulary description language. RDFS defines classes and properties that may be used to describe classes, properties and other resources.|True|False|[https://www.w3.org/TR/rdf-schema/](https://www.w3.org/TR/rdf-schema/)|||[STANDARDSDATASTANDARDORTOOL:370](https://w3id.org/bridge2ai/standards-datastandardortool-schema/370)|[DataStandard](DataStandard)|RDFS|RDF Schema||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [ARDC](ARDC)|The Registry Interchange Format - Collections and Services (RIF-CS) Schema was developed as a data interchange format for supporting the electronic exchange of collection and service descriptions. It organises information about collections and services into the format required by the ANDS Collections Registry.|True|False|[https://services.ands.org.au/documentation/rifcs/1.2.0/guidelines/rif-cs.html](https://services.ands.org.au/documentation/rifcs/1.2.0/guidelines/rif-cs.html)|||[STANDARDSDATASTANDARDORTOOL:371](https://w3id.org/bridge2ai/standards-datastandardortool-schema/371)|[DataStandard](DataStandard)|RIF-CS|Registry Interchange Format - Collections and Services schema||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A community effort to establish a lightweight approach to packaging research data with their metadata. It is based on schema.org annotations in JSON-LD, and aims to make best-practice in formal metadata description accessible and practical for use in a wider variety of situations, from an individual researcher working with a folder of data, to large data-intensive computational research environments.|True|False|[https://www.researchobject.org/ro-crate/](https://www.researchobject.org/ro-crate/)|[doi:10.3233/DS-210053](doi:10.3233/DS-210053)|[https://www.researchobject.org/ro-crate/specification.html](https://www.researchobject.org/ro-crate/specification.html)|[STANDARDSDATASTANDARDORTOOL:372](https://w3id.org/bridge2ai/standards-datastandardortool-schema/372)|[DataStandard](DataStandard)|RO-CRATE|Research Object Crate||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|describe anything|True|False|[https://www.w3.org/TR/rdf-schema/](https://www.w3.org/TR/rdf-schema/)|||[STANDARDSDATASTANDARDORTOOL:373](https://w3id.org/bridge2ai/standards-datastandardortool-schema/373)|[DataStandard](DataStandard)|RDF|Resource Description Framework||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A new simple format for storing tensors safely (as opposed to pickle) and that is still fast (zero-copy).|True|False|||[https://github.com/huggingface/safetensors](https://github.com/huggingface/safetensors)|[STANDARDSDATASTANDARDORTOOL:374](https://w3id.org/bridge2ai/standards-datastandardortool-schema/374)|[DataStandard](DataStandard)|Safetensors|Safetensors||
| audiovisual fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|Scalable Vector Graphics (SVG) Version 1.1, a modularized language for describing two-dimensional vector and mixed vector/raster graphics in XML.|True|False|[https://www.w3.org/Graphics/SVG/About.html](https://www.w3.org/Graphics/SVG/About.html)|||[STANDARDSDATASTANDARDORTOOL:375](https://w3id.org/bridge2ai/standards-datastandardortool-schema/375)|[DataStandard](DataStandard)|SVG|Scalable Vector Graphics Format||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|A language for validating RDF graphs against a set of conditions. These conditions are provided as shapes and other constructs expressed in the form of an RDF graph. RDF graphs that are used in this manner are called "shapes graphs" in SHACL and the RDF graphs that are validated against a shapes graph are called "data graphs". As SHACL shape graphs are used to validate that data graphs satisfy a set of conditions they can also be viewed as a description of the data graphs that do satisfy these conditions. Such descriptions may be used for a variety of purposes beside validation, including user interface building, code generation and data integration.|True|False|[https://www.w3.org/TR/shacl/](https://www.w3.org/TR/shacl/)|||[STANDARDSDATASTANDARDORTOOL:376](https://w3id.org/bridge2ai/standards-datastandardortool-schema/376)|[DataStandard](DataStandard)|SHACL|Shapes Constraint Language||
| audiovisual fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||A raster graphics file format.|True|False|[https://en.wikipedia.org/wiki/Silicon_Graphics_Image](https://en.wikipedia.org/wiki/Silicon_Graphics_Image)|||[STANDARDSDATASTANDARDORTOOL:377](https://w3id.org/bridge2ai/standards-datastandardortool-schema/377)|[DataStandard](DataStandard)|SGI|Silicon Graphics image format||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||SSSOM is a Simple Standard for Sharing Ontological Mappings, providing a TSV-based representation for ontology term mappings, a comprehensive set of standard metadata elements to describe mappings, and a standard translation between the TSV and the Web Ontology Language (OWL).|True|False|[https://mapping-commons.github.io/sssom/](https://mapping-commons.github.io/sssom/)|[doi:10.1093/database/baac035](doi:10.1093/database/baac035)|[https://github.com/mapping-commons/sssom](https://github.com/mapping-commons/sssom)|[STANDARDSDATASTANDARDORTOOL:378](https://w3id.org/bridge2ai/standards-datastandardortool-schema/378)|[DataStandard](DataStandard)|SSSOM|Simple Standard for Sharing Ontological Mappings||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Statismo defines a storage format (Statistical Image And Shape Models) based on HDF5, which includes all the information necessary to use the model, as well as meta-data about the model creation, which helps to make model building reproducible.|True|False|||[https://github.com/statismo/statismo](https://github.com/statismo/statismo)|[STANDARDSDATASTANDARDORTOOL:379](https://w3id.org/bridge2ai/standards-datastandardortool-schema/379)|[DataStandard](DataStandard)|statismo|Statismo format||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [SDMX](SDMX)|SDMX is an initiative to foster standards for the exchange of statistical information.|True|False|[https://sdmx.org/](https://sdmx.org/)|||[STANDARDSDATASTANDARDORTOOL:380](https://w3id.org/bridge2ai/standards-datastandardortool-schema/380)|[DataStandard](DataStandard)|SDMX|Statistical Data and Metadata eXchange standard||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||STL files describe only the surface geometry of a three-dimensional object without any representation of color, texture or other common CAD model attributes. The STL format specifies both ASCII and binary representations.|True|False|[https://www.loc.gov/preservation/digital/formats/fdd/fdd000504.shtml](https://www.loc.gov/preservation/digital/formats/fdd/fdd000504.shtml)|||[STANDARDSDATASTANDARDORTOOL:381](https://w3id.org/bridge2ai/standards-datastandardortool-schema/381)|[DataStandard](DataStandard)|STL|STereoLithography File Format Family||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:93](STANDARDSORGANIZATION:93)|The goal of the Structured Descriptive Data (SDD) standard is to allow capture, transport, caching and archiving of descriptive data in all the forms shown above, using a platform- and application-independent, international standard. Such a standard is crucial to enabling lossless porting of data between existing and future software platforms including identification, data-mining and analysis tools, and federated databases.|True|False|[https://www.tdwg.org/standards/sdd/](https://www.tdwg.org/standards/sdd/)||[https://github.com/tdwg/sdd](https://github.com/tdwg/sdd)|[STANDARDSDATASTANDARDORTOOL:382](https://w3id.org/bridge2ai/standards-datastandardortool-schema/382)|[DataStandard](DataStandard)|SDD|Structured Descriptive Data||
| audiovisual fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||An image file format for storing raster graphics images.|True|False|[https://en.wikipedia.org/wiki/TIFF](https://en.wikipedia.org/wiki/TIFF)|||[STANDARDSDATASTANDARDORTOOL:383](https://w3id.org/bridge2ai/standards-datastandardortool-schema/383)|[DataStandard](DataStandard)|TIFF|Tagged Image File Format||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A tar (tape archive) file format is an archive created by tar, a UNIX-based utility used to package files together for backup or distribution purposes. It contains multiple files (also known as a tarball) stored in an uncompressed format along with metadata about the archive. Tar files are not compressed archive files. They are often compressed with file compression utilities such as gzip or bzip2.|True|False|[https://www.loc.gov/preservation/digital/formats/fdd/fdd000531.shtml](https://www.loc.gov/preservation/digital/formats/fdd/fdd000531.shtml)|||[STANDARDSDATASTANDARDORTOOL:384](https://w3id.org/bridge2ai/standards-datastandardortool-schema/384)|[DataStandard](DataStandard)|TAR|TAR archive file format||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:93](STANDARDSORGANIZATION:93)|The TDWG Access Protocol for Information Retrieval (TAPIR) is a Web Service protocol and XML schema to perform queries across distributed databases of varied physical and logical structure. It was originally designed to be used by federated networks. TAPIR is intended for communication between applications, using HTTP as the transport mechanism. TAPIR's flexibility makes it suitable to both very simple service implementations where the provider only responds to a set of pre-defined queries, or more advanced implementations where the provider software can dynamically parse complex queries referencing output models supplied by the client.|True|False|[https://www.tdwg.org/standards/tapir/](https://www.tdwg.org/standards/tapir/)|||[STANDARDSDATASTANDARDORTOOL:385](https://w3id.org/bridge2ai/standards-datastandardortool-schema/385)|[DataStandard](DataStandard)|TAPIR|TDWG Access Protocol for Information Retrieval||
| codesystem| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [RI](RI)|A common syntax for communication of quantities and their units.|True|False|[https://unitsofmeasure.org/ucum](https://unitsofmeasure.org/ucum)|||[STANDARDSDATASTANDARDORTOOL:386](https://w3id.org/bridge2ai/standards-datastandardortool-schema/386)|[DataStandard](DataStandard)|UCUM|The Unified Code for Units of Measure||
| audiovisual fileformat| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)||Waveform Audio File Format (WAVE or WAV due to its filename extension is an audio file format standard.|True|False|[https://en.wikipedia.org/wiki/WAV](https://en.wikipedia.org/wiki/WAV)||[https://sites.google.com/site/musicgapi/technical-documents/wav-file-format](https://sites.google.com/site/musicgapi/technical-documents/wav-file-format)|[STANDARDSDATASTANDARDORTOOL:387](https://w3id.org/bridge2ai/standards-datastandardortool-schema/387)|[DataStandard](DataStandard)|WAV|Waveform Audio File Format||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|The Web Ontology Language (OWL) is a family of knowledge representation languages or ontology languages for authoring ontologies or knowledge bases. The languages are characterized by formal semantics and RDF/XML-based serializations for the Semantic Web. OWL is endorsed by the World Wide Web Consortium (W3C) and has attracted academic, medical and commercial interest. The OWL 2 Web Ontology Language, informally OWL 2, is an ontology language for the Semantic Web with formally defined meaning. OWL 2 ontologies provide classes, properties, individuals, and data values and are stored as Semantic Web documents. OWL 2 ontologies can be used along with information written in RDF, and OWL 2 ontologies themselves are primarily exchanged as RDF documents.|True|False|[https://www.w3.org/OWL/](https://www.w3.org/OWL/)|||[STANDARDSDATASTANDARDORTOOL:388](https://w3id.org/bridge2ai/standards-datastandardortool-schema/388)|[DataStandard](DataStandard)|OWL|Web Ontology Language||
| workflowlanguage|||The Workflow Description Language (WDL) is a way to specify data processing workflows with a human-readable and -writeable syntax. WDL makes it straightforward to define analysis tasks, chain them together in workflows, and parallelize their execution. The language makes common patterns simple to express, while also admitting uncommon or complicated behavior; and strives to achieve portability not only across execution platforms, but also different types of users. Whether one is an analyst, a programmer, an operator of a production system, or any other sort of user, WDL should be accessible and understandable.|True|False|[https://openwdl.org/](https://openwdl.org/)||[https://github.com/openwdl/wdl](https://github.com/openwdl/wdl)|[STANDARDSDATASTANDARDORTOOL:389](https://w3id.org/bridge2ai/standards-datastandardortool-schema/389)|[DataStandard](DataStandard)|WDL|Workflow Description Language||
| audiovisual deprecated fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||X PixMap (XBM) is an image file format used by the X Window System. Replaced by XPM.|True|False|[https://en.wikipedia.org/wiki/X_PixMap](https://en.wikipedia.org/wiki/X_PixMap)|||[STANDARDSDATASTANDARDORTOOL:390](https://w3id.org/bridge2ai/standards-datastandardortool-schema/390)|[DataStandard](DataStandard)|XBM|X PixMap bitmap image format||
| audiovisual fileformat| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||X PixMap (XPM) is an image file format used by the X Window System.|True|False|[https://en.wikipedia.org/wiki/X_PixMap](https://en.wikipedia.org/wiki/X_PixMap)|||[STANDARDSDATASTANDARDORTOOL:391](https://w3id.org/bridge2ai/standards-datastandardortool-schema/391)|[DataStandard](DataStandard)|XPM|X PixMap image format||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||An open source project and Python package that introduces labels in the form of dimensions, coordinates, and attributes on top of raw NumPy-like arrays, which allows for more intuitive, more concise, and less error-prone user experience.|True|False|[https://xarray.dev/](https://xarray.dev/)||[https://github.com/pydata/xarray](https://github.com/pydata/xarray)|[STANDARDSDATASTANDARDORTOOL:392](https://w3id.org/bridge2ai/standards-datastandardortool-schema/392)|[DataStandard](DataStandard)|xarray|xarray||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A human-readable data-serialization language. It is commonly used for configuration files and in applications where data is being stored or transmitted.|True|False|[https://en.wikipedia.org/wiki/YAML](https://en.wikipedia.org/wiki/YAML)|||[STANDARDSDATASTANDARDORTOOL:393](https://w3id.org/bridge2ai/standards-datastandardortool-schema/393)|[DataStandard](DataStandard)|YAML|YAML Ain't Markup Language||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A format for storage of large N-dimensional typed arrays. Has implementations in multiple programming languages.|True|False|[https://zarr.dev/](https://zarr.dev/)|||[STANDARDSDATASTANDARDORTOOL:394](https://w3id.org/bridge2ai/standards-datastandardortool-schema/394)|[DataStandard](DataStandard)|Zarr|Zarr||
| fileformat| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||An archive file format that supports lossless data compression.|True|False|[https://en.wikipedia.org/wiki/ZIP_(file_format)](https://en.wikipedia.org/wiki/ZIP_(file_format))|||[STANDARDSDATASTANDARDORTOOL:395](https://w3id.org/bridge2ai/standards-datastandardortool-schema/395)|[DataStandard](DataStandard)|ZIP|ZIP compressed file format||
|| [Model](Model)||Adapter refers to a set of newly introduced weights, typically within the layers of a transformer model. Adapters provide an alternative to fully fine-tuning the model for each downstream task, while maintaining performance. AdapterHub builds on the HuggingFace transformers framework, requiring as little as two additional lines of code to train adapters for a downstream task.|True|False|[https://adapterhub.ml/](https://adapterhub.ml/)|[doi:10.48550/arXiv.2007.07779](doi:10.48550/arXiv.2007.07779)|[https://github.com/adapter-hub/Hub](https://github.com/adapter-hub/Hub)|[STANDARDSDATASTANDARDORTOOL:396](https://w3id.org/bridge2ai/standards-datastandardortool-schema/396)|[ModelRepository](ModelRepository)|AdapterHub|AdapterHub||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||A community-driven, fully open resource where standardized pre-trained models can be shared, explored, tested, and downloaded for further adaptation or direct deployment in multiple end user-facing tools (e.g., ilastik, deepImageJ, QuPath, StarDist, ImJoy, ZeroCostDL4Mic, CSBDeep).|True|False|[https://bioimage.io/#/](https://bioimage.io/#/)|[doi:10.1101/2022.06.07.495102](doi:10.1101/2022.06.07.495102)|[https://github.com/bioimage-io/bioimage.io](https://github.com/bioimage-io/bioimage.io)|[STANDARDSDATASTANDARDORTOOL:397](https://w3id.org/bridge2ai/standards-datastandardortool-schema/397)|[ModelRepository](ModelRepository)|Bioimage|Bioimage Model Zoo||
| dataregistry| [Model](Model)||machine learning models, with focus on language models and NLP|True|False|[https://huggingface.co/models](https://huggingface.co/models)||[https://github.com/huggingface/huggingface_hub](https://github.com/huggingface/huggingface_hub)|[STANDARDSDATASTANDARDORTOOL:398](https://w3id.org/bridge2ai/standards-datastandardortool-schema/398)|[ModelRepository](ModelRepository)|HF Models|Hugging Face 🤗 Models||
|| [Model](Model)||machine learning models|True|False|[https://modelzoo.co/](https://modelzoo.co/)|||[STANDARDSDATASTANDARDORTOOL:399](https://w3id.org/bridge2ai/standards-datastandardortool-schema/399)|[ModelRepository](ModelRepository)|modelzoo.co|Model Zoo||
| dataregistry| [Model](Model)||OpenML is an open platform for sharing datasets, algorithms, and experiments|True|True|[https://www.openml.org/](https://www.openml.org/)||[https://github.com/openml/OpenML](https://github.com/openml/OpenML)|[STANDARDSDATASTANDARDORTOOL:400](https://w3id.org/bridge2ai/standards-datastandardortool-schema/400)|[ModelRepository](ModelRepository)|OpenML|OpenML||
|| [Model](Model)||machine learning models|True|False|[https://pytorch.org/hub/](https://pytorch.org/hub/)||[https://github.com/pytorch/hub](https://github.com/pytorch/hub)|[STANDARDSDATASTANDARDORTOOL:401](https://w3id.org/bridge2ai/standards-datastandardortool-schema/401)|[ModelRepository](ModelRepository)|PyTorch Hub|PyTorch Hub||
|| [Model](Model)| [STANDARDSORGANIZATION:37](STANDARDSORGANIZATION:37)|machine learning models|True|False|[https://tfhub.dev/](https://tfhub.dev/)|||[STANDARDSDATASTANDARDORTOOL:402](https://w3id.org/bridge2ai/standards-datastandardortool-schema/402)|[ModelRepository](ModelRepository)|TFHub|Tensorflow Hub||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [ASA](ASA) [STANDARDSORGANIZATION:4](STANDARDSORGANIZATION:4)|Definitions for terms used in human bioacoustics.|False|True|[https://webstore.ansi.org/Standards/ASA/ANSIASAS3202015R2020](https://webstore.ansi.org/Standards/ASA/ANSIASAS3202015R2020)|||[STANDARDSDATASTANDARDORTOOL:403](https://w3id.org/bridge2ai/standards-datastandardortool-schema/403)|[OntologyOrVocabulary](OntologyOrVocabulary)|ASA/ANSI S3.20|Acoustical Society of America / American National Standards Institute S3.20||
| obofoundry| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||concepts related to Alzheimer's Disease|True|False|||[https://github.com/Fraunhofer-SCAI-Applied-Semantics/ADO](https://github.com/Fraunhofer-SCAI-Applied-Semantics/ADO)|[STANDARDSDATASTANDARDORTOOL:404](https://w3id.org/bridge2ai/standards-datastandardortool-schema/404)|[OntologyOrVocabulary](OntologyOrVocabulary)|ADO|Alzheimer's Disease Ontology||
| obofoundry|||Antibiotic resistance genes and mutations|True|False||[doi:10.1093/nar/gkz935](doi:10.1093/nar/gkz935)|[https://github.com/arpcard/aro](https://github.com/arpcard/aro)|[STANDARDSDATASTANDARDORTOOL:405](https://w3id.org/bridge2ai/standards-datastandardortool-schema/405)|[OntologyOrVocabulary](OntologyOrVocabulary)|ARO|Antibiotic Resistance Ontology||
| obofoundry|||Terms and relations for interoperation between epidemic models and public health application software.|True|False|||[https://github.com/ApolloDev/apollo-sv](https://github.com/ApolloDev/apollo-sv)|[STANDARDSDATASTANDARDORTOOL:406](https://w3id.org/bridge2ai/standards-datastandardortool-schema/406)|[OntologyOrVocabulary](OntologyOrVocabulary)|APOLLO_SV|Apollo Structured Vocabulary||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||General terms for AI|True|False|[https://bioportal.bioontology.org/ontologies/AIO](https://bioportal.bioontology.org/ontologies/AIO)||[https://github.com/berkeleybop/artificial-intelligence-ontology](https://github.com/berkeleybop/artificial-intelligence-ontology)|[STANDARDSDATASTANDARDORTOOL:407](https://w3id.org/bridge2ai/standards-datastandardortool-schema/407)|[OntologyOrVocabulary](OntologyOrVocabulary)|AIO|Artificial Intelligence Ontology||
| obofoundry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Upper level ontology.|True|False|[http://basic-formal-ontology.org/](http://basic-formal-ontology.org/)|[doi:10.3233/AO-160164](doi:10.3233/AO-160164)|[https://github.com/BFO-ontology/BFO](https://github.com/BFO-ontology/BFO)|[STANDARDSDATASTANDARDORTOOL:408](https://w3id.org/bridge2ai/standards-datastandardortool-schema/408)|[OntologyOrVocabulary](OntologyOrVocabulary)|BFO|Basic Formal Ontology||
| obofoundry|||Biodiversity data, including data on museum collections and environmental/metagenomic samples.|True|False|||[https://github.com/BiodiversityOntologies/bco](https://github.com/BiodiversityOntologies/bco)|[STANDARDSDATASTANDARDORTOOL:409](https://w3id.org/bridge2ai/standards-datastandardortool-schema/409)|[OntologyOrVocabulary](OntologyOrVocabulary)|BCO|Biological Collections Ontology||
| obofoundry| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||Sample preparation, visualization and imaging methods used in biomedical research.|True|False|[http://cellimagelibrary.org/](http://cellimagelibrary.org/)||[https://github.com/CRBS/Biological_Imaging_Methods_Ontology/](https://github.com/CRBS/Biological_Imaging_Methods_Ontology/)|[STANDARDSDATASTANDARDORTOOL:410](https://w3id.org/bridge2ai/standards-datastandardortool-schema/410)|[OntologyOrVocabulary](OntologyOrVocabulary)|FBBI|Biological Imaging Methods Ontology||
| obofoundry|||Spatial concepts, anatomical axes, gradients, regions, planes, sides, and surfaces.|True|False||[doi:10.1186/2041-1480-5-34](doi:10.1186/2041-1480-5-34)|[https://github.com/obophenotype/biological-spatial-ontology](https://github.com/obophenotype/biological-spatial-ontology)|[STANDARDSDATASTANDARDORTOOL:411](https://w3id.org/bridge2ai/standards-datastandardortool-schema/411)|[OntologyOrVocabulary](OntologyOrVocabulary)|BSPO|Biological Spatial Ontology||
| obofoundry|||A structured controlled vocabulary for the source of an enzyme comprising tissues, cell lines, cell types and cell cultures.|True|False|[http://www.brenda-enzymes.org/](http://www.brenda-enzymes.org/)|[doi:10.1093/nar/gkq968](doi:10.1093/nar/gkq968)|[https://github.com/BRENDA-Enzymes/BTO](https://github.com/BRENDA-Enzymes/BTO)|[STANDARDSDATASTANDARDORTOOL:412](https://w3id.org/bridge2ai/standards-datastandardortool-schema/412)|[OntologyOrVocabulary](OntologyOrVocabulary)|BTO|BRENDA tissue / enzyme source||
| obofoundry|||A structured controlled vocabulary of Caenorhabditis elegans phenotypes.|True|False||[doi:10.1186/1471-2105-12-32](doi:10.1186/1471-2105-12-32)|[https://github.com/obophenotype/c-elegans-phenotype-ontology](https://github.com/obophenotype/c-elegans-phenotype-ontology)|[STANDARDSDATASTANDARDORTOOL:413](https://w3id.org/bridge2ai/standards-datastandardortool-schema/413)|[OntologyOrVocabulary](OntologyOrVocabulary)|WBPHENOTYPE|C. elegans phenotype ontology||
| obofoundry| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||Entities related to cardiovascular diseases.|True|False|||[https://github.com/OpenLHS/CVDO](https://github.com/OpenLHS/CVDO)|[STANDARDSDATASTANDARDORTOOL:414](https://w3id.org/bridge2ai/standards-datastandardortool-schema/414)|[OntologyOrVocabulary](OntologyOrVocabulary)|CVDO|Cardiovascular Disease Ontology||
| obofoundry|||Standardize and integrate cell line information and to support computer-assisted reasoning.|True|False|[http://www.clo-ontology.org/](http://www.clo-ontology.org/)|[doi:10.1186/2041-1480-5-3](doi:10.1186/2041-1480-5-3)|[https://github.com/CLO-Ontology/CLO](https://github.com/CLO-Ontology/CLO)|[STANDARDSDATASTANDARDORTOOL:415](https://w3id.org/bridge2ai/standards-datastandardortool-schema/415)|[OntologyOrVocabulary](OntologyOrVocabulary)|CLO|Cell Line Ontology||
| obofoundry|||Cell Types|True|False|[https://cell-ontology.github.io/](https://cell-ontology.github.io/)|[doi:10.1186/s13326-016-0088-7](doi:10.1186/s13326-016-0088-7)|[https://github.com/obophenotype/cell-ontology](https://github.com/obophenotype/cell-ontology)|[STANDARDSDATASTANDARDORTOOL:416](https://w3id.org/bridge2ai/standards-datastandardortool-schema/416)|[OntologyOrVocabulary](OntologyOrVocabulary)|CL|Cell Ontology||
| obofoundry| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)| [STANDARDSORGANIZATION:29](STANDARDSORGANIZATION:29)|A distinct role hierarchy for chemicals.|True|False||[doi:10.26434/chemrxiv.12591221.v1](doi:10.26434/chemrxiv.12591221.v1)|[https://github.com/obophenotype/chiro](https://github.com/obophenotype/chiro)|[STANDARDSDATASTANDARDORTOOL:417](https://w3id.org/bridge2ai/standards-datastandardortool-schema/417)|[OntologyOrVocabulary](OntologyOrVocabulary)|CHIRO|CHEBI Integrated Role Ontology||
| obofoundry| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)| [STANDARDSORGANIZATION:29](STANDARDSORGANIZATION:29)|Chemicals|True|False|[https://www.ebi.ac.uk/chebi/](https://www.ebi.ac.uk/chebi/)|[doi:10.1093/nar/gkv1031](doi:10.1093/nar/gkv1031)|[https://github.com/ebi-chebi/ChEBI](https://github.com/ebi-chebi/ChEBI)|[STANDARDSDATASTANDARDORTOOL:418](https://w3id.org/bridge2ai/standards-datastandardortool-schema/418)|[OntologyOrVocabulary](OntologyOrVocabulary)|CHEBI|Chemical Entities of Biological Interest||
| obofoundry| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)||Descriptors commonly used in cheminformatics software applications and the algorithms which generate them.|True|False||[doi:10.1371/journal.pone.0025513](doi:10.1371/journal.pone.0025513)|[https://github.com/semanticchemistry/semanticchemistry](https://github.com/semanticchemistry/semanticchemistry)|[STANDARDSDATASTANDARDORTOOL:419](https://w3id.org/bridge2ai/standards-datastandardortool-schema/419)|[OntologyOrVocabulary](OntologyOrVocabulary)|CHEMINF|Chemical Information Ontology||
| obofoundry| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)||A chemical methods ontology.|True|False|||[https://github.com/rsc-ontologies/rsc-cmo](https://github.com/rsc-ontologies/rsc-cmo)|[STANDARDSDATASTANDARDORTOOL:420](https://w3id.org/bridge2ai/standards-datastandardortool-schema/420)|[OntologyOrVocabulary](OntologyOrVocabulary)|CHMO|Chemical Methods Ontology||
| obofoundry| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)||An ontology of informational entities formalizing clinical laboratory tests prescriptions and reporting documents.|True|False||[doi:10.5281/zenodo.6522019](doi:10.5281/zenodo.6522019)|[https://github.com/OpenLHS/LABO](https://github.com/OpenLHS/LABO)|[STANDARDSDATASTANDARDORTOOL:421](https://w3id.org/bridge2ai/standards-datastandardortool-schema/421)|[OntologyOrVocabulary](OntologyOrVocabulary)|LABO|clinical LABoratory Ontology||
| obofoundry| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)||Morphological and physiological measurement records generated from clinical and model organism research and health programs.|True|False||[doi:10.1186/2041-1480-4-26](doi:10.1186/2041-1480-4-26)|[https://github.com/rat-genome-database/CMO-Clinical-Measurement-Ontology](https://github.com/rat-genome-database/CMO-Clinical-Measurement-Ontology)|[STANDARDSDATASTANDARDORTOOL:422](https://w3id.org/bridge2ai/standards-datastandardortool-schema/422)|[OntologyOrVocabulary](OntologyOrVocabulary)|CMO|Clinical measurement ontology||
| obofoundry|| [STANDARDSORGANIZATION:13](STANDARDSORGANIZATION:13)|Code set for active and inactive vaccines available in the US.|True|False|[https://www2a.cdc.gov/vaccines/iis/iisstandards/vaccines.asp?rpt=cvx](https://www2a.cdc.gov/vaccines/iis/iisstandards/vaccines.asp?rpt=cvx)|||[STANDARDSDATASTANDARDORTOOL:423](https://w3id.org/bridge2ai/standards-datastandardortool-schema/423)|[OntologyOrVocabulary](OntologyOrVocabulary)|CVX|Clinical Vaccines Administered||
| obofoundry|||An upper level ontology to facilitate interoperability between existing anatomy ontologies for different species.|True|False|||[https://github.com/obophenotype/caro/](https://github.com/obophenotype/caro/)|[STANDARDSDATASTANDARDORTOOL:424](https://w3id.org/bridge2ai/standards-datastandardortool-schema/424)|[OntologyOrVocabulary](OntologyOrVocabulary)|CARO|Common Anatomy Reference Ontology||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4) [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||Common Terminology Criteria for Adverse Events (CTCAE) is widely accepted throughout the oncology community as the standard classification and severity grading scale for adverse events in cancer therapy clinical trials and other oncology settings.|True|False|[https://bioportal.bioontology.org/ontologies/CTCAE](https://bioportal.bioontology.org/ontologies/CTCAE)||[https://ctep.cancer.gov/protocoldevelopment/electronic_applications/ctc.htm](https://ctep.cancer.gov/protocoldevelopment/electronic_applications/ctc.htm)|[STANDARDSDATASTANDARDORTOOL:425](https://w3id.org/bridge2ai/standards-datastandardortool-schema/425)|[OntologyOrVocabulary](OntologyOrVocabulary)|CTCAE|Common Terminology Criteria for Adverse Events||
| obofoundry|||A formalization of concepts and relations relevant to evolutionary comparative analysis.|True|False||[doi:10.4137/EBO.S2320](doi:10.4137/EBO.S2320)|[https://github.com/evoinfo/cdao](https://github.com/evoinfo/cdao)|[STANDARDSDATASTANDARDORTOOL:426](https://w3id.org/bridge2ai/standards-datastandardortool-schema/426)|[OntologyOrVocabulary](OntologyOrVocabulary)|CDAO|Comparative Data Analysis Ontology||
| obofoundry|||Nutritional attributes of material entities that contribute to human diet.|True|False|[https://cdno.info/](https://cdno.info/)|[doi:10.3389/fnut.2022.928837](doi:10.3389/fnut.2022.928837)|[https://github.com/Southern-Cross-Plant-Science/cdno](https://github.com/Southern-Cross-Plant-Science/cdno)|[STANDARDSDATASTANDARDORTOOL:427](https://w3id.org/bridge2ai/standards-datastandardortool-schema/427)|[OntologyOrVocabulary](OntologyOrVocabulary)|CDNO|Compositional Dietary Nutrition Ontology||
| obofoundry|||Capture confidence information about annotations.|True|False||[doi:10.1093/database/bav043](doi:10.1093/database/bav043)|[https://github.com/BgeeDB/confidence-information-ontology](https://github.com/BgeeDB/confidence-information-ontology)|[STANDARDSDATASTANDARDORTOOL:428](https://w3id.org/bridge2ai/standards-datastandardortool-schema/428)|[OntologyOrVocabulary](OntologyOrVocabulary)|CIO|Confidence Information Ontology||
| obofoundry| [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16)||A classification of the diverse roles performed in the work leading to a published research output in the sciences.|True|False|||[https://github.com/data2health/contributor-role-ontology](https://github.com/data2health/contributor-role-ontology)|[STANDARDSDATASTANDARDORTOOL:429](https://w3id.org/bridge2ai/standards-datastandardortool-schema/429)|[OntologyOrVocabulary](OntologyOrVocabulary)|CRO|Contributor Role Ontology||
| obofoundry|| [obofoundry](obofoundry)|Terms from a wide range of OBO projects to improve interoperability.|True|False|||[https://github.com/OBOFoundry/COB](https://github.com/OBOFoundry/COB)|[STANDARDSDATASTANDARDORTOOL:430](https://w3id.org/bridge2ai/standards-datastandardortool-schema/430)|[OntologyOrVocabulary](OntologyOrVocabulary)|COB|Core Ontology for Biology and Biomedicine||
| obofoundry| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||Ontologically represent and standardize various aspects of coronavirus infectious.|True|False||[doi:10.1038/s41597-020-0523-6](doi:10.1038/s41597-020-0523-6)|[https://github.com/cido-ontology/cido](https://github.com/cido-ontology/cido)|[STANDARDSDATASTANDARDORTOOL:431](https://w3id.org/bridge2ai/standards-datastandardortool-schema/431)|[OntologyOrVocabulary](OntologyOrVocabulary)|CIDO|Coronavirus Infectious Disease Ontology||
| obofoundry| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [FSCAI](FSCAI)|A structured resource integrating basic terms and concepts in the context of clinical trials.|True|False|||[https://github.com/ClinicalTrialOntology/CTO/](https://github.com/ClinicalTrialOntology/CTO/)|[STANDARDSDATASTANDARDORTOOL:432](https://w3id.org/bridge2ai/standards-datastandardortool-schema/432)|[OntologyOrVocabulary](OntologyOrVocabulary)|CTO|CTO Core Ontology of Clinical Trials||
| obofoundry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|Data use rules|True|False|||[https://github.com/EBISPOT/DUO](https://github.com/EBISPOT/DUO)|[STANDARDSDATASTANDARDORTOOL:433](https://w3id.org/bridge2ai/standards-datastandardortool-schema/433)|[OntologyOrVocabulary](OntologyOrVocabulary)|DUO|Data Use Ontology||
||||An ontology developed to facilitate information curation in the area of medical devices, experimental scaffolds and biomaterials.|True|False|[https://bioportal.bioontology.org/ontologies/DEB](https://bioportal.bioontology.org/ontologies/DEB)|[doi:10.1002/adfm.201909910](doi:10.1002/adfm.201909910)|[https://github.com/ProjectDebbie/Ontology_DEB](https://github.com/ProjectDebbie/Ontology_DEB)|[STANDARDSDATASTANDARDORTOOL:434](https://w3id.org/bridge2ai/standards-datastandardortool-schema/434)|[OntologyOrVocabulary](OntologyOrVocabulary)|DEB|Devices, Experimental scaffolds and Biomaterials Ontology||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||This ontology network aims at representing the main sets of entities and relationships used in the context of DevOps infrastructure. It is the result of a collaboration between Huawei Research Ireland and the Ontology Engineering Group at Universidad Politécnica de Madrid. It originally started from an analysis of the Configuration Management Databases used by Huawei Research Ireland for the management of a large part of its DevOps infrastructure, and has evolved into an ontology that may be used as a starting point for the standardisation of the representation of CMDB-related data across vendors.|True|False|[https://oeg-upm.github.io/devops-infra/index.html](https://oeg-upm.github.io/devops-infra/index.html)||[https://github.com/oeg-upm/devops-infra](https://github.com/oeg-upm/devops-infra)|[STANDARDSDATASTANDARDORTOOL:435](https://w3id.org/bridge2ai/standards-datastandardortool-schema/435)|[OntologyOrVocabulary](OntologyOrVocabulary)|devops-infra|Devops Infrastructure Ontology||
| obofoundry|||Ontology for drivers and triggers of human diseases, built to classify ExO ontology exposure stressors. An application ontology.|True|False|||[https://github.com/DiseaseOntology/DiseaseDriversOntology](https://github.com/DiseaseOntology/DiseaseDriversOntology)|[STANDARDSDATASTANDARDORTOOL:436](https://w3id.org/bridge2ai/standards-datastandardortool-schema/436)|[OntologyOrVocabulary](OntologyOrVocabulary)|DISDRIV|Disease Drivers Ontology||
| obofoundry| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)||Commonly encountered and/or high level Drosophila phenotypes.|True|False|[https://github.com/FlyBase/flybase-controlled-vocabulary/wiki](https://github.com/FlyBase/flybase-controlled-vocabulary/wiki)|[doi:10.1186/2041-1480-4-30](doi:10.1186/2041-1480-4-30)|[https://github.com/FlyBase/drosophila-phenotype-ontology](https://github.com/FlyBase/drosophila-phenotype-ontology)|[STANDARDSDATASTANDARDORTOOL:437](https://w3id.org/bridge2ai/standards-datastandardortool-schema/437)|[OntologyOrVocabulary](OntologyOrVocabulary)|DPO|Drosophila Phenotype Ontology||
|| [STANDARDSDATATOPIC:8](STANDARDSDATATOPIC:8) [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)||Drug Target Ontology (DTO) is being developed at the University of Miami in the research group of Stephan Schürer. DTO was developed as part of the Illuminating the Druggable Genome (IDG) project (https://commonfund.nih.gov/idg/overview), is supported by grant (IDG Knowledge Management Center, (U54CA189205). DTO is a novel semantic framework to formalize knowledge about drug targets and is developed as a reference for drug targets with the longer-term goal to create a community standard that will facilitate the integration of diverse drug discovery information from numerous heterogeneous resources.|True|False|[https://bioportal.bioontology.org/ontologies/DTO](https://bioportal.bioontology.org/ontologies/DTO)|[doi:10.1186/s13326-017-0161-x](doi:10.1186/s13326-017-0161-x)|[http://drugtargetontology.org/](http://drugtargetontology.org/)|[STANDARDSDATASTANDARDORTOOL:438](https://w3id.org/bridge2ai/standards-datastandardortool-schema/438)|[OntologyOrVocabulary](OntologyOrVocabulary)|DTO|Drug Target Ontology||
| obofoundry| [STANDARDSDATATOPIC:8](STANDARDSDATATOPIC:8)||The Potential Drug-drug Interaction and Potential Drug-drug Interaction Evidence Ontology|True|False|||[https://github.com/DIDEO/DIDEO](https://github.com/DIDEO/DIDEO)|[STANDARDSDATASTANDARDORTOOL:439](https://w3id.org/bridge2ai/standards-datastandardortool-schema/439)|[OntologyOrVocabulary](OntologyOrVocabulary)|DIDEO|Drug-drug Interaction and Drug-drug Interaction Evidence Ontology||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:29](STANDARDSORGANIZATION:29)|Data types, identifiers, and formats|True|False||[doi:10.1093/bioinformatics/btt113](doi:10.1093/bioinformatics/btt113)|[https://github.com/edamontology/edamontology](https://github.com/edamontology/edamontology)|[STANDARDSDATASTANDARDORTOOL:440](https://w3id.org/bridge2ai/standards-datastandardortool-schema/440)|[OntologyOrVocabulary](OntologyOrVocabulary)|EDAM|EMBRACE Data And Methods Ontology||
| obofoundry|||Affective phenomena such as emotions, moods, appraisals and subjective feelings.|True|False|||[https://github.com/jannahastings/emotion-ontology](https://github.com/jannahastings/emotion-ontology)|[STANDARDSDATASTANDARDORTOOL:441](https://w3id.org/bridge2ai/standards-datastandardortool-schema/441)|[OntologyOrVocabulary](OntologyOrVocabulary)|MFOEM|Emotion Ontology||
| obofoundry| [STANDARDSDATATOPIC:11](STANDARDSDATATOPIC:11)||Environmental systems, components, and processes.|True|False|[http://environmentontology.org/](http://environmentontology.org/)||[https://github.com/EnvironmentOntology/envo](https://github.com/EnvironmentOntology/envo)|[STANDARDSDATASTANDARDORTOOL:442](https://w3id.org/bridge2ai/standards-datastandardortool-schema/442)|[OntologyOrVocabulary](OntologyOrVocabulary)|ENVO|Environment Ontology||
| obofoundry| [STANDARDSDATATOPIC:11](STANDARDSDATATOPIC:11)||Exposures to experimental treatments of plants and model organisms.|True|False|||[https://github.com/EnvironmentOntology/environmental-exposure-ontology](https://github.com/EnvironmentOntology/environmental-exposure-ontology)|[STANDARDSDATASTANDARDORTOOL:443](https://w3id.org/bridge2ai/standards-datastandardortool-schema/443)|[OntologyOrVocabulary](OntologyOrVocabulary)|ECTO|Environmental conditions, treatments and exposures ontology||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||The Evidence Graph Ontology (EVI) extends core concepts from the W3C Provenance Ontology [PROV-O] to describe evidence for correctness of findings in biomedical publications. The semantic data model in EVI is expressed using OWL2 Web Ontology Language.|True|False|[https://evidencegraph.github.io/EVI/index.html](https://evidencegraph.github.io/EVI/index.html)||[https://github.com/EvidenceGraph/EVI](https://github.com/EvidenceGraph/EVI)|[STANDARDSDATASTANDARDORTOOL:444](https://w3id.org/bridge2ai/standards-datastandardortool-schema/444)|[OntologyOrVocabulary](OntologyOrVocabulary)|EVI|Evidence Graph Ontology||
| obofoundry|||An ontology for experimental and other evidence statements.|True|False|[https://www.evidenceontology.org/](https://www.evidenceontology.org/)|[doi:10.1093/nar/gkab1025](doi:10.1093/nar/gkab1025)|[https://github.com/evidenceontology/evidenceontology](https://github.com/evidenceontology/evidenceontology)|[STANDARDSDATASTANDARDORTOOL:445](https://w3id.org/bridge2ai/standards-datastandardortool-schema/445)|[OntologyOrVocabulary](OntologyOrVocabulary)|ECO|Evidence ontology||
| obofoundry|||Conditions under which physiological and morphological measurements are made both in the clinic and in studies involving humans or model org...|True|False|[https://rgd.mcw.edu/rgdweb/ontology/view.html?acc_id=XCO:0000000](https://rgd.mcw.edu/rgdweb/ontology/view.html?acc_id=XCO:0000000)|[doi:10.1186/2041-1480-4-26](doi:10.1186/2041-1480-4-26)|[https://github.com/rat-genome-database/XCO-experimental-condition-ontology](https://github.com/rat-genome-database/XCO-experimental-condition-ontology)|[STANDARDSDATASTANDARDORTOOL:446](https://w3id.org/bridge2ai/standards-datastandardortool-schema/446)|[OntologyOrVocabulary](OntologyOrVocabulary)|XCO|Experimental condition ontology||
| obofoundry| [STANDARDSDATATOPIC:11](STANDARDSDATATOPIC:11)||Vocabularies for describing exposure data to inform understanding of environmental health.|True|False|||[https://github.com/CTDbase/exposure-ontology](https://github.com/CTDbase/exposure-ontology)|[STANDARDSDATASTANDARDORTOOL:447](https://w3id.org/bridge2ai/standards-datastandardortool-schema/447)|[OntologyOrVocabulary](OntologyOrVocabulary)|EXO|Exposure ontology||
| obofoundry| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)||Phenotypes observed in fission yeast.|True|False||[doi:10.1093/bioinformatics/btt266](doi:10.1093/bioinformatics/btt266)|[https://github.com/pombase/fypo](https://github.com/pombase/fypo)|[STANDARDSDATASTANDARDORTOOL:448](https://w3id.org/bridge2ai/standards-datastandardortool-schema/448)|[OntologyOrVocabulary](OntologyOrVocabulary)|FYPO|Fission Yeast Phenotype Ontology||
| obofoundry| [STANDARDSDATATOPIC:8](STANDARDSDATATOPIC:8)||Food-Drug interactions automatically extracted from scientific literature.|True|False|[https://gitub.u-bordeaux.fr/erias/fideo](https://gitub.u-bordeaux.fr/erias/fideo)||[https://github.com/getbordea/fideo/](https://github.com/getbordea/fideo/)|[STANDARDSDATASTANDARDORTOOL:449](https://w3id.org/bridge2ai/standards-datastandardortool-schema/449)|[OntologyOrVocabulary](OntologyOrVocabulary)|FIDEO|Food Interactions with Drugs Evidence Ontology||
| obofoundry|||A broadly scoped ontology representing entities which bear a “food role”. It encompasses materials in natural ecosystems and agriculture tha...|True|False|[https://foodon.org/](https://foodon.org/)|[doi:10.1038/s41538-018-0032-6](doi:10.1038/s41538-018-0032-6)|[https://github.com/FoodOntology/foodon/](https://github.com/FoodOntology/foodon/)|[STANDARDSDATASTANDARDORTOOL:450](https://w3id.org/bridge2ai/standards-datastandardortool-schema/450)|[OntologyOrVocabulary](OntologyOrVocabulary)|FOODON|Food Ontology||
| obofoundry|||Represent food intake data and associate it with metabolomic data|True|False||[doi:10.1093/bioinformatics/btab626](doi:10.1093/bioinformatics/btab626)|[https://github.com/pcastellanoescuder/FoodBiomarkerOntology](https://github.com/pcastellanoescuder/FoodBiomarkerOntology)|[STANDARDSDATASTANDARDORTOOL:451](https://w3id.org/bridge2ai/standards-datastandardortool-schema/451)|[OntologyOrVocabulary](OntologyOrVocabulary)|FOBI|Food-Biomarker Ontology||
| obofoundry| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)||Application ontology used to convert vertebrate trait data in spreadsheets to triples.|True|False|[https://futres.org/](https://futres.org/)||[https://github.com/futres/fovt](https://github.com/futres/fovt)|[STANDARDSDATASTANDARDORTOOL:452](https://w3id.org/bridge2ai/standards-datastandardortool-schema/452)|[OntologyOrVocabulary](OntologyOrVocabulary)|FOVT|FuTRES Ontology of Vertebrate Traits||
| obofoundry| [Demographics](Demographics)||Terms for annotating interdisciplinary information concerning gender, sex, and sexual orientation.|True|False|[https://gsso.research.cchmc.org/](https://gsso.research.cchmc.org/)||[https://github.com/Superraptor/GSSO](https://github.com/Superraptor/GSSO)|[STANDARDSDATASTANDARDORTOOL:453](https://w3id.org/bridge2ai/standards-datastandardortool-schema/453)|[OntologyOrVocabulary](OntologyOrVocabulary)|GSSO|Gender, Sex, and Sexual Orientation Ontology||
| obofoundry| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12)| [GO](GO)|Function of genes and gene products.|True|False|[http://geneontology.org/](http://geneontology.org/)|[doi:10.1093/nar/gkaa1113](doi:10.1093/nar/gkaa1113)|[https://github.com/geneontology/go-ontology](https://github.com/geneontology/go-ontology)|[STANDARDSDATASTANDARDORTOOL:454](https://w3id.org/bridge2ai/standards-datastandardortool-schema/454)|[OntologyOrVocabulary](OntologyOrVocabulary)|GO|Gene Ontology||
| obofoundry|||Vocabulary necessary to identify, document and research foodborne pathogens.|True|False|[http://genepio.org/](http://genepio.org/)||[https://github.com/GenEpiO/genepio](https://github.com/GenEpiO/genepio)|[STANDARDSDATASTANDARDORTOOL:455](https://w3id.org/bridge2ai/standards-datastandardortool-schema/455)|[OntologyOrVocabulary](OntologyOrVocabulary)|GENEPIO|Genomic Epidemiology Ontology||
| obofoundry| [STANDARDSDATATOPIC:4, Demographics](STANDARDSDATATOPIC:4, Demographics)||Genomics cohort attributes.|True|False|||[https://github.com/IHCC-cohorts/GECKO](https://github.com/IHCC-cohorts/GECKO)|[STANDARDSDATASTANDARDORTOOL:456](https://w3id.org/bridge2ai/standards-datastandardortool-schema/456)|[OntologyOrVocabulary](OntologyOrVocabulary)|GECKO|Genomics Cohorts Knowledge Ontology||
| obofoundry|| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|Genotypes|True|False|||[https://github.com/monarch-initiative/GENO-ontology](https://github.com/monarch-initiative/GENO-ontology)|[STANDARDSDATASTANDARDORTOOL:457](https://w3id.org/bridge2ai/standards-datastandardortool-schema/457)|[OntologyOrVocabulary](OntologyOrVocabulary)|GENO|Genotype Ontology||
| obofoundry| [Geolocation](Geolocation)| [UFBMI](UFBMI)|An ontology of geographical entities|True|False|||[https://github.com/ufbmi/geographical-entity-ontology/](https://github.com/ufbmi/geographical-entity-ontology/)|[STANDARDSDATASTANDARDORTOOL:458](https://w3id.org/bridge2ai/standards-datastandardortool-schema/458)|[OntologyOrVocabulary](OntologyOrVocabulary)|GEO|Geographical Entity Ontology||
||| [GMDNA](GMDNA)|The Global Medical Device Nomenclature (GMDN) is a comprehensive set of terms, within a structured category hierarchy, which name and group ALL medical device products including implantables, medical equipment, consumables, and diagnostic devices.|False|True|[https://www.gmdnagency.org/](https://www.gmdnagency.org/)|||[STANDARDSDATASTANDARDORTOOL:459](https://w3id.org/bridge2ai/standards-datastandardortool-schema/459)|[OntologyOrVocabulary](OntologyOrVocabulary)|GMDN|Global Medical Device Nomenclature||
| obofoundry|||GlyTouCan provides stable accessions for glycans described at varyious degrees of characterization, including compositions (no linkage).|True|False|[https://gnome.glyomics.org/](https://gnome.glyomics.org/)|[doi:10.5281/zenodo.6678279](doi:10.5281/zenodo.6678279)|[https://github.com/glygen-glycan-data/GNOme](https://github.com/glygen-glycan-data/GNOme)|[STANDARDSDATASTANDARDORTOOL:460](https://w3id.org/bridge2ai/standards-datastandardortool-schema/460)|[OntologyOrVocabulary](OntologyOrVocabulary)|GNO|Glycan Naming and Subsumption Ontology||
| obofoundry|| [SVA](SVA)|Surveillance system level data.|True|False|[https://w3id.org/hso](https://w3id.org/hso)||[https://github.com/SVA-SE/HSO](https://github.com/SVA-SE/HSO)|[STANDARDSDATASTANDARDORTOOL:461](https://w3id.org/bridge2ai/standards-datastandardortool-schema/461)|[OntologyOrVocabulary](OntologyOrVocabulary)|HSO|Health Surveillance Ontology||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|A "index" to the HL7-supported Code Systems.|True|False|[https://www.hl7.org/documentcenter/public/standards/vocabulary/vocabulary_tables/infrastructure/vocabulary/vocabulary.html#voc-systems](https://www.hl7.org/documentcenter/public/standards/vocabulary/vocabulary_tables/infrastructure/vocabulary/vocabulary.html#voc-systems)|||[STANDARDSDATASTANDARDORTOOL:462](https://w3id.org/bridge2ai/standards-datastandardortool-schema/462)|[OntologyOrVocabulary](OntologyOrVocabulary)|HL7 Vocabulary|HL7 Vocabulary||
| obofoundry|||Concepts related to homology, as well as other concepts used to describe similarity and non-homology.|True|False||[doi:10.1016/j.tig.2009.12.012](doi:10.1016/j.tig.2009.12.012)|[https://github.com/BgeeDB/homology-ontology](https://github.com/BgeeDB/homology-ontology)|[STANDARDSDATASTANDARDORTOOL:463](https://w3id.org/bridge2ai/standards-datastandardortool-schema/463)|[OntologyOrVocabulary](OntologyOrVocabulary)|HOM|Homology Ontology||
|| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)| [Orphanet](Orphanet)|Orphanet provides phenotypic annotations of the rare diseases in the Orphanet nomenclature using the Human Phenotype Ontology (HPO). HOOM is a module that qualifies the annotation between a clinical entity and phenotypic abnormalities according to a frequency and by integrating the notion of diagnostic criterion.|True|False|[https://bioportal.bioontology.org/ontologies/HOOM](https://bioportal.bioontology.org/ontologies/HOOM)||[https://www.orphadata.com/ontologies/](https://www.orphadata.com/ontologies/)|[STANDARDSDATASTANDARDORTOOL:464](https://w3id.org/bridge2ai/standards-datastandardortool-schema/464)|[OntologyOrVocabulary](OntologyOrVocabulary)|HOOM|HPO - ORDO Ontological Module||
| obofoundry|||A systematic description of the ancestry concepts used in the NHGRI-EBI Catalog|True|False||[doi:10.1186/s13059-018-1396-2](doi:10.1186/s13059-018-1396-2)|[https://github.com/EBISPOT/ancestro](https://github.com/EBISPOT/ancestro)|[STANDARDSDATASTANDARDORTOOL:465](https://w3id.org/bridge2ai/standards-datastandardortool-schema/465)|[OntologyOrVocabulary](OntologyOrVocabulary)|HANCESTRO|Human Ancestry Ontology||
| obofoundry|||Life cycle stages for Human.|True|False|[https://github.com/obophenotype/developmental-stage-ontologies/wiki/HsapDv](https://github.com/obophenotype/developmental-stage-ontologies/wiki/HsapDv)||[https://github.com/obophenotype/developmental-stage-ontologies](https://github.com/obophenotype/developmental-stage-ontologies)|[STANDARDSDATASTANDARDORTOOL:466](https://w3id.org/bridge2ai/standards-datastandardortool-schema/466)|[OntologyOrVocabulary](OntologyOrVocabulary)|HSAPDV|Human Developmental Stages||
| obofoundry| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||An ontology for describing the classification of human diseases organized by etiology.|True|False|[http://www.disease-ontology.org](http://www.disease-ontology.org)||[https://github.com/DiseaseOntology/HumanDiseaseOntology](https://github.com/DiseaseOntology/HumanDiseaseOntology)|[STANDARDSDATASTANDARDORTOOL:467](https://w3id.org/bridge2ai/standards-datastandardortool-schema/467)|[OntologyOrVocabulary](OntologyOrVocabulary)|DOID|Human Disease Ontology||
| obofoundry| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)||Phenotypic Features|True|False|[https://hpo.jax.org/](https://hpo.jax.org/)||[https://github.com/obophenotype/human-phenotype-ontology](https://github.com/obophenotype/human-phenotype-ontology)|[STANDARDSDATASTANDARDORTOOL:468](https://w3id.org/bridge2ai/standards-datastandardortool-schema/468)|[OntologyOrVocabulary](OntologyOrVocabulary)|HPO|Human Phenotype Ontology||
|| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|A structured controlled vocabulary for cross-linking reagents used with proteomics mass spectrometry.|True|False|[https://www.psidev.info/groups/controlled-vocabularies](https://www.psidev.info/groups/controlled-vocabularies)|||[STANDARDSDATASTANDARDORTOOL:469](https://w3id.org/bridge2ai/standards-datastandardortool-schema/469)|[OntologyOrVocabulary](OntologyOrVocabulary)|XLMOD|HUPO-PSI cross-linking and derivatization reagents controlled vocabulary||
| obofoundry| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||An ontology for representing clinical data about hypertension.|True|False|||[https://github.com/aellenhicks/htn_owl](https://github.com/aellenhicks/htn_owl)|[STANDARDSDATASTANDARDORTOOL:470](https://w3id.org/bridge2ai/standards-datastandardortool-schema/470)|[OntologyOrVocabulary](OntologyOrVocabulary)|HTN|Hypertension Ontology||
| obofoundry| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||A set of interoperable ontologies that will together provide coverage of the infectious disease domain. IDO core is the upper-level ontology...|True|False|||[https://github.com/infectious-disease-ontology/infectious-disease-ontology](https://github.com/infectious-disease-ontology/infectious-disease-ontology)|[STANDARDSDATASTANDARDORTOOL:471](https://w3id.org/bridge2ai/standards-datastandardortool-schema/471)|[OntologyOrVocabulary](OntologyOrVocabulary)|IDO|Infectious Disease Ontology||
| obofoundry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||An ontology of information entities.|True|False|||[https://github.com/information-artifact-ontology/IAO](https://github.com/information-artifact-ontology/IAO)|[STANDARDSDATASTANDARDORTOOL:472](https://w3id.org/bridge2ai/standards-datastandardortool-schema/472)|[OntologyOrVocabulary](OntologyOrVocabulary)|IAO|Information Artifact Ontology||
| obofoundry| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)||An ontology of clinical informed consents|True|False|||[https://github.com/ICO-ontology/ICO](https://github.com/ICO-ontology/ICO)|[STANDARDSDATASTANDARDORTOOL:473](https://w3id.org/bridge2ai/standards-datastandardortool-schema/473)|[OntologyOrVocabulary](OntologyOrVocabulary)|ICO|Informed Consent Ontology||
| obofoundry|||An integrated biological ontology for the description of bacterial integrative and conjugative elements (ICEs).|True|False|[http://db-mml.sjtu.edu.cn/ICEberg/](http://db-mml.sjtu.edu.cn/ICEberg/)|[doi:10.1038/s41597-021-01112-5](doi:10.1038/s41597-021-01112-5)|[https://github.com/ontoice/ICEO](https://github.com/ontoice/ICEO)|[STANDARDSDATASTANDARDORTOOL:474](https://w3id.org/bridge2ai/standards-datastandardortool-schema/474)|[OntologyOrVocabulary](OntologyOrVocabulary)|ICEO|Integrative and Conjugative Element Ontology||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [Samwald](Samwald)|Comprehensive, curated and interlinked data of artificial intelligence tasks, benchmarks, AI performance metrics, benchmark results and research papers.|True|False|[https://openbiolink.github.io/ITOExplorer/](https://openbiolink.github.io/ITOExplorer/)||[https://github.com/OpenBioLink/ITO](https://github.com/OpenBioLink/ITO)|[STANDARDSDATASTANDARDORTOOL:475](https://w3id.org/bridge2ai/standards-datastandardortool-schema/475)|[OntologyOrVocabulary](OntologyOrVocabulary)|ITO|Intelligence Task Ontology||
| obofoundry|||An ontology of interactions and interaction networks.|True|False||[doi:10.1186/2041-1480-6-2](doi:10.1186/2041-1480-6-2)|[https://github.com/INO-ontology/ino](https://github.com/INO-ontology/ino)|[STANDARDSDATASTANDARDORTOOL:476](https://w3id.org/bridge2ai/standards-datastandardortool-schema/476)|[OntologyOrVocabulary](OntologyOrVocabulary)|INO|Interaction Network Ontology||
|| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)||biological, biomedical, and related concepts|True|False||[doi:10.1007/s00354-019-00074-y](doi:10.1007/s00354-019-00074-y)|[https://github.com/kushidat/IOBC](https://github.com/kushidat/IOBC)|[STANDARDSDATASTANDARDORTOOL:477](https://w3id.org/bridge2ai/standards-datastandardortool-schema/477)|[OntologyOrVocabulary](OntologyOrVocabulary)|IOBC|Interlinking Ontology for Biological Concepts||
| obofoundry|||Algorithms for simulating biology, their parameters, and their outputs.|True|False|[http://co.mbine.org/standards/kisao](http://co.mbine.org/standards/kisao)||[https://github.com/SED-ML/KiSAO](https://github.com/SED-ML/KiSAO)|[STANDARDSDATASTANDARDORTOOL:478](https://w3id.org/bridge2ai/standards-datastandardortool-schema/478)|[OntologyOrVocabulary](OntologyOrVocabulary)|KISAO|Kinetic Simulation Algorithm Ontology||
| obofoundry| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)||Standard terms for annotating mammalian phenotypic data.|True|False||[doi:10.1007/s00335-012-9421-3](doi:10.1007/s00335-012-9421-3)|[https://github.com/mgijax/mammalian-phenotype-ontology](https://github.com/mgijax/mammalian-phenotype-ontology)|[STANDARDSDATASTANDARDORTOOL:479](https://w3id.org/bridge2ai/standards-datastandardortool-schema/479)|[OntologyOrVocabulary](OntologyOrVocabulary)|MP|Mammalian Phenotype Ontology||
||| [STANDARDSORGANIZATION:13](STANDARDSORGANIZATION:13)|Code set for active and inactive manufacturers of vaccines in the US.|True|False|[https://www2a.cdc.gov/vaccines/iis/iisstandards/vaccines.asp?rpt=mvx](https://www2a.cdc.gov/vaccines/iis/iisstandards/vaccines.asp?rpt=mvx)|||[STANDARDSDATASTANDARDORTOOL:480](https://w3id.org/bridge2ai/standards-datastandardortool-schema/480)|[OntologyOrVocabulary](OntologyOrVocabulary)|MVX|Manufacturers of Vaccines||
|| [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|A structured controlled vocabulary for the annotation of experiments concerned with proteomics mass spectrometry.|True|False|[http://www.psidev.info/groups/controlled-vocabularies](http://www.psidev.info/groups/controlled-vocabularies)|[doi:10.1093/database/bat009](doi:10.1093/database/bat009)|[https://github.com/HUPO-PSI/psi-ms-CV](https://github.com/HUPO-PSI/psi-ms-CV)|[STANDARDSDATASTANDARDORTOOL:481](https://w3id.org/bridge2ai/standards-datastandardortool-schema/481)|[OntologyOrVocabulary](OntologyOrVocabulary)|MS|Mass spectrometry ontology||
| obofoundry|||A representation of the variety of methods used to make clinical and phenotype measurements.|True|False|[https://rgd.mcw.edu/rgdweb/ontology/view.html?acc_id=MMO:0000000](https://rgd.mcw.edu/rgdweb/ontology/view.html?acc_id=MMO:0000000)|[doi:10.1186/2041-1480-4-26](doi:10.1186/2041-1480-4-26)|[https://github.com/rat-genome-database/MMO-Measurement-Method-Ontology/](https://github.com/rat-genome-database/MMO-Measurement-Method-Ontology/)|[STANDARDSDATASTANDARDORTOOL:482](https://w3id.org/bridge2ai/standards-datastandardortool-schema/482)|[OntologyOrVocabulary](OntologyOrVocabulary)|MMO|Measurement method ontology||
| obofoundry|||Life cycle stages for Medaka|True|False|[https://github.com/obophenotype/developmental-stage-ontologies/wiki/OlatDv](https://github.com/obophenotype/developmental-stage-ontologies/wiki/OlatDv)||[https://github.com/obophenotype/developmental-stage-ontologies](https://github.com/obophenotype/developmental-stage-ontologies)|[STANDARDSDATASTANDARDORTOOL:483](https://w3id.org/bridge2ai/standards-datastandardortool-schema/483)|[OntologyOrVocabulary](OntologyOrVocabulary)|OLATDV|Medaka Developmental Stages||
| obofoundry| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|Terms for medical procedures, interventions, therapies, treatments, and recommendations.|True|False|||[https://github.com/monarch-initiative/MAxO](https://github.com/monarch-initiative/MAxO)|[STANDARDSDATASTANDARDORTOOL:484](https://w3id.org/bridge2ai/standards-datastandardortool-schema/484)|[OntologyOrVocabulary](OntologyOrVocabulary)|MAXO|Medical Action Ontology||
| codesystem| [STANDARDSDATATOPIC:8](STANDARDSDATATOPIC:8)| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|Formal ontological representations of medication terminology, pharmacologic classifications, and asserted authoritative relationships between them. Replaces NDF-RT. Provided through UMLS.|True|True|[https://evs.nci.nih.gov/ftp1/NDF-RT/Introduction%20to%20MED-RT.pdf](https://evs.nci.nih.gov/ftp1/NDF-RT/Introduction%20to%20MED-RT.pdf)|||[STANDARDSDATASTANDARDORTOOL:485](https://w3id.org/bridge2ai/standards-datastandardortool-schema/485)|[OntologyOrVocabulary](OntologyOrVocabulary)|MED-RT|Medication Reference Terminology||
| obofoundry| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||Mental diseases such as schizophrenia, annotated with DSM-IV and ICD codes where applicable.|True|False|||[https://github.com/jannahastings/mental-functioning-ontology](https://github.com/jannahastings/mental-functioning-ontology)|[STANDARDSDATASTANDARDORTOOL:486](https://w3id.org/bridge2ai/standards-datastandardortool-schema/486)|[OntologyOrVocabulary](OntologyOrVocabulary)|MFOMD|Mental Disease Ontology||
| obofoundry|||All aspects of mental functioning.|True|False|||[https://github.com/jannahastings/mental-functioning-ontology](https://github.com/jannahastings/mental-functioning-ontology)|[STANDARDSDATASTANDARDORTOOL:487](https://w3id.org/bridge2ai/standards-datastandardortool-schema/487)|[OntologyOrVocabulary](OntologyOrVocabulary)|MF|Mental Functioning Ontology||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||An OWL ontology and application profile to capture metadata information for ontologies, vocabularies or semantic resources/artefacts in general.|True|False||[doi:10.1007/978-3-319-70863-8_17](doi:10.1007/978-3-319-70863-8_17)|[https://github.com/sifrproject/MOD-Ontology](https://github.com/sifrproject/MOD-Ontology)|[STANDARDSDATASTANDARDORTOOL:488](https://w3id.org/bridge2ai/standards-datastandardortool-schema/488)|[OntologyOrVocabulary](OntologyOrVocabulary)|MOD|Metadata vocabulary for Ontology Description and Publication||
| obofoundry|||Major Histocompatibility Complex (MHC) restriction in experiments.|True|False|||[https://github.com/IEDB/MRO](https://github.com/IEDB/MRO)|[STANDARDSDATASTANDARDORTOOL:489](https://w3id.org/bridge2ai/standards-datastandardortool-schema/489)|[OntologyOrVocabulary](OntologyOrVocabulary)|MRO|MHC Restriction Ontology||
| obofoundry|||An application ontology to formalize annotation of phylogenetic data.|True|False|[https://www.evoio.org/wiki/MIAPA](https://www.evoio.org/wiki/MIAPA)|[doi:10.1089/omi.2006.10.231](doi:10.1089/omi.2006.10.231)|[https://github.com/evoinfo/miapa/](https://github.com/evoinfo/miapa/)|[STANDARDSDATASTANDARDORTOOL:490](https://w3id.org/bridge2ai/standards-datastandardortool-schema/490)|[OntologyOrVocabulary](OntologyOrVocabulary)|MIAPA|MIAPA Ontology||
| obofoundry|||Minimum information regarding potential drug-drug interaction information.|True|False|||[https://github.com/MPIO-Developers/MPIO](https://github.com/MPIO-Developers/MPIO)|[STANDARDSDATASTANDARDORTOOL:491](https://w3id.org/bridge2ai/standards-datastandardortool-schema/491)|[OntologyOrVocabulary](OntologyOrVocabulary)|MPIO|Minimum PDDI Information Ontology||
| modelcards| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||An OWL2-based artifact that represents and formalizes model card report information. The current release of this ontology utilizes standard concepts and properties from OBO Foundry ontologies.|True|False||[doi:10.1186/s12859-022-04797-6](doi:10.1186/s12859-022-04797-6)|[https://github.com/UTHealth-Ontology/MCRO](https://github.com/UTHealth-Ontology/MCRO)|[STANDARDSDATASTANDARDORTOOL:492](https://w3id.org/bridge2ai/standards-datastandardortool-schema/492)|[OntologyOrVocabulary](OntologyOrVocabulary)|MCRO|Model Card Report Ontology||
|| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20) [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|Vocabulary for the annotation of experiments concerned with protein-protein interactions.|True|False|||[https://github.com/HUPO-PSI/psi-mi-CV](https://github.com/HUPO-PSI/psi-mi-CV)|[STANDARDSDATASTANDARDORTOOL:493](https://w3id.org/bridge2ai/standards-datastandardortool-schema/493)|[OntologyOrVocabulary](OntologyOrVocabulary)|MI|Molecular Interactions Controlled Vocabulary||
| obofoundry|| [STANDARDSORGANIZATION:29](STANDARDSORGANIZATION:29)|Processes at the molecular level|True|False|[https://www.ebi.ac.uk/ols/ontologies/mop](https://www.ebi.ac.uk/ols/ontologies/mop)||[https://github.com/rsc-ontologies/rxno](https://github.com/rsc-ontologies/rxno)|[STANDARDSDATASTANDARDORTOOL:494](https://w3id.org/bridge2ai/standards-datastandardortool-schema/494)|[OntologyOrVocabulary](OntologyOrVocabulary)|MOP|Molecular Process Ontology||
| obofoundry| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|Diseases|True|False|[https://mondo.monarchinitiative.org/](https://mondo.monarchinitiative.org/)|[doi:10.1093/nar/gkw1128](doi:10.1093/nar/gkw1128)|[https://github.com/monarch-initiative/mondo](https://github.com/monarch-initiative/mondo)|[STANDARDSDATASTANDARDORTOOL:495](https://w3id.org/bridge2ai/standards-datastandardortool-schema/495)|[OntologyOrVocabulary](OntologyOrVocabulary)|MONDO|Mondo Disease Ontology||
| obofoundry|||Mouse anatomy covering embryonic development and postnatal stages.|True|False|[http://www.informatics.jax.org/expression.shtml](http://www.informatics.jax.org/expression.shtml)||[https://github.com/obophenotype/mouse-anatomy-ontology](https://github.com/obophenotype/mouse-anatomy-ontology)|[STANDARDSDATASTANDARDORTOOL:496](https://w3id.org/bridge2ai/standards-datastandardortool-schema/496)|[OntologyOrVocabulary](OntologyOrVocabulary)|EMAPA|Mouse Developmental Anatomy Ontology||
| obofoundry|||A structured controlled vocabulary of mutant and transgenic mouse pathology phenotypes.|True|False|[http://www.pathbase.net/](http://www.pathbase.net/)||[https://github.com/PaulNSchofield/mpath](https://github.com/PaulNSchofield/mpath)|[STANDARDSDATASTANDARDORTOOL:497](https://w3id.org/bridge2ai/standards-datastandardortool-schema/497)|[OntologyOrVocabulary](OntologyOrVocabulary)|MPATH|Mouse pathology ontology||
| obofoundry| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)||Connects organic name reactions to their roles in an organic synthesis and to processes in MOP|True|False|||[https://github.com/rsc-ontologies/rxno](https://github.com/rsc-ontologies/rxno)|[STANDARDSDATASTANDARDORTOOL:498](https://w3id.org/bridge2ai/standards-datastandardortool-schema/498)|[OntologyOrVocabulary](OntologyOrVocabulary)|RXNO|Name Reaction Ontology||
|| [STANDARDSDATATOPIC:8](STANDARDSDATATOPIC:8)| [STANDARDSORGANIZATION:31](STANDARDSORGANIZATION:31)|Information about finished drug products, unfinished drugs and compounded drug products|True|False|[https://www.accessdata.fda.gov/scripts/cder/ndc/index.cfm](https://www.accessdata.fda.gov/scripts/cder/ndc/index.cfm)|||[STANDARDSDATASTANDARDORTOOL:499](https://w3id.org/bridge2ai/standards-datastandardortool-schema/499)|[OntologyOrVocabulary](OntologyOrVocabulary)|NDC|National Drug Code||
| obofoundry|| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|An ontology representation of the NCBI organismal taxonomy.|True|False|[http://www.ncbi.nlm.nih.gov/taxonomy](http://www.ncbi.nlm.nih.gov/taxonomy)||[https://github.com/obophenotype/ncbitaxon](https://github.com/obophenotype/ncbitaxon)|[STANDARDSDATASTANDARDORTOOL:500](https://w3id.org/bridge2ai/standards-datastandardortool-schema/500)|[OntologyOrVocabulary](OntologyOrVocabulary)|NCBITAXON|NCBI organismal classification||
| obofoundry|| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|A reference terminology that includes broad coverage of the cancer domain, including cancer related diseases.|True|False|||[https://github.com/NCI-Thesaurus/thesaurus-obo-edition](https://github.com/NCI-Thesaurus/thesaurus-obo-edition)|[STANDARDSDATASTANDARDORTOOL:501](https://w3id.org/bridge2ai/standards-datastandardortool-schema/501)|[OntologyOrVocabulary](OntologyOrVocabulary)|NCIT|NCI Thesaurus OBO Edition||
| obofoundry|||Human and animal behaviours and behavioural phenotypes|True|False|||[https://github.com/obo-behavior/behavior-ontology/](https://github.com/obo-behavior/behavior-ontology/)|[STANDARDSDATASTANDARDORTOOL:502](https://w3id.org/bridge2ai/standards-datastandardortool-schema/502)|[OntologyOrVocabulary](OntologyOrVocabulary)|NBO|Neuro Behavior Ontology||
|| [STANDARDSDATATOPIC:22](STANDARDSDATATOPIC:22)||A Comprehensive Hierarchical Nomenclature for Structures of the Primate Brain (human and macaque)|True|False|[http://braininfo.rprc.washington.edu/aboutBrainInfo.aspx#NeuroNames](http://braininfo.rprc.washington.edu/aboutBrainInfo.aspx#NeuroNames)|[doi:10.1007/s12021-011-9128-8](doi:10.1007/s12021-011-9128-8)||[STANDARDSDATASTANDARDORTOOL:503](https://w3id.org/bridge2ai/standards-datastandardortool-schema/503)|[OntologyOrVocabulary](OntologyOrVocabulary)|NeuroNames|Neuronames Brain Hierarchy||
| obofoundry|||A nomenclatural ontology for biological names (not concepts). It encodes the goverened rules of nomenclature.|True|False|||[https://github.com/SpeciesFileGroup/nomen](https://github.com/SpeciesFileGroup/nomen)|[STANDARDSDATASTANDARDORTOOL:504](https://w3id.org/bridge2ai/standards-datastandardortool-schema/504)|[OntologyOrVocabulary](OntologyOrVocabulary)|NOMEN|Nomenclatural ontology for biological names||
| obofoundry| [STANDARDSDATATOPIC:33](STANDARDSDATATOPIC:33)||An ontology for non-coding RNA, both of biological origin, and engineered.|True|False|||[https://github.com/OmniSearch/ncro](https://github.com/OmniSearch/ncro)|[STANDARDSDATASTANDARDORTOOL:505](https://w3id.org/bridge2ai/standards-datastandardortool-schema/505)|[OntologyOrVocabulary](OntologyOrVocabulary)|NCRO|Non-Coding RNA Ontology||
| obofoundry|||Terms for nutrition assessment, diagnosis, intervention, and monitoring/evaluation.|False|True|[https://www.ncpro.org/](https://www.ncpro.org/)|||[STANDARDSDATASTANDARDORTOOL:506](https://w3id.org/bridge2ai/standards-datastandardortool-schema/506)|[OntologyOrVocabulary](OntologyOrVocabulary)|NCPT|Nutrition Care Process Terminology||
| obofoundry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Terms that are used to annotate ontology terms for all OBO ontologies.|True|False|||[https://github.com/information-artifact-ontology/ontology-metadata](https://github.com/information-artifact-ontology/ontology-metadata)|[STANDARDSDATASTANDARDORTOOL:507](https://w3id.org/bridge2ai/standards-datastandardortool-schema/507)|[OntologyOrVocabulary](OntologyOrVocabulary)|OMO|OBO Metadata Ontology||
| obofoundry|||A structured controlled vocabulary to provide a representation of the data from electronic health records involved in the care of pregnancy.|True|False|||[https://github.com/ontoneo-project/Ontoneo](https://github.com/ontoneo-project/Ontoneo)|[STANDARDSDATASTANDARDORTOOL:508](https://w3id.org/bridge2ai/standards-datastandardortool-schema/508)|[OntologyOrVocabulary](OntologyOrVocabulary)|ONTONEO|Obstetric and Neonatal Ontology||
| obofoundry|||Vocabulary for the description of the most widely-used computational approach for studying digital evolution.|True|False|||[https://gitlab.com/fortunalab/ontoavida](https://gitlab.com/fortunalab/ontoavida)|[STANDARDSDATASTANDARDORTOOL:509](https://w3id.org/bridge2ai/standards-datastandardortool-schema/509)|[OntologyOrVocabulary](OntologyOrVocabulary)|ONTOAVIDA|OntoAvida ontology for Avida digital evolution platform||
| obofoundry|||Annotation and modeling of biobank repository and biobanking administration.|True|False|||[https://github.com/biobanking/biobanking](https://github.com/biobanking/biobanking)|[STANDARDSDATASTANDARDORTOOL:510](https://w3id.org/bridge2ai/standards-datastandardortool-schema/510)|[OntologyOrVocabulary](OntologyOrVocabulary)|OBIB|Ontology for Biobanking||
| obofoundry|||Description of life-science and clinical investigations.|True|False|[http://obi-ontology.org](http://obi-ontology.org)|[doi:10.1371/journal.pone.0154556](doi:10.1371/journal.pone.0154556)|[https://github.com/obi-ontology/obi](https://github.com/obi-ontology/obi)|[STANDARDSDATASTANDARDORTOOL:511](https://w3id.org/bridge2ai/standards-datastandardortool-schema/511)|[OntologyOrVocabulary](OntologyOrVocabulary)|OBI|Ontology for Biomedical Investigations||
| obofoundry| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4) [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||Treatment of disease and diagnosis and on carcinomas and other pathological entities.|True|False|||[https://github.com/OGMS/ogms](https://github.com/OGMS/ogms)|[STANDARDSDATASTANDARDORTOOL:512](https://w3id.org/bridge2ai/standards-datastandardortool-schema/512)|[OntologyOrVocabulary](OntologyOrVocabulary)|OGMS|Ontology for General Medical Science||
| obofoundry|||Data exchange standards and common data elements in the microRNA (miR) domain.|True|False|||[https://github.com/OmniSearch/omit](https://github.com/OmniSearch/omit)|[STANDARDSDATASTANDARDORTOOL:513](https://w3id.org/bridge2ai/standards-datastandardortool-schema/513)|[OntologyOrVocabulary](OntologyOrVocabulary)|OMIT|Ontology for MIRNA Target||
| obofoundry|||Research output of nutritional epidemiologic studies.|True|False||[doi:10.3390/nu11061300](doi:10.3390/nu11061300)|[https://github.com/cyang0128/Nutritional-epidemiologic-ontologies](https://github.com/cyang0128/Nutritional-epidemiologic-ontologies)|[STANDARDSDATASTANDARDORTOOL:514](https://w3id.org/bridge2ai/standards-datastandardortool-schema/514)|[OntologyOrVocabulary](OntologyOrVocabulary)|ONE|Ontology for Nutritional Epidemiology||
| obofoundry|||Description of concepts in the nutritional studies domain.|True|False||[doi:10.1186/s12263-018-0601-y](doi:10.1186/s12263-018-0601-y)|[https://github.com/enpadasi/Ontology-for-Nutritional-Studies](https://github.com/enpadasi/Ontology-for-Nutritional-Studies)|[STANDARDSDATASTANDARDORTOOL:515](https://w3id.org/bridge2ai/standards-datastandardortool-schema/515)|[OntologyOrVocabulary](OntologyOrVocabulary)|ONS|Ontology for Nutritional Studies||
| obofoundry| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4) [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||Adverse clinical events.|True|False|||[https://github.com/OAE-ontology/OAE/](https://github.com/OAE-ontology/OAE/)|[STANDARDSDATASTANDARDORTOOL:516](https://w3id.org/bridge2ai/standards-datastandardortool-schema/516)|[OntologyOrVocabulary](OntologyOrVocabulary)|OAE|Ontology of Adverse Events||
| obofoundry|||Biological and clinical statistics.|True|False|||[https://github.com/obcs/obcs](https://github.com/obcs/obcs)|[STANDARDSDATASTANDARDORTOOL:517](https://w3id.org/bridge2ai/standards-datastandardortool-schema/517)|[OntologyOrVocabulary](OntologyOrVocabulary)|OBCS|Ontology of Biological and Clinical Statistics||
| obofoundry|||A collection of biological attributes (traits) covering all kingdoms of life.|True|False|[https://wiki.geneontology.org/index.php/Extensions/x-attribute](https://wiki.geneontology.org/index.php/Extensions/x-attribute)||[https://github.com/obophenotype/bio-attribute-ontology](https://github.com/obophenotype/bio-attribute-ontology)|[STANDARDSDATASTANDARDORTOOL:518](https://w3id.org/bridge2ai/standards-datastandardortool-schema/518)|[OntologyOrVocabulary](OntologyOrVocabulary)|OBA|Ontology of Biological Attributes||
| obofoundry|||An application ontology to represent genetic susceptibility to a specific disease, adverse event, or a pathological process.|True|False|||[https://github.com/linikujp/OGSF](https://github.com/linikujp/OGSF)|[STANDARDSDATASTANDARDORTOOL:519](https://w3id.org/bridge2ai/standards-datastandardortool-schema/519)|[OntologyOrVocabulary](OntologyOrVocabulary)|OGSF|Ontology of Genetic Susceptibility Factor||
| obofoundry|||Host-pathogen interactions and virulence factors.|True|False||[doi:10.1093/nar/gky999](doi:10.1093/nar/gky999)|[https://github.com/OHPI/ohpi](https://github.com/OHPI/ohpi)|[STANDARDSDATASTANDARDORTOOL:520](https://w3id.org/bridge2ai/standards-datastandardortool-schema/520)|[OntologyOrVocabulary](OntologyOrVocabulary)|OHPI|Ontology of Host Pathogen Interactions||
| obofoundry|||Entities and relations related to microbiomes, microbiome host organisms (e.g., human and mouse), and the interactions between the hosts and microbiomes at different conditions.|True|False|||[https://github.com/ohmi-ontology/ohmi](https://github.com/ohmi-ontology/ohmi)|[STANDARDSDATASTANDARDORTOOL:521](https://w3id.org/bridge2ai/standards-datastandardortool-schema/521)|[OntologyOrVocabulary](OntologyOrVocabulary)|OHMI|Ontology of Host-Microbiome Interactions||
| obofoundry|||This ontology covers the domain of social entities that are related to health care, such as demographic information and the roles of various...|True|False|[https://github.com/ufbmi/OMRSE/wiki/OMRSE-Overview](https://github.com/ufbmi/OMRSE/wiki/OMRSE-Overview)|[doi:10.1186/s13326-016-0087-8](doi:10.1186/s13326-016-0087-8)|[https://github.com/ufbmi/OMRSE](https://github.com/ufbmi/OMRSE)|[STANDARDSDATASTANDARDORTOOL:522](https://w3id.org/bridge2ai/standards-datastandardortool-schema/522)|[OntologyOrVocabulary](OntologyOrVocabulary)|OMRSE|Ontology of Medically Related Social Entities||
| obofoundry|| [UFBMI](UFBMI)|Organizational components of trauma centers and trauma systems.|True|False|||[https://github.com/OOSTT/OOSTT](https://github.com/OOSTT/OOSTT)|[STANDARDSDATASTANDARDORTOOL:523](https://w3id.org/bridge2ai/standards-datastandardortool-schema/523)|[OntologyOrVocabulary](OntologyOrVocabulary)|OOSTT|Ontology of Organizational Structures of Trauma centers and Trauma systems||
| obofoundry|||Entities and relations associated with precision medicine and related investigations at different conditions.|True|False|||[https://github.com/OPMI/opmi](https://github.com/OPMI/opmi)|[STANDARDSDATASTANDARDORTOOL:524](https://w3id.org/bridge2ai/standards-datastandardortool-schema/524)|[OntologyOrVocabulary](OntologyOrVocabulary)|OPMI|Ontology of Precision Medicine and Investigation||
| obofoundry| [STANDARDSDATATOPIC:33](STANDARDSDATATOPIC:33)||An application ontology designed to annotate next-generation sequencing experiments performed on RNA.|True|False|||[https://github.com/safisher/ornaseq](https://github.com/safisher/ornaseq)|[STANDARDSDATASTANDARDORTOOL:525](https://w3id.org/bridge2ai/standards-datastandardortool-schema/525)|[OntologyOrVocabulary](OntologyOrVocabulary)|ORNASEQ|Ontology of RNA Sequencing||
| obofoundry| [STANDARDSDATATOPIC:4, Disease](STANDARDSDATATOPIC:4, Disease)||A biomedical ontology in the domain of vaccine adverse events.|True|False|||[https://github.com/OVAE-Ontology/ovae](https://github.com/OVAE-Ontology/ovae)|[STANDARDSDATASTANDARDORTOOL:526](https://w3id.org/bridge2ai/standards-datastandardortool-schema/526)|[OntologyOrVocabulary](OntologyOrVocabulary)|OVAE|Ontology of Vaccine Adverse Events||
| obofoundry| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||Content of dental practice health records.|True|False||[doi:10.1186/s13326-020-00222-0](doi:10.1186/s13326-020-00222-0)|[https://github.com/oral-health-and-disease-ontologies/ohd-ontology](https://github.com/oral-health-and-disease-ontologies/ohd-ontology)|[STANDARDSDATASTANDARDORTOOL:527](https://w3id.org/bridge2ai/standards-datastandardortool-schema/527)|[OntologyOrVocabulary](OntologyOrVocabulary)|OHD|Oral Health and Disease Ontology||
|| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)| [Orphanet](Orphanet)|The Orphanet Rare Disease ontology (ORDO) is jointly developed by Orphanet and the EBI to provide a structured vocabulary for rare diseases capturing relationships between diseases, genes and other relevant features which will form a useful resource for the computational analysis of rare diseases.|True|False|[https://bioportal.bioontology.org/ontologies/ORDO](https://bioportal.bioontology.org/ontologies/ORDO)||[https://www.orphadata.com/ontologies/](https://www.orphadata.com/ontologies/)|[STANDARDSDATASTANDARDORTOOL:528](https://w3id.org/bridge2ai/standards-datastandardortool-schema/528)|[OntologyOrVocabulary](OntologyOrVocabulary)|ORDO|Orphanet Rare Disease Ontology||
| obofoundry|||Species-neutral phenotypes observed in pathogen-host interactions.|True|False||[doi:10.1093/nar/gkab1037](doi:10.1093/nar/gkab1037)|[https://github.com/PHI-base/phipo](https://github.com/PHI-base/phipo)|[STANDARDSDATASTANDARDORTOOL:529](https://w3id.org/bridge2ai/standards-datastandardortool-schema/529)|[OntologyOrVocabulary](OntologyOrVocabulary)|PHIPO|Pathogen Host Interaction Phenotype Ontology||
| obofoundry| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)||An ontology representing the disease transmission process during which the pathogen is transmitted directly or indirectly.|True|False||[doi:10.1093/nar/gkp832](doi:10.1093/nar/gkp832)|[https://github.com/DiseaseOntology/PathogenTransmissionOntology](https://github.com/DiseaseOntology/PathogenTransmissionOntology)|[STANDARDSDATASTANDARDORTOOL:530](https://w3id.org/bridge2ai/standards-datastandardortool-schema/530)|[OntologyOrVocabulary](OntologyOrVocabulary)|TRANS|Pathogen Transmission Ontology||
| obofoundry| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||A controlled vocabulary for annotating gene products to pathways.|True|False|[http://rgd.mcw.edu/rgdweb/ontology/search.html](http://rgd.mcw.edu/rgdweb/ontology/search.html)|[doi:10.1186/2041-1480-5-7](doi:10.1186/2041-1480-5-7)|[https://github.com/rat-genome-database/PW-Pathway-Ontology](https://github.com/rat-genome-database/PW-Pathway-Ontology)|[STANDARDSDATASTANDARDORTOOL:531](https://w3id.org/bridge2ai/standards-datastandardortool-schema/531)|[OntologyOrVocabulary](OntologyOrVocabulary)|PW|Pathway ontology||
| obofoundry| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)||Ontology to reproducibly study visualizations of clinical performance|True|False|||[https://github.com/Display-Lab/psdo](https://github.com/Display-Lab/psdo)|[STANDARDSDATASTANDARDORTOOL:532](https://w3id.org/bridge2ai/standards-datastandardortool-schema/532)|[OntologyOrVocabulary](OntologyOrVocabulary)|PSDO|Performance Summary Display Ontology||
|| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3) [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7) [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21) [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|An application ontology for accessing and comparing knowledge concerning phenotypes across species and genetic backgrounds.|True|False|||[https://github.com/monarch-initiative/phenio](https://github.com/monarch-initiative/phenio)|[STANDARDSDATASTANDARDORTOOL:533](https://w3id.org/bridge2ai/standards-datastandardortool-schema/533)|[OntologyOrVocabulary](OntologyOrVocabulary)|PHENIO|Phenomics Integrated Ontology||
| obofoundry| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)||Phenotypic qualities (properties, attributes or characteristics).|True|False|||[https://github.com/pato-ontology/pato](https://github.com/pato-ontology/pato)|[STANDARDSDATASTANDARDORTOOL:534](https://w3id.org/bridge2ai/standards-datastandardortool-schema/534)|[OntologyOrVocabulary](OntologyOrVocabulary)|PATO|Phenotype And Trait Ontology||
| obofoundry|||Groups of interacting organisms such as populations and communities.|True|False|||[https://github.com/PopulationAndCommunityOntology/pco](https://github.com/PopulationAndCommunityOntology/pco)|[STANDARDSDATASTANDARDORTOOL:535](https://w3id.org/bridge2ai/standards-datastandardortool-schema/535)|[OntologyOrVocabulary](OntologyOrVocabulary)|PCO|Population and Community Ontology||
| obofoundry| [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)||Process chemistry, the chemical field concerned with scaling up laboratory syntheses to commercially viable processes.|True|False|||[https://github.com/proco-ontology/PROCO](https://github.com/proco-ontology/PROCO)|[STANDARDSDATASTANDARDORTOOL:536](https://w3id.org/bridge2ai/standards-datastandardortool-schema/536)|[OntologyOrVocabulary](OntologyOrVocabulary)|PROCO|Process Chemistry Ontology||
| obofoundry| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)| [STANDARDSORGANIZATION:41](STANDARDSORGANIZATION:41)|PSI-MOD is an ontology consisting of terms that describe protein chemical modifications|True|False|[https://www.psidev.info/groups/protein-modifications](https://www.psidev.info/groups/protein-modifications)|[doi:10.1038/nbt0808-864](doi:10.1038/nbt0808-864)|[https://github.com/HUPO-PSI/psi-mod-CV](https://github.com/HUPO-PSI/psi-mod-CV)|[STANDARDSDATASTANDARDORTOOL:537](https://w3id.org/bridge2ai/standards-datastandardortool-schema/537)|[OntologyOrVocabulary](OntologyOrVocabulary)|PSI-MOD|Protein modification||
| obofoundry| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)||An ontological representation of protein-related entities|True|False|||[https://github.com/PROconsortium/PRoteinOntology/](https://github.com/PROconsortium/PRoteinOntology/)|[STANDARDSDATASTANDARDORTOOL:538](https://w3id.org/bridge2ai/standards-datastandardortool-schema/538)|[OntologyOrVocabulary](OntologyOrVocabulary)|PR|PRotein Ontology||
| obofoundry| [STANDARDSDATATOPIC:2](STANDARDSDATATOPIC:2)||Cell types that are provisionally defined by experimental techniques such as single cell or single nucleus transcriptomics.|True|False|||[https://github.com/obophenotype/provisional_cell_ontology](https://github.com/obophenotype/provisional_cell_ontology)|[STANDARDSDATASTANDARDORTOOL:539](https://w3id.org/bridge2ai/standards-datastandardortool-schema/539)|[OntologyOrVocabulary](OntologyOrVocabulary)|PCL|Provisional Cell Ontology||
| obofoundry| [STANDARDSDATATOPIC:1, Environment](STANDARDSDATATOPIC:1, Environment)||Effects of radiation on biota in terrestrial and space environments.|True|False|||[https://github.com/Radiobiology-Informatics-Consortium/RBO](https://github.com/Radiobiology-Informatics-Consortium/RBO)|[STANDARDSDATASTANDARDORTOOL:540](https://w3id.org/bridge2ai/standards-datastandardortool-schema/540)|[OntologyOrVocabulary](OntologyOrVocabulary)|RBO|Radiation Biology Ontology||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [RSNA](RSNA)|A comprehensive set of radiology terms for use in radiology reporting, decision support, data mining, data registries, education and research.|True|True|[https://www.rsna.org/practice-tools/data-tools-and-standards/radlex-radiology-lexicon](https://www.rsna.org/practice-tools/data-tools-and-standards/radlex-radiology-lexicon)|||[STANDARDSDATASTANDARDORTOOL:541](https://w3id.org/bridge2ai/standards-datastandardortool-schema/541)|[OntologyOrVocabulary](OntologyOrVocabulary)|RadLex|RadLex radiology lexicon||
| obofoundry|||Ontology of rat strains.|True|False|[http://rgd.mcw.edu/rgdweb/search/strains.html](http://rgd.mcw.edu/rgdweb/search/strains.html)|[doi:10.1186/2041-1480-4-36](doi:10.1186/2041-1480-4-36)|[https://github.com/rat-genome-database/RS-Rat-Strain-Ontology](https://github.com/rat-genome-database/RS-Rat-Strain-Ontology)|[STANDARDSDATASTANDARDORTOOL:542](https://w3id.org/bridge2ai/standards-datastandardortool-schema/542)|[OntologyOrVocabulary](OntologyOrVocabulary)|RS|Rat Strain Ontology||
| obofoundry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Relationship types shared across multiple ontologies.|True|False|[https://oborel.github.io/](https://oborel.github.io/)||[https://github.com/oborel/obo-relations](https://github.com/oborel/obo-relations)|[STANDARDSDATASTANDARDORTOOL:543](https://w3id.org/bridge2ai/standards-datastandardortool-schema/543)|[OntologyOrVocabulary](OntologyOrVocabulary)|RO|Relation Ontology||
| codesystem| [STANDARDSDATATOPIC:8](STANDARDSDATATOPIC:8)| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|Medication terminology. Provided through UMLS.|True|True|[https://www.nlm.nih.gov/research/umls/rxnorm/index.html](https://www.nlm.nih.gov/research/umls/rxnorm/index.html)|||[STANDARDSDATASTANDARDORTOOL:544](https://w3id.org/bridge2ai/standards-datastandardortool-schema/544)|[OntologyOrVocabulary](OntologyOrVocabulary)|RxNorm|RxNorm||
| obofoundry|| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|Provenance of scientific claims and the evidence that supports them.|True|False|||[https://github.com/monarch-initiative/SEPIO-ontology](https://github.com/monarch-initiative/SEPIO-ontology)|[STANDARDSDATASTANDARDORTOOL:545](https://w3id.org/bridge2ai/standards-datastandardortool-schema/545)|[OntologyOrVocabulary](OntologyOrVocabulary)|SEPIO|Scientific Evidence and Provenance Information Ontology||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:99](STANDARDSORGANIZATION:99)|An ontology for describing sensors and their observations, the involved procedures, the studied features of interest, the samples used to do so, and the observed properties, as well as actuators.|True|False|[https://www.w3.org/TR/vocab-ssn/](https://www.w3.org/TR/vocab-ssn/)||[https://github.com/w3c/sdw](https://github.com/w3c/sdw)|[STANDARDSDATASTANDARDORTOOL:546](https://w3id.org/bridge2ai/standards-datastandardortool-schema/546)|[OntologyOrVocabulary](OntologyOrVocabulary)|SSN|Semantic Sensor Network Ontology||
| obofoundry|||A structured controlled vocabulary for sequence annotation, for the exchange of annotation data and for the description of sequence objects.|True|False|[http://www.sequenceontology.org/](http://www.sequenceontology.org/)|[doi:10.1016/j.jbi.2010.03.002](doi:10.1016/j.jbi.2010.03.002)|[https://github.com/The-Sequence-Ontology/SO-Ontologies](https://github.com/The-Sequence-Ontology/SO-Ontologies)|[STANDARDSDATASTANDARDORTOOL:547](https://w3id.org/bridge2ai/standards-datastandardortool-schema/547)|[OntologyOrVocabulary](OntologyOrVocabulary)|SO|Sequence types and features ontology||
| obofoundry|||Sickle Cell Disease terminology.|True|False|[https://scdontology.h3abionet.org/](https://scdontology.h3abionet.org/)||[https://github.com/scdodev/scdo-ontology](https://github.com/scdodev/scdo-ontology)|[STANDARDSDATASTANDARDORTOOL:548](https://w3id.org/bridge2ai/standards-datastandardortool-schema/548)|[OntologyOrVocabulary](OntologyOrVocabulary)|SCDO|Sickle Cell Disease Ontology||
| obofoundry|||Software tools, their types, tasks, versions, provenance and associated data.|True|False||[doi:10.1186/2041-1480-5-25](doi:10.1186/2041-1480-5-25)|[https://github.com/allysonlister/swo](https://github.com/allysonlister/swo)|[STANDARDSDATASTANDARDORTOOL:549](https://w3id.org/bridge2ai/standards-datastandardortool-schema/549)|[OntologyOrVocabulary](OntologyOrVocabulary)|SWO|Software ontology||
||| [STANDARDSORGANIZATION:3](STANDARDSORGANIZATION:3)|Translate each code descriptor from the official CPT code set into language that is easily understood by the average patient and/or his or her caregiver. The objective is to simplify the highly technical CPT code descriptors into something more patient-focused and patient-friendly.|False|True|[https://commerce.ama-assn.org/catalog/media/Consumer-and-Clinician-Descriptors-in-CPT-Data-Files.pdf](https://commerce.ama-assn.org/catalog/media/Consumer-and-Clinician-Descriptors-in-CPT-Data-Files.pdf)|||[STANDARDSDATASTANDARDORTOOL:550](https://w3id.org/bridge2ai/standards-datastandardortool-schema/550)|[OntologyOrVocabulary](OntologyOrVocabulary)|CFDs|Standard Current Procedural Terminology Consumer Friendly Descriptors||
| obofoundry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:47](STANDARDSORGANIZATION:47)|Statistical tests and methods|True|False|[http://stato-ontology.org/](http://stato-ontology.org/)||[https://github.com/ISA-tools/stato](https://github.com/ISA-tools/stato)|[STANDARDSDATASTANDARDORTOOL:551](https://w3id.org/bridge2ai/standards-datastandardortool-schema/551)|[OntologyOrVocabulary](OntologyOrVocabulary)|STATO|Statistics Ontology||
| obofoundry|||Disease symptoms, with symptoms encompasing perceived changes in function, sensations or appearance reported by a patient.|True|False|[http://symptomontologywiki.igs.umaryland.edu/mediawiki/index.php/Main_Page](http://symptomontologywiki.igs.umaryland.edu/mediawiki/index.php/Main_Page)|[doi:10.1093/nar/gkab1063](doi:10.1093/nar/gkab1063)|[https://github.com/DiseaseOntology/SymptomOntology](https://github.com/DiseaseOntology/SymptomOntology)|[STANDARDSDATASTANDARDORTOOL:552](https://w3id.org/bridge2ai/standards-datastandardortool-schema/552)|[OntologyOrVocabulary](OntologyOrVocabulary)|SYMP|Symptom Ontology||
| codesystem| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|Standard for electronic exchange of clinical health information. Provided through UMLS.|True|True|[https://www.nlm.nih.gov/healthit/snomedct/index.html](https://www.nlm.nih.gov/healthit/snomedct/index.html)|||[STANDARDSDATASTANDARDORTOOL:553](https://w3id.org/bridge2ai/standards-datastandardortool-schema/553)|[OntologyOrVocabulary](OntologyOrVocabulary)|SNOMED CT|Systematized Nomenclature of Medicine - Clinical Terms||
||| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|SNOMED, not SNOMED-CT|True|False|[https://bioportal.bioontology.org/ontologies/SNMI](https://bioportal.bioontology.org/ontologies/SNMI)|||[STANDARDSDATASTANDARDORTOOL:554](https://w3id.org/bridge2ai/standards-datastandardortool-schema/554)|[OntologyOrVocabulary](OntologyOrVocabulary)|SNMI|Systematized Nomenclature of Medicine, International Version||
| obofoundry| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)| [STANDARDSORGANIZATION:29](STANDARDSORGANIZATION:29)|Terms commonly used in Systems Biology and computational modeling.|True|False|||[https://github.com/EBI-BioModels/SBO](https://github.com/EBI-BioModels/SBO)|[STANDARDSDATASTANDARDORTOOL:555](https://w3id.org/bridge2ai/standards-datastandardortool-schema/555)|[OntologyOrVocabulary](OntologyOrVocabulary)|SBO|Systems Biology Ontology||
| obofoundry| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)||A vocabulary of taxonomic ranks (species, family, phylum, etc).|True|False||[doi:10.1186/2041-1480-4-34](doi:10.1186/2041-1480-4-34)|[https://github.com/phenoscape/taxrank](https://github.com/phenoscape/taxrank)|[STANDARDSDATASTANDARDORTOOL:556](https://w3id.org/bridge2ai/standards-datastandardortool-schema/556)|[OntologyOrVocabulary](OntologyOrVocabulary)|TAXRANK|Taxonomic rank vocabulary||
| obofoundry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A terminology for the skills necessary to make data FAIR and to keep it FAIR.|True|False|[https://obofoundry.org/ontology/t4fs.html](https://obofoundry.org/ontology/t4fs.html)|[doi:10.5281/zenodo.4772741](doi:10.5281/zenodo.4772741)|[https://github.com/terms4fairskills/FAIRterminology](https://github.com/terms4fairskills/FAIRterminology)|[STANDARDSDATASTANDARDORTOOL:557](https://w3id.org/bridge2ai/standards-datastandardortool-schema/557)|[OntologyOrVocabulary](OntologyOrVocabulary)|T4FS|terms4FAIRskills||
| obofoundry| [STANDARDSDATATOPIC:8](STANDARDSDATATOPIC:8)| [UFBMI](UFBMI)|An ontology to support comparative effectiveness researchers studying claims data.|True|False||[doi:10.1186/s13326-017-0121-5](doi:10.1186/s13326-017-0121-5)|[https://github.com/ufbmi/dron](https://github.com/ufbmi/dron)|[STANDARDSDATASTANDARDORTOOL:558](https://w3id.org/bridge2ai/standards-datastandardortool-schema/558)|[OntologyOrVocabulary](OntologyOrVocabulary)|DRON|The Drug Ontology||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [NCEAS](NCEAS)|The Extensible Observation Ontology (OBOE) is a formal ontology for capturing the semantics of scientific observation and measurement.|True|False|[https://bioportal.bioontology.org/ontologies/OBOE](https://bioportal.bioontology.org/ontologies/OBOE)||[https://github.com/NCEAS/oboe/](https://github.com/NCEAS/oboe/)|[STANDARDSDATASTANDARDORTOOL:559](https://w3id.org/bridge2ai/standards-datastandardortool-schema/559)|[OntologyOrVocabulary](OntologyOrVocabulary)|OBOE|The Extensible Observation Ontology||
| obofoundry| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A formal ontology of genes and genomes of biological organisms.|True|False|||[https://bitbucket.org/hegroup/ogg/src/master/](https://bitbucket.org/hegroup/ogg/src/master/)|[STANDARDSDATASTANDARDORTOOL:560](https://w3id.org/bridge2ai/standards-datastandardortool-schema/560)|[OntologyOrVocabulary](OntologyOrVocabulary)|OGG|The Ontology of Genes and Genomes||
| obofoundry| [STANDARDSDATATOPIC:8](STANDARDSDATATOPIC:8)||An ontology to describe entities related to prescription of drugs|True|False||[doi:10.3390/ijerph182212025](doi:10.3390/ijerph182212025)|[https://github.com/OpenLHS/PDRO](https://github.com/OpenLHS/PDRO)|[STANDARDSDATASTANDARDORTOOL:561](https://w3id.org/bridge2ai/standards-datastandardortool-schema/561)|[OntologyOrVocabulary](OntologyOrVocabulary)|PDRO|The Prescription of Drugs Ontology||
| obofoundry|||Terms involving toxicity courses and processes.|True|False|[https://toxpilot.nibiohn.go.jp/](https://toxpilot.nibiohn.go.jp/)||[https://github.com/txpo-ontology/TXPO/](https://github.com/txpo-ontology/TXPO/)|[STANDARDSDATASTANDARDORTOOL:562](https://w3id.org/bridge2ai/standards-datastandardortool-schema/562)|[OntologyOrVocabulary](OntologyOrVocabulary)|TXPO|Toxic Process Ontology||
| obofoundry|||Anatomy|True|False|[https://obophenotype.github.io/uberon/](https://obophenotype.github.io/uberon/)|[doi:10.1186/gb-2012-13-1-r5](doi:10.1186/gb-2012-13-1-r5)|[https://github.com/obophenotype/uberon](https://github.com/obophenotype/uberon)|[STANDARDSDATASTANDARDORTOOL:563](https://w3id.org/bridge2ai/standards-datastandardortool-schema/563)|[OntologyOrVocabulary](OntologyOrVocabulary)|UBERON|Uberon||
||| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|Biomedical terminology and hierarchical relationships between concepts.|True|True|[https://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/index.html](https://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/index.html)|||[STANDARDSDATASTANDARDORTOOL:564](https://w3id.org/bridge2ai/standards-datastandardortool-schema/564)|[OntologyOrVocabulary](OntologyOrVocabulary)|Metathesaurus|UMLS Metathesaurus||
| obofoundry| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)||Integrates multiple phenotype ontologies into a unified cross-species phenotype ontology.|True|False|||[https://github.com/obophenotype/upheno](https://github.com/obophenotype/upheno)|[STANDARDSDATASTANDARDORTOOL:565](https://w3id.org/bridge2ai/standards-datastandardortool-schema/565)|[OntologyOrVocabulary](OntologyOrVocabulary)|UPHENO|Unified phenotype ontology||
| obofoundry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||The Units Ontology - a tool for integrating units of measurement in science|True|False|[https://obofoundry.org/ontology/uo.html](https://obofoundry.org/ontology/uo.html)|[doi:10.1093/database/bas033](doi:10.1093/database/bas033)||[STANDARDSDATASTANDARDORTOOL:566](https://w3id.org/bridge2ai/standards-datastandardortool-schema/566)|[OntologyOrVocabulary](OntologyOrVocabulary)|UO|Units of measure ontology||
| obofoundry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Metrical units for use in conjunction with PATO.|True|False|||[https://github.com/bio-ontology-research-group/unit-ontology](https://github.com/bio-ontology-research-group/unit-ontology)|[STANDARDSDATASTANDARDORTOOL:567](https://w3id.org/bridge2ai/standards-datastandardortool-schema/567)|[OntologyOrVocabulary](OntologyOrVocabulary)|UO|Units of measurement ontology||
||| [ECRI](ECRI)|Universal Medical Device Nomenclature System (UMDNS) is a nomenclature that has been officially adopted by many nations. UMDNS facilitates identifying, processing, filing, storing, retrieving, transferring, and communicating data about medical devices. The nomenclature is used in applications ranging from hospital inventory and work-order controls to national agency medical device regulatory systems.|False|True|[https://www.ecri.org/solutions/umdns](https://www.ecri.org/solutions/umdns)|||[STANDARDSDATASTANDARDORTOOL:568](https://w3id.org/bridge2ai/standards-datastandardortool-schema/568)|[OntologyOrVocabulary](OntologyOrVocabulary)|UMDNS|Universal Medical Device Nomenclature System||
| obofoundry|||Vaccine and vaccination ontology.|True|False||[doi:10.1186/2041-1480-3-17](doi:10.1186/2041-1480-3-17)|[https://github.com/vaccineontology/VO](https://github.com/vaccineontology/VO)|[STANDARDSDATASTANDARDORTOOL:569](https://w3id.org/bridge2ai/standards-datastandardortool-schema/569)|[OntologyOrVocabulary](OntologyOrVocabulary)|VO|Vaccine Ontology||
| obofoundry|| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|Vertebrate breed names.|True|False|||[https://github.com/monarch-initiative/vertebrate-breed-ontology](https://github.com/monarch-initiative/vertebrate-breed-ontology)|[STANDARDSDATASTANDARDORTOOL:570](https://w3id.org/bridge2ai/standards-datastandardortool-schema/570)|[OntologyOrVocabulary](OntologyOrVocabulary)|VBO|Vertebrate Breed Ontology||
| obofoundry|||Extinct and extant vertebrate taxa.|True|False|||[https://github.com/phenoscape/vertebrate-taxonomy-ontology](https://github.com/phenoscape/vertebrate-taxonomy-ontology)|[STANDARDSDATASTANDARDORTOOL:571](https://w3id.org/bridge2ai/standards-datastandardortool-schema/571)|[OntologyOrVocabulary](OntologyOrVocabulary)|VTO|Vertebrate Taxonomy Ontology||
| obofoundry| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)||Traits covering vertebrates.|True|False|||[https://github.com/AnimalGenome/vertebrate-trait-ontology](https://github.com/AnimalGenome/vertebrate-trait-ontology)|[STANDARDSDATASTANDARDORTOOL:572](https://w3id.org/bridge2ai/standards-datastandardortool-schema/572)|[OntologyOrVocabulary](OntologyOrVocabulary)|VT|Vertebrate trait ontology||
| obofoundry|||Support ontology for the Eukaryotic Pathogen, Host & Vector Genomics Resource (VEuPathDB; https://veupathdb.org).|True|False||[doi:10.5281/zenodo.6685957](doi:10.5281/zenodo.6685957)|[https://github.com/VEuPathDB-ontology/VEuPathDB-ontology](https://github.com/VEuPathDB-ontology/VEuPathDB-ontology)|[STANDARDSDATASTANDARDORTOOL:573](https://w3id.org/bridge2ai/standards-datastandardortool-schema/573)|[OntologyOrVocabulary](OntologyOrVocabulary)|EUPATH|VEuPathDB ontology||
| obofoundry| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)||Anatomical, cellular, and gene function phenotypes occurring throughout the development of Xenopus laevis.|True|False||[doi:10.1186/s12859-022-04636-8](doi:10.1186/s12859-022-04636-8)|[https://github.com/obophenotype/xenopus-phenotype-ontology](https://github.com/obophenotype/xenopus-phenotype-ontology)|[STANDARDSDATASTANDARDORTOOL:574](https://w3id.org/bridge2ai/standards-datastandardortool-schema/574)|[OntologyOrVocabulary](OntologyOrVocabulary)|XPO|Xenopus Phenotype Ontology||
| obofoundry| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)||All phenotypes of the Zebrafish model organism.|True|False|||[https://github.com/obophenotype/zebrafish-phenotype-ontology](https://github.com/obophenotype/zebrafish-phenotype-ontology)|[STANDARDSDATASTANDARDORTOOL:575](https://w3id.org/bridge2ai/standards-datastandardortool-schema/575)|[OntologyOrVocabulary](OntologyOrVocabulary)|ZP|Zebrafish Phenotype Ontology||
|| [Demographics](Demographics)| [CDC](CDC) [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|A code set for use in coding race and ethnicity data.|True|False|[https://www.cdc.gov/phin/resources/vocabulary/documents/cdc-race--ethnicity-background-and-purpose.pdf](https://www.cdc.gov/phin/resources/vocabulary/documents/cdc-race--ethnicity-background-and-purpose.pdf)||[https://phinvads.cdc.gov/vads/ViewValueSet.action?id=B246B692-6DF8-E111-B875-001A4BE7FA90](https://phinvads.cdc.gov/vads/ViewValueSet.action?id=B246B692-6DF8-E111-B875-001A4BE7FA90)|[STANDARDSDATASTANDARDORTOOL:576](https://w3id.org/bridge2ai/standards-datastandardortool-schema/576)|[DataStandardOrTool](DataStandardOrTool)|PHVS_Race_HL7_2x|CDC Race and Ethnicity Code Set||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5) [Demographics](Demographics)| [IETF](IETF)|Best practices for the structure, content, construction, and semantics of language tags for use in cases where it is desirable to indicate the language used in an information object.|True|False|[https://www.rfc-editor.org/rfc/rfc5646](https://www.rfc-editor.org/rfc/rfc5646)|||[STANDARDSDATASTANDARDORTOOL:577](https://w3id.org/bridge2ai/standards-datastandardortool-schema/577)|[DataStandardOrTool](DataStandardOrTool)|RFC 5646|IETF Request for Comment 5646 Tags for Identifying Languages||
|| [STANDARDSDATATOPIC:31](STANDARDSDATATOPIC:31)| [STANDARDSORGANIZATION:50](STANDARDSORGANIZATION:50)|Standard notation for printing telephone numbers, E-mail addresses and Web addresses.|True|False|[https://www.itu.int/rec/T-REC-E.123-200102-I/en](https://www.itu.int/rec/T-REC-E.123-200102-I/en)|||[STANDARDSDATASTANDARDORTOOL:578](https://w3id.org/bridge2ai/standards-datastandardortool-schema/578)|[DataStandardOrTool](DataStandardOrTool)|ITU–T E.123|International Telecommunication Union E.123 Notation for national and international telephone numbers, e-mail addresses and web addresses||
|| [STANDARDSDATATOPIC:31](STANDARDSDATATOPIC:31)| [STANDARDSORGANIZATION:50](STANDARDSORGANIZATION:50)|Number structure and functionality for the five categories of numbers used for international public telecommunication - geographic areas, global services, Networks, groups of countries (GoC) and resources for trials.|True|False|[https://www.itu.int/rec/T-REC-E.164-201011-I/en](https://www.itu.int/rec/T-REC-E.164-201011-I/en)|||[STANDARDSDATASTANDARDORTOOL:579](https://w3id.org/bridge2ai/standards-datastandardortool-schema/579)|[DataStandardOrTool](DataStandardOrTool)|ITU–T E.164|International Telecommunication Union E.164 The international public telecommunication numbering plan||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||A new clinical database, ACRIMA, has been made publicly available, containing 705 labelled images. It is composed of 396 glaucomatous images and 309 normal images. Additionally, python scripts used to obtain the presented results are also available.|True|False|[http://www.cvblab.webs.upv.es/project/acrima_en/](http://www.cvblab.webs.upv.es/project/acrima_en/)|[doi:10.1186/s12938-019-0649-y](doi:10.1186/s12938-019-0649-y)|[https://figshare.com/articles/dataset/CNNs_for_Automatic_Glaucoma_Assessment_using_Fundus_Images_An_Extensive_Validation/7613135](https://figshare.com/articles/dataset/CNNs_for_Automatic_Glaucoma_Assessment_using_Fundus_Images_An_Extensive_Validation/7613135)|[STANDARDSDATASTANDARDORTOOL:580](https://w3id.org/bridge2ai/standards-datastandardortool-schema/580)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|ACRIMA|ACRIMA dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Speech dataset. ~500 utterances classified by emotion|True|False|[http://m3c.web.auth.gr/research/aesdd-speech-emotion-recognition/](http://m3c.web.auth.gr/research/aesdd-speech-emotion-recognition/)|||[STANDARDSDATASTANDARDORTOOL:581](https://w3id.org/bridge2ai/standards-datastandardortool-schema/581)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|AESDD|Acted Emotional Speech Dynamic Database||
|| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7) [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16) [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21) [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25) [STANDARDSDATATOPIC:33](STANDARDSDATATOPIC:33)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|The Alliance of Genome Resources contains a subset of model organism data from member databases that is harmonized to the same model. This is the graph ingest of Alliance data prepared for loading into the Monarch Initiative graph resource.|True|False|[https://monarch-initiative.github.io/monarch-ingest/Sources/Alliance/](https://monarch-initiative.github.io/monarch-ingest/Sources/Alliance/)||[https://data.monarchinitiative.org/monarch-kg-dev/latest/rdf/alliance.nt.gz](https://data.monarchinitiative.org/monarch-kg-dev/latest/rdf/alliance.nt.gz)|[STANDARDSDATASTANDARDORTOOL:582](https://w3id.org/bridge2ai/standards-datastandardortool-schema/582)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Alliance ingest|Alliance of Genome Resources Knowledge Graph||
|| [STANDARDSDATATOPIC:27](STANDARDSDATATOPIC:27)| [STANDARDSORGANIZATION:24](STANDARDSORGANIZATION:24)|AlphaFold DB provides open access to over 200 million protein structure predictions to accelerate scientific research.|True|False|[https://alphafold.ebi.ac.uk/](https://alphafold.ebi.ac.uk/)|[doi:10.1038/s41586-021-03819-2](doi:10.1038/s41586-021-03819-2)||[STANDARDSDATASTANDARDORTOOL:583](https://w3id.org/bridge2ai/standards-datastandardortool-schema/583)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|AlphaFold DB|AlphaFold protein structure database||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||The OCTAGON dataset is a set of Angiography by Octical Coherence Tomography images (OCT-A) used to the segmentation of the Foveal Avascular Zone (FAZ). The dataset includes 144 healthy OCT-A images and 69 diabetic OCT-A images, divided into four groups, each one with 36 and about 17 OCT-A images, respectively.|False|True|[http://www.varpa.es/research/ophtalmology.html](http://www.varpa.es/research/ophtalmology.html)|[doi:10.1371/journal.pone.0212364](doi:10.1371/journal.pone.0212364)||[STANDARDSDATASTANDARDORTOOL:584](https://w3id.org/bridge2ai/standards-datastandardortool-schema/584)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|OCTAGON|Angiography by Optical Coherence Tomography segmentation dataset||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||90 fundus images with annotations for retinal arteriovenous (AV) nicking.|True|False|[https://people.eng.unimelb.edu.au/thivun/projects/AV_nicking_quantification/](https://people.eng.unimelb.edu.au/thivun/projects/AV_nicking_quantification/)|[doi:10.1109/TBME.2013.2271035](doi:10.1109/TBME.2013.2271035)||[STANDARDSDATASTANDARDORTOOL:585](https://w3id.org/bridge2ai/standards-datastandardortool-schema/585)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|AV Nicking|Arteriovenous Nicking dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||30000 audio samples of spoken digits|True|False||[doi:10.48550/arXiv.1807.03418](doi:10.48550/arXiv.1807.03418)|[https://github.com/soerenab/AudioMNIST](https://github.com/soerenab/AudioMNIST)|[STANDARDSDATASTANDARDORTOOL:586](https://w3id.org/bridge2ai/standards-datastandardortool-schema/586)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|AudioMNIST|AudioMNIST||
|| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||Bgee is a database for retrieval and comparison of gene expression patterns across multiple animal species, produced from multiple data types (bulk RNA-Seq, single-cell RNA-Seq, Affymetrix, in situ hybridization, and EST data) and from multiple data sets (including GTEx data).|True|False|[https://bgee.org/](https://bgee.org/)|[doi:10.1093/nar/gkaa793](doi:10.1093/nar/gkaa793)||[STANDARDSDATASTANDARDORTOOL:587](https://w3id.org/bridge2ai/standards-datastandardortool-schema/587)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Bgee|Bgee||
| text| [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16)||Biomedical text relation annotations and labels for novel findings|True|False|[https://ftp.ncbi.nlm.nih.gov/pub/lu/BioRED/](https://ftp.ncbi.nlm.nih.gov/pub/lu/BioRED/)|[doi:10.1093/bib/bbac282](doi:10.1093/bib/bbac282)||[STANDARDSDATASTANDARDORTOOL:588](https://w3id.org/bridge2ai/standards-datastandardortool-schema/588)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|BioRED|Biomedical Relation Extraction Dataset||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||195 phase-contrast microscopy images that were divided into 16 subwindows and each subwindow labeled into 4 classes by two trained operators.|True|False|[https://figshare.com/s/d6fb591f1beb4f8efa6f](https://figshare.com/s/d6fb591f1beb4f8efa6f)|[doi:10.1371/journal.pone.0149399](doi:10.1371/journal.pone.0149399)||[STANDARDSDATASTANDARDORTOOL:589](https://w3id.org/bridge2ai/standards-datastandardortool-schema/589)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|BioMediTech RPE|BioMediTech retinal pigmented epithelium dataset||
| text| [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16)||Biomedical texts annotated for negation, speculation and linguistic scope|True|False|[https://rgai.inf.u-szeged.hu/node/105](https://rgai.inf.u-szeged.hu/node/105)|||[STANDARDSDATASTANDARDORTOOL:590](https://w3id.org/bridge2ai/standards-datastandardortool-schema/590)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|BioScope|BioScope corpus||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||More than 54,000 external iris images|True|True|[http://biometrics.idealtest.org/findTotalDbByMode.do?mode=Iris#/datasetDetail/4](http://biometrics.idealtest.org/findTotalDbByMode.do?mode=Iris#/datasetDetail/4)|||[STANDARDSDATASTANDARDORTOOL:591](https://w3id.org/bridge2ai/standards-datastandardortool-schema/591)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|CASIA Iris|CASIA Iris Image Database||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||More than 26,000 external iris images|True|True|[http://biometrics.idealtest.org/findTotalDbByMode.do?mode=Iris#/datasetDetail/14](http://biometrics.idealtest.org/findTotalDbByMode.do?mode=Iris#/datasetDetail/14)|||[STANDARDSDATASTANDARDORTOOL:592](https://w3id.org/bridge2ai/standards-datastandardortool-schema/592)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|CASIA Iris Subject Ageing|CASIA Iris Subject Ageing dataset||
| proteindata| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)| [STANDARDSORGANIZATION:95](STANDARDSORGANIZATION:95)|A free, publicly available online resource that provides information on the evolutionary relationships of protein structural domains.|True|False|[http://www.cathdb.info/](http://www.cathdb.info/)|[doi:10.1093/nar/gkaa1079](doi:10.1093/nar/gkaa1079)||[STANDARDSDATASTANDARDORTOOL:593](https://w3id.org/bridge2ai/standards-datastandardortool-schema/593)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|CATH|CATH||
| text| [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16)||Biomedical texts annotated for concepts and linguistic features|True|False|[https://github.com/UCDenver-ccp/CRAFT](https://github.com/UCDenver-ccp/CRAFT)|[doi:10.1007/978-94-024-0881-2_53](doi:10.1007/978-94-024-0881-2_53)|[https://github.com/UCDenver-ccp/CRAFT](https://github.com/UCDenver-ccp/CRAFT)|[STANDARDSDATASTANDARDORTOOL:594](https://w3id.org/bridge2ai/standards-datastandardortool-schema/594)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|CRAFT|Colorado Richly Annotated Full-Text Corpus||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Recordings of 4 speakers in ~9000 recordings over 4 noisy locations.|True|False|[https://archive.org/details/chime-home](https://archive.org/details/chime-home)|||[STANDARDSDATASTANDARDORTOOL:595](https://w3id.org/bridge2ai/standards-datastandardortool-schema/595)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|CHiME|Computational Hearing in Multisource Environments Dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Respiratory sounds and speech of healthy and COVID-19 positive individuals.|True|False|||[https://github.com/iiscleap/Coswara-Data](https://github.com/iiscleap/Coswara-Data)|[STANDARDSDATASTANDARDORTOOL:596](https://w3id.org/bridge2ai/standards-datastandardortool-schema/596)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Coswara|Coswara dataset||
| text| [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16)||Biomedical texts with focus on SARS-CoV-2|True|False|[https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html](https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html)||[https://github.com/allenai/cord19](https://github.com/allenai/cord19)|[STANDARDSDATASTANDARDORTOOL:597](https://w3id.org/bridge2ai/standards-datastandardortool-schema/597)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|CORD-19|COVID-19 Open Research Dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Speech dataset. 7,442 recordings from 91 actors.|True|False||[doi:10.1109/TAFFC.2014.2336244](doi:10.1109/TAFFC.2014.2336244)|[https://github.com/CheyneyComputerScience/CREMA-D](https://github.com/CheyneyComputerScience/CREMA-D)|[STANDARDSDATASTANDARDORTOOL:598](https://w3id.org/bridge2ai/standards-datastandardortool-schema/598)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|CREMA-D|Crowd-sourced Emotional Multimodal Actors Dataset||
|| [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)||Database of human chromosomal rearrangement (CR) events and their associated diseases. For each reported CR event, dbCRID documents the type of the event, the disease or symptoms associated, and—when possible—detailed information about the CR event including precise breakpoint positions, junction sequences, genes and gene regions disrupted and experimental techniques applied to discover/analyze the CR event.|True|False|[https://web.archive.org/web/20180902234150/http://dbcrid.biolead.org/](https://web.archive.org/web/20180902234150/http://dbcrid.biolead.org/)|[doi:10.1093/nar/gkq1038](doi:10.1093/nar/gkq1038)||[STANDARDSDATASTANDARDORTOOL:599](https://w3id.org/bridge2ai/standards-datastandardortool-schema/599)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|dbCRID|Database of Chromosomal Rearrangements In Diseases||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)| [STANDARDSORGANIZATION:29](STANDARDSORGANIZATION:29)|DECIPHER is used by the clinical community to share and compare phenotypic and genotypic data. The DECIPHER database contains data from 44,062 patients who have given consent for broad data-sharing; DECIPHER also supports more limited sharing via consortia.|True|True|[https://www.deciphergenomics.org/](https://www.deciphergenomics.org/)|[doi:10/1016/j.ajhg.2009.03.010](doi:10/1016/j.ajhg.2009.03.010)||[STANDARDSDATASTANDARDORTOOL:600](https://w3id.org/bridge2ai/standards-datastandardortool-schema/600)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|DECIPHER|DatabasE of genomiC varIation and Phenotype in Humans using Ensembl Resources||
|| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|The database of Genotypes and Phenotypes (dbGaP) was developed to archive and distribute the data and results from studies that have investigated the interaction of genotype and phenotype in Humans.|False|True|[https://www.ncbi.nlm.nih.gov/gap/](https://www.ncbi.nlm.nih.gov/gap/)|||[STANDARDSDATASTANDARDORTOOL:601](https://w3id.org/bridge2ai/standards-datastandardortool-schema/601)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|dbGaP|Database of Genotypes and Phenotypes||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||In DeepDR (Deep Diabetic Retinopathy), the fundus images composed of two parts. One part is from the participants in the Shanghai Diabetic Complication Screening Project (SDCSP), Nicheng Diabetes Screening Project (NDSP), and Nationwide Screening for Complications of Diabetes (NSCD) between 2014 and 2017 for regular fundus images. The other part was captured by a retinal specialist at an Eye Clinic located in Department of Ophthalmology, Shanghai Jiao Tong University affiliated Sixth People’s Hospital, China between 2014 to 2017 for regular fundus images and between Jan 2019 to present for ultra-widefield retinal images. From the thousands of examinations available, we have extracted 2000 regular fundus images from 500 patients and 256 ultra-widefield images from another 128 patients to form our dataset.|True|False|[https://isbi.deepdr.org/data.html](https://isbi.deepdr.org/data.html)|[doi:10.1016/j.patter.2022.100512](doi:10.1016/j.patter.2022.100512)|[https://github.com/deepdrdoc/DeepDRiD](https://github.com/deepdrdoc/DeepDRiD)|[STANDARDSDATASTANDARDORTOOL:602](https://w3id.org/bridge2ai/standards-datastandardortool-schema/602)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|DeepDRiD|Deep Diabetic Retinopathy dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Human nonverbal vocal sound dataset|False|True|[https://en.babba.ai/nonverbal](https://en.babba.ai/nonverbal)||[https://github.com/deeplyinc/Nonverbal-Vocalization-Dataset](https://github.com/deeplyinc/Nonverbal-Vocalization-Dataset)|[STANDARDSDATASTANDARDORTOOL:603](https://w3id.org/bridge2ai/standards-datastandardortool-schema/603)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Deeply|Deeply Nonverbal Vocalization Dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||20 speakers reading 5 excerpts each from public domain books.|True|False|[https://zenodo.org/record/4660670](https://zenodo.org/record/4660670)|||[STANDARDSDATASTANDARDORTOOL:604](https://w3id.org/bridge2ai/standards-datastandardortool-schema/604)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|DAPS|Device and Produced Speech Dataset||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||The Diabetic Retinopathy Image Dataset (DRiDB) has been established to help scientists from around the world to test and develop new image processing methods for early diabetic retinopathy detection in retinal fundus images.|False|True|[https://ipg.fer.hr/ipg/resources/image_database](https://ipg.fer.hr/ipg/resources/image_database)|[doi:10.1109/ISPA.2013.6703830](doi:10.1109/ISPA.2013.6703830)||[STANDARDSDATASTANDARDORTOOL:605](https://w3id.org/bridge2ai/standards-datastandardortool-schema/605)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|DRiDB|Diabetic retinopathy image database||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||The database consists of 110 colour digital retinal images. Initially, it were obtained 124 eye fundus images selected randomly from an eye fundus image base belonging to the Ophthalmology Service at Miguel Servet Hospital, Saragossa (Spain). From this initial image base, all those eye images (14 in total) that had some type of cataract (severe and moderate) were eliminated and, finally, was obtained the image base with 110 images.|True|False|[http://www.ia.uned.es/~ejcarmona/DRIONS-DB.html](http://www.ia.uned.es/~ejcarmona/DRIONS-DB.html)|[doi:10.1016/j.artmed.2008.04.005](doi:10.1016/j.artmed.2008.04.005)||[STANDARDSDATASTANDARDORTOOL:606](https://w3id.org/bridge2ai/standards-datastandardortool-schema/606)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|DRIONS-DB|Digital Retinal Images for Optic Nerve Segmentation DataBase||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||40 fundus images; annotations for diabetic retinopathy|True|True|[https://drive.grand-challenge.org/](https://drive.grand-challenge.org/)|[doi:10.1109/TMI.2004.825627](doi:10.1109/TMI.2004.825627)||[STANDARDSDATASTANDARDORTOOL:607](https://w3id.org/bridge2ai/standards-datastandardortool-schema/607)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|DRIVE|Digital Retinal Images for Vessel Extraction dataset||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||A dataset of retinal images which include both normal and glaucomatous eyes and manual segmentations from multiple human experts.|True|True|[http://cvit.iiit.ac.in/projects/mip/drishti-gs/mip-dataset2/Home.php](http://cvit.iiit.ac.in/projects/mip/drishti-gs/mip-dataset2/Home.php)|[doi:10.1109/ISBI.2014.6867807](doi:10.1109/ISBI.2014.6867807)||[STANDARDSDATASTANDARDORTOOL:608](https://w3id.org/bridge2ai/standards-datastandardortool-schema/608)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Drishti-GS|Drishti-GS dataset||
| clinicaldata multimodal text| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:57](STANDARDSORGANIZATION:57)|Deidentified, multimodal patient data from ICU stays|True|True|[https://eicu-crd.mit.edu/](https://eicu-crd.mit.edu/)|||[STANDARDSDATASTANDARDORTOOL:609](https://w3id.org/bridge2ai/standards-datastandardortool-schema/609)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|eICU-CRD|eICU Collaborative Research Database||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||144 audio files labelled by 40 listeners.|True|False|[https://zenodo.org/record/3727593](https://zenodo.org/record/3727593)|[doi:10.1145/3243274.3243277](doi:10.1145/3243274.3243277)||[STANDARDSDATASTANDARDORTOOL:610](https://w3id.org/bridge2ai/standards-datastandardortool-schema/610)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|EmoSynth|EmoSynth||
|| [STANDARDSDATATOPIC:27](STANDARDSDATATOPIC:27)| [Meta](Meta)|An open atlas of 617 million metagenomic protein structures.|True|False|[https://esmatlas.com/](https://esmatlas.com/)|[doi:10.1101/2022.07.20.500902](doi:10.1101/2022.07.20.500902)||[STANDARDSDATASTANDARDORTOOL:611](https://w3id.org/bridge2ai/standards-datastandardortool-schema/611)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|ESM Atlas|ESM Metagenomic Atlas||
| proteindata| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)||A hierarchical classification of protein domains according to their evolutionary relationships. Only proteins with experimentally determined spatial structures from the PDB database are currently classified in ECOD.|True|False|[http://prodata.swmed.edu/ecod/](http://prodata.swmed.edu/ecod/)|[doi:10.1371/journal.pcbi.1003926](doi:10.1371/journal.pcbi.1003926)||[STANDARDSDATASTANDARDORTOOL:612](https://w3id.org/bridge2ai/standards-datastandardortool-schema/612)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|ECOD|Evolutionary Classification of Protein Domains||
|| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||Ongoing transcriptome analysis project.|True|False|[https://fantom.gsc.riken.jp/](https://fantom.gsc.riken.jp/)|[doi:10.1101/gr.254219.119](doi:10.1101/gr.254219.119)||[STANDARDSDATASTANDARDORTOOL:613](https://w3id.org/bridge2ai/standards-datastandardortool-schema/613)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|FANTOM|FANTOM||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||Individual optical coherence tomography images and marking 38400 BScans from 269 age-related macular degeneration patients and 115 normal subjects, their ages, and their corresponding segmentation boundaries on a 5mm diameter centered at the fovea.|True|False|[http://people.duke.edu/~sf59/RPEDC_Ophth_2013_dataset.htm](http://people.duke.edu/~sf59/RPEDC_Ophth_2013_dataset.htm)|[doi:10.1016/j.ophtha.2013.07.013](doi:10.1016/j.ophtha.2013.07.013)||[STANDARDSDATASTANDARDORTOOL:614](https://w3id.org/bridge2ai/standards-datastandardortool-schema/614)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Duke OCT|Farsiu et al. Optical Coherence Tomography dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||4 speakers, 2,000 recordings, 50 of each digit per speaker.|True|False|||[https://github.com/Jakobovski/free-spoken-digit-dataset](https://github.com/Jakobovski/free-spoken-digit-dataset)|[STANDARDSDATASTANDARDORTOOL:615](https://w3id.org/bridge2ai/standards-datastandardortool-schema/615)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|FSDD|Free Spoken Digit Dataset||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||1020 high resolution colour fundus images and provides ground truth annotations for glaucoma diagnosis, optic disc and optic cup segmentation, vertical cup-to-disc ratio, size of neuroretinal rim in inferior, superior, nasal and temporal quadrants, and bounding box location for optic disc.|False|False|[https://www.dfki.uni-kl.de/g1020](https://www.dfki.uni-kl.de/g1020)|[doi:10.1109/IJCNN48605.2020.9207664](doi:10.1109/IJCNN48605.2020.9207664)||[STANDARDSDATASTANDARDORTOOL:616](https://w3id.org/bridge2ai/standards-datastandardortool-schema/616)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|G1020|G1020 dataset||
| referencegenome| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||The goal of the GENCODE project is to identify and classify all gene features in the human and mouse genomes with high accuracy based on biological evidence, and to release these annotations for the benefit of biomedical research and genome interpretation.|True|False|[https://www.gencodegenes.org/human/release_24.html](https://www.gencodegenes.org/human/release_24.html)|||[STANDARDSDATASTANDARDORTOOL:617](https://w3id.org/bridge2ai/standards-datastandardortool-schema/617)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|GRCh38|GENCODE24 (GRCh38) reference genome||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||10 actors portraying 10 states and 12 emotions|True|True|[https://www.unige.ch/cisa/gemep](https://www.unige.ch/cisa/gemep)|||[STANDARDSDATASTANDARDORTOOL:618](https://w3id.org/bridge2ai/standards-datastandardortool-schema/618)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|GEMEP|GEneva Multimodal Emotion Portrayals corpus||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25) [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)||A continuously updating, queryable, federated genomic data commons.|False|True|[https://www.genomicinformationcommons.org/](https://www.genomicinformationcommons.org/)|||[STANDARDSDATASTANDARDORTOOL:619](https://w3id.org/bridge2ai/standards-datastandardortool-schema/619)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|GIC|Genomic Information Commons||
|| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||The Genotype-Tissue Expression (GTEx) project is an ongoing effort to build a comprehensive public resource to study tissue-specific gene expression and regulation. Samples were collected from 54 non-diseased tissue sites across nearly 1000 individuals, primarily for molecular assays including WGS, WES, and RNA-Seq.|True|False|[https://gtexportal.org/home/](https://gtexportal.org/home/)|[doi:10.1038/ng.2653.](doi:10.1038/ng.2653.)||[STANDARDSDATASTANDARDORTOOL:620](https://w3id.org/bridge2ai/standards-datastandardortool-schema/620)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|GTex|Genotype Tissue Expression project||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)| [STANDARDSORGANIZATION:37](STANDARDSORGANIZATION:37)|dataset of manually-annotated audio events|True|False|[https://research.google.com/audioset/](https://research.google.com/audioset/)|[doi:10.1109/ICASSP.2017.7952261](doi:10.1109/ICASSP.2017.7952261)||[STANDARDSDATASTANDARDORTOOL:621](https://w3id.org/bridge2ai/standards-datastandardortool-schema/621)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|AudioSet|Google AudioSet||
| clinicaldata|| [AHRQ](AHRQ)|The Healthcare Cost and Utilization Project (HCUP) includes the largest collection of longitudinal hospital care data in the United States.|False|True|[https://www.hcup-us.ahrq.gov/](https://www.hcup-us.ahrq.gov/)|||[STANDARDSDATASTANDARDORTOOL:622](https://w3id.org/bridge2ai/standards-datastandardortool-schema/622)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|HCUP|Healthcare Cost and Utilization Project||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||The public database contains at the moment 15 images of healthy patients, 15 images of patients with diabetic retinopathy and 15 images of glaucomatous patients. Binary gold standard vessel segmentation images are available for each image. Also the masks determining field of view (FOV) are provided for particular datasets.|True|False|[https://www5.cs.fau.de/research/data/fundus-images/](https://www5.cs.fau.de/research/data/fundus-images/)|[doi:10.1155/2013/154860](doi:10.1155/2013/154860)||[STANDARDSDATASTANDARDORTOOL:623](https://w3id.org/bridge2ai/standards-datastandardortool-schema/623)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|HRF|High resolution fundus image database||
|| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7) [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|Annotations on Human Phenotype Ontology terms for Orphanet diseases.|True|False|[https://hpo-annotation-qc.readthedocs.io/en/latest/annotationFormat.html#phenotype-hpoa-format](https://hpo-annotation-qc.readthedocs.io/en/latest/annotationFormat.html#phenotype-hpoa-format)||[http://purl.obolibrary.org/obo/hp/hpoa/phenotype.hpoa](http://purl.obolibrary.org/obo/hp/hpoa/phenotype.hpoa)|[STANDARDSDATASTANDARDORTOOL:624](https://w3id.org/bridge2ai/standards-datastandardortool-schema/624)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|HPOA phenotype|HPOA - Disease Annotations||
|| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|Annotations on Human Phenotype Ontology terms for genes.|True|False|[https://hpo.jax.org/app/data/annotations](https://hpo.jax.org/app/data/annotations)||[http://purl.obolibrary.org/obo/hp/hpoa/genes_to_phenotype.txt](http://purl.obolibrary.org/obo/hp/hpoa/genes_to_phenotype.txt)|[STANDARDSDATASTANDARDORTOOL:625](https://w3id.org/bridge2ai/standards-datastandardortool-schema/625)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|HPOA genes to phenotype|HPOA - Gene to Phenotype Associations||
|| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|Annotations on Human Phenotype Ontology terms for genes.|True|False|[https://hpo.jax.org/app/data/annotations](https://hpo.jax.org/app/data/annotations)||[http://purl.obolibrary.org/obo/hp/hpoa/phenotype_to_genes.txt](http://purl.obolibrary.org/obo/hp/hpoa/phenotype_to_genes.txt)|[STANDARDSDATASTANDARDORTOOL:626](https://w3id.org/bridge2ai/standards-datastandardortool-schema/626)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|HPOA phenotype to genes|HPOA - Phenotype to Gene Associations||
|| [STANDARDSDATATOPIC:2](STANDARDSDATATOPIC:2)||The Human Cell Atlas (HCA) is an international group of researchers using a combination of these new technologies to create cellular reference maps with the position, function and characteristics of every cell type in the human body.|True|False|[https://www.humancellatlas.org/portals/](https://www.humancellatlas.org/portals/)|[doi:10.7554/eLife.27041](doi:10.7554/eLife.27041)|[https://github.com/HumanCellAtlas/](https://github.com/HumanCellAtlas/)|[STANDARDSDATASTANDARDORTOOL:627](https://w3id.org/bridge2ai/standards-datastandardortool-schema/627)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|HCA|Human Cell Atlas||
|| [STANDARDSDATATOPIC:17](STANDARDSDATATOPIC:17)||A freely available electronic database containing detailed information about small molecule metabolites found in the human body. It is intended to be used for applications in metabolomics, clinical chemistry, biomarker discovery and general education. The database is designed to contain or link three kinds of data - 1) chemical data, 2) clinical data, and 3) molecular biology/biochemistry data.|True|False|[https://hmdb.ca/](https://hmdb.ca/)|[doi:10.1093/nar/gkab1062](doi:10.1093/nar/gkab1062)||[STANDARDSDATASTANDARDORTOOL:628](https://w3id.org/bridge2ai/standards-datastandardortool-schema/628)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|HMDB|Human Metabolome Database||
| proteindata| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26) [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)||The Human Protein Atlas is a Swedish-based program initiated in 2003 with the aim to map all the human proteins in cells, tissues, and organs using an integration of various omics technologies, including antibody-based imaging, mass spectrometry-based proteomics, transcriptomics, and systems biology. All the data in the knowledge resource is open access to allow scientists both in academia and industry to freely access the data for exploration of the human proteome.|True|False|[https://www.proteinatlas.org/](https://www.proteinatlas.org/)|[doi:10.1126/science.1260419](doi:10.1126/science.1260419)||[STANDARDSDATASTANDARDORTOOL:629](https://w3id.org/bridge2ai/standards-datastandardortool-schema/629)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|HPA|Human Protein Atlas||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||Dataset constituting typical diabetic retinopathy lesions and also normal retinal structures annotated at a pixel level.|True|True|[https://idrid.grand-challenge.org/](https://idrid.grand-challenge.org/)|[doi:10.3390/data3030025](doi:10.3390/data3030025)|[https://ieee-dataport.org/open-access/indian-diabetic-retinopathy-image-dataset-idrid](https://ieee-dataport.org/open-access/indian-diabetic-retinopathy-image-dataset-idrid)|[STANDARDSDATASTANDARDORTOOL:630](https://w3id.org/bridge2ai/standards-datastandardortool-schema/630)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|IDRiD|Indian Diabetic Retinopathy Image Dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||12 hours of audiovisual data by 10 actors; 5 emotions.|True|True|[https://sail.usc.edu/iemocap/iemocap_release.htm](https://sail.usc.edu/iemocap/iemocap_release.htm)|||[STANDARDSDATASTANDARDORTOOL:631](https://w3id.org/bridge2ai/standards-datastandardortool-schema/631)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|IEMOCAP|Interactive emotional dyadic motion capture database||
| proteindata| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)| [STANDARDSORGANIZATION:29](STANDARDSORGANIZATION:29)|InterPro provides functional analysis of proteins by classifying them into families and predicting domains and important sites.|True|False|[https://www.ebi.ac.uk/interpro/](https://www.ebi.ac.uk/interpro/)|[doi:10.1093/nar/gkaa977](doi:10.1093/nar/gkaa977)||[STANDARDSDATASTANDARDORTOOL:632](https://w3id.org/bridge2ai/standards-datastandardortool-schema/632)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|InterPro|InterPro||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Derived from LibriSpeech by concatenating the corpus utterances to simulate a conversation and capturing the audio replays with far-field microphones.|True|False|||[https://github.com/chenzhuo1011/libri_css](https://github.com/chenzhuo1011/libri_css)|[STANDARDSDATASTANDARDORTOOL:633](https://w3id.org/bridge2ai/standards-datastandardortool-schema/633)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Libri-CSS|Libri-CSS dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Derived from LibriSpeech. Generated, noisy mixes of speech.|True|False|||[https://github.com/JorisCos/LibriMix](https://github.com/JorisCos/LibriMix)|[STANDARDSDATASTANDARDORTOOL:634](https://w3id.org/bridge2ai/standards-datastandardortool-schema/634)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|LibriMix|LibriMix dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||A corpus of ~1000 hours of English speech derived from read audiobooks from the LibriVox project.|True|False|[https://www.openslr.org/12](https://www.openslr.org/12)|[doi:10.1109/ICASSP.2015.7178964](doi:10.1109/ICASSP.2015.7178964)||[STANDARDSDATASTANDARDORTOOL:635](https://w3id.org/bridge2ai/standards-datastandardortool-schema/635)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Librispeech|Librispeech||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||A public domain speech dataset consisting of 13,100 short audio clips of a single speaker reading passages from 7 non-fiction books, with transcriptions.|True|False|[https://keithito.com/LJ-Speech-Dataset/](https://keithito.com/LJ-Speech-Dataset/)|||[STANDARDSDATASTANDARDORTOOL:636](https://w3id.org/bridge2ai/standards-datastandardortool-schema/636)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|LJ Speech|LJ Speech||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||Longitudinal visual field data of 139 glaucoma patients.|True|True|[http://www.rodrep.com/data-sets.html](http://www.rodrep.com/data-sets.html)|[doi:10.1167/iovs.13-12492](doi:10.1167/iovs.13-12492)||[STANDARDSDATASTANDARDORTOOL:637](https://w3id.org/bridge2ai/standards-datastandardortool-schema/637)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|LGVF|Longitudinal Glaucomatous Visual Field data||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||A linked-data commons that coordinates access to data and harmonizes data management activities at three critical stages - (1) intake, including curation, de-identification, abstraction, and quality assessment (2) annotation and labelling of images and other data using semi-automated approaches and (3) distributed access and query methods.|True|True|[https://www.midrc.org/](https://www.midrc.org/)|||[STANDARDSDATASTANDARDORTOOL:638](https://w3id.org/bridge2ai/standards-datastandardortool-schema/638)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|MIDRC|Medical Imaging and Data Resource Center||
| clinicaldata multimodal text| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:57](STANDARDSORGANIZATION:57)|Deidentified, multimodal patient data|True|True|[https://mimic.mit.edu/](https://mimic.mit.edu/)|||[STANDARDSDATASTANDARDORTOOL:639](https://w3id.org/bridge2ai/standards-datastandardortool-schema/639)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|MIMIC|Medical Information Mart for Intensive Care||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||The 1200 eye fundus color numerical images of the posterior pole of the Messidor database were acquired by 3 ophthalmologic departments.|True|True|[https://www.adcis.net/en/third-party/messidor/](https://www.adcis.net/en/third-party/messidor/)|[doi:10.5566/ias.1155](doi:10.5566/ias.1155)||[STANDARDSDATASTANDARDORTOOL:640](https://w3id.org/bridge2ai/standards-datastandardortool-schema/640)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Messidor|Methods to Evaluate Segmentation and Indexing Techniques in the field of Retinal Ophthalmology dataset||
||||A collection of 3D microstructural datasets assembed using a single 2D input slice as training data.|True|False|[https://microlib.io/](https://microlib.io/)|[doi:10.1038/s41597-022-01744-1](doi:10.1038/s41597-022-01744-1)|[https://github.com/tldr-group/microlib](https://github.com/tldr-group/microlib)|[STANDARDSDATASTANDARDORTOOL:641](https://w3id.org/bridge2ai/standards-datastandardortool-schema/641)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|MicroLib|MicroLib||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)| [STANDARDSORGANIZATION:56](STANDARDSORGANIZATION:56)|A noisy speech dataset that can scale to arbitrary sizes depending on the number of speakers, noise types, and Speech to Noise Ratio.|True|False|||[https://github.com/microsoft/MS-SNSD](https://github.com/microsoft/MS-SNSD)|[STANDARDSDATASTANDARDORTOOL:642](https://w3id.org/bridge2ai/standards-datastandardortool-schema/642)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|MS-SNSD|Microsoft Scalable Noisy Speech Dataset||
| clinicaldata| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)| [STANDARDSORGANIZATION:57](STANDARDSORGANIZATION:57)|A large collection of physiological signals and measurements from patients in intensive care units, including electrocardiograms, photoplethysmograms, respiration, invasive and non-invasive blood pressure, and more. These measurements and signals are obtained directly from the bedside monitor, and provide a detailed view into the physiology of critically ill patients.|True|False|[https://physionet.org/content/mimic4wdb/0.1.0/](https://physionet.org/content/mimic4wdb/0.1.0/)|[doi:10.13026/a2mw-f949](doi:10.13026/a2mw-f949)||[STANDARDSDATASTANDARDORTOOL:643](https://w3id.org/bridge2ai/standards-datastandardortool-schema/643)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|WFDB|MIMIC Waveform Database for Biomedical Signal Processing||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)| [Mozilla](Mozilla)|Spoken text from public domain sources.|True|True|[https://voice.mozilla.org/](https://voice.mozilla.org/)|[doi:10.48550/arXiv.1912.06670](doi:10.48550/arXiv.1912.06670)|[https://github.com/common-voice/common-voice](https://github.com/common-voice/common-voice)|[STANDARDSDATASTANDARDORTOOL:644](https://w3id.org/bridge2ai/standards-datastandardortool-schema/644)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Common Voice|Mozilla Common Voice data||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||100 hours by over 100 speakers.|True|True|[https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Podcast.html](https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Podcast.html)|[doi:10.1109/TAFFC.2017.2736999](doi:10.1109/TAFFC.2017.2736999)||[STANDARDSDATASTANDARDORTOOL:645](https://w3id.org/bridge2ai/standards-datastandardortool-schema/645)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|MSP-Podcast|MSP Podcast Corpus||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||20 sentences by 12 actors; 4 emotions, with video|True|True|[https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Improv.html](https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Improv.html)|[doi:10.1109/TAFFC.2016.2515617](doi:10.1109/TAFFC.2016.2515617)||[STANDARDSDATASTANDARDORTOOL:646](https://w3id.org/bridge2ai/standards-datastandardortool-schema/646)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|MSP-IMPROV|MSP-IMPROV||
| multimodal| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26) [STANDARDSDATATOPIC:28](STANDARDSDATATOPIC:28)||Two central approaches for mapping cellular structure – protein fluorescent imaging and protein biophysical association – each generate extensive datasets but of distinct qualities and resolutions that are typically treated separately. The MuSIC map is designed to address this challenge, by integrating immunofluorescent images in the Human Protein Atlas with ongoing affinity purification experiments from the BioPlex resource. The result is a unified hierarchical map of eukaryotic cell architecture. In the MuSIC hierarchy, nodes represent systems and arrows indicate containment of the lower system by the upper. Node color indicates known (gold) or putative novel (purple) systems. The size of each circle is based on the number of proteins in the system. The relative height of each system in the layout is determined based on the predicted diameter of the system in MuSIC.|True|False|[http://doi.org/10.18119/N9188W](http://doi.org/10.18119/N9188W)|[doi:10.1038/s41586-021-04115-9](doi:10.1038/s41586-021-04115-9)|[https://github.com/idekerlab/MuSIC](https://github.com/idekerlab/MuSIC)|[STANDARDSDATASTANDARDORTOOL:647](https://w3id.org/bridge2ai/standards-datastandardortool-schema/647)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|MuSIC data|Multi-Scale Integrated Cell data||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Derived from EmotionLines. Includes more than 1400 dialogues and 13000 utterances from the Friends TV series.|True|False|||[https://github.com/SenticNet/MELD](https://github.com/SenticNet/MELD)|[STANDARDSDATASTANDARDORTOOL:648](https://w3id.org/bridge2ai/standards-datastandardortool-schema/648)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|MELD|Multimodal EmotionLines Dataset||
| clinicaldata|| [STANDARDSORGANIZATION:14](STANDARDSORGANIZATION:14)|The National Health and Nutrition Examination Survey (NHANES) is a program of studies designed to assess the health and nutritional status of adults and children in the United States. The survey is unique in that it combines interviews and physical examinations. NHANES is a major program of the National Center for Health Statistics (NCHS).|True|False|[https://www.cdc.gov/nchs/nhanes/index.htm](https://www.cdc.gov/nchs/nhanes/index.htm)|||[STANDARDSDATASTANDARDORTOOL:649](https://w3id.org/bridge2ai/standards-datastandardortool-schema/649)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|NHANES|National Health and Nutrition Examination Survey||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:81](STANDARDSORGANIZATION:81)|Clinical data from 9 primary partners.|False|True|[https://pcornet.org/data/](https://pcornet.org/data/)|||[STANDARDSDATASTANDARDORTOOL:650](https://w3id.org/bridge2ai/standards-datastandardortool-schema/650)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|PCORNet Data|National Patient-Centered Clinical Research Network data||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||14k speech samples with simulated background noise and live degradation conditions.|True|False||[doi:10.21437/Interspeech.2021-299](doi:10.21437/Interspeech.2021-299)|[https://github.com/gabrielmittag/NISQA/wiki/NISQA-Corpus](https://github.com/gabrielmittag/NISQA/wiki/NISQA-Corpus)|[STANDARDSDATASTANDARDORTOOL:651](https://w3id.org/bridge2ai/standards-datastandardortool-schema/651)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|NISQA-Corpus|NISQA Speech Quality Corpus||
|| [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16) [STANDARDSDATATOPIC:3](STANDARDSDATATOPIC:3)| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|204 full-text PubMed Central (PMC) articles, fully annotated for chemical entities by 12 NLM indexers for both span (i.e. named entity recognition) and normalization (i.e. entity linking) using MeSH.|True|False|[https://ftp.ncbi.nlm.nih.gov/pub/lu/NLM-Chem-BC7-corpus/](https://ftp.ncbi.nlm.nih.gov/pub/lu/NLM-Chem-BC7-corpus/)|[doi:10.1093/database/baac102](doi:10.1093/database/baac102)||[STANDARDSDATASTANDARDORTOOL:652](https://w3id.org/bridge2ai/standards-datastandardortool-schema/652)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|NLM-Chem-BC7|NLM-Chem BioCreative VII Chemical Identification corpus||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Clean and noisy parallel speech database. Also known as VBD, Voice Bank + DEMAND. Speech samples from VCTK dataset.|True|False|[https://datashare.is.ed.ac.uk/handle/10283/2791](https://datashare.is.ed.ac.uk/handle/10283/2791)|[doi:10.7488/ds/2117](doi:10.7488/ds/2117)||[STANDARDSDATASTANDARDORTOOL:653](https://w3id.org/bridge2ai/standards-datastandardortool-schema/653)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Noisy|Noisy Dataset||
| clinicaldata| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7) [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25)| [STANDARDSORGANIZATION:18](STANDARDSORGANIZATION:18)|A real-world-data-derived resource with annotation for rare-disease-related phenotypes. This resource is derived from the EHRs of two academic health institutions containing more than 10 million individuals spanning wide age ranges and different disease subgroups. By leveraging ontology mapping and advanced natural-language-processing (NLP) methods, OARD automatically and efficiently extracts concepts for both rare diseases and their phenotypic traits from billing codes and lab tests as well as over 100 million clinical narratives.|True|False|[https://rare.cohd.io/](https://rare.cohd.io/)|[doi:10.1016/j.ajhg.2022.08.002](doi:10.1016/j.ajhg.2022.08.002)|[https://github.com/stormliucong/oard-react](https://github.com/stormliucong/oard-react)|[STANDARDSDATASTANDARDORTOOL:654](https://w3id.org/bridge2ai/standards-datastandardortool-schema/654)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|OARD|Open annotation for rare diseases dataset||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||An open source Optical Coherence Tomography Image Database containing different retinal OCT images with different pathological conditions.|True|False|[https://borealisdata.ca/dataverse/OCTID](https://borealisdata.ca/dataverse/OCTID)|[doi:10.48550/arXiv.1812.07056](doi:10.48550/arXiv.1812.07056)||[STANDARDSDATASTANDARDORTOOL:655](https://w3id.org/bridge2ai/standards-datastandardortool-schema/655)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|OCTID|Optical Coherence Tomography Image Retinal Database||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||650 retinal images annotated by trained professionals from Singapore Eye Research Institute. A wide collection of image signs, critical for glaucoma diagnosis, are annotated.|False|False||[doi:10.1109/IEMBS.2010.5626137](doi:10.1109/IEMBS.2010.5626137)||[STANDARDSDATASTANDARDORTOOL:656](https://w3id.org/bridge2ai/standards-datastandardortool-schema/656)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|ORIGA-light|ORIGA-light dataset||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||Dataset with fundus images and clinical data of both eyes of the same patient for glaucoma assessment|True|False||[doi:10.1038/s41597-022-01388-1](doi:10.1038/s41597-022-01388-1)|[https://figshare.com/articles/dataset/PAPILA/14798004/2](https://figshare.com/articles/dataset/PAPILA/14798004/2)|[STANDARDSDATASTANDARDORTOOL:657](https://w3id.org/bridge2ai/standards-datastandardortool-schema/657)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|PAPILA|PAPILA dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Recordings from 20 Parkinson’s Disease patients and 20 healthy subjects.|True|False|[https://archive.ics.uci.edu/ml/datasets/Parkinson+Speech+Dataset+with++Multiple+Types+of+Sound+Recordings](https://archive.ics.uci.edu/ml/datasets/Parkinson+Speech+Dataset+with++Multiple+Types+of+Sound+Recordings)|[doi:10.1109/JBHI.2013.2245674](doi:10.1109/JBHI.2013.2245674)||[STANDARDSDATASTANDARDORTOOL:658](https://w3id.org/bridge2ai/standards-datastandardortool-schema/658)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|PD database|Parkinson's speech dataset||
| text| [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16)| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|Biomedical texts|True|False|[https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/](https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/)|||[STANDARDSDATASTANDARDORTOOL:659](https://w3id.org/bridge2ai/standards-datastandardortool-schema/659)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|PMC OA|PubMed Central Open Access Subset||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||1200 fundus images with ground truth segmentations of the optic disc and optic cup, and clinical glaucoma labels.|True|True|[https://refuge.grand-challenge.org/](https://refuge.grand-challenge.org/)|[doi:10.1016/j.media.2019.101570](doi:10.1016/j.media.2019.101570)||[STANDARDSDATASTANDARDORTOOL:660](https://w3id.org/bridge2ai/standards-datastandardortool-schema/660)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|REFUGE|Retinal Fundus Glaucoma Challenge Dataset||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||750 retinal fundus images.|True|True|[https://deepblue.lib.umich.edu/data/concern/data_sets/3b591905z](https://deepblue.lib.umich.edu/data/concern/data_sets/3b591905z)|[doi:10.1117/12.2293584](doi:10.1117/12.2293584)||[STANDARDSDATASTANDARDORTOOL:661](https://w3id.org/bridge2ai/standards-datastandardortool-schema/661)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|RIGA|Retinal fundus Images for Glaucoma Analysis dataset||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||313 retinographies from normal subjects and 172 retinographies from patients with glaucoma. All of these images have been assessed by two experts and include a manual segmentation of the disc and cup.|True|False||[doi:10.5566/ias.2346](doi:10.5566/ias.2346)|[https://github.com/miag-ull/rim-one-dl](https://github.com/miag-ull/rim-one-dl)|[STANDARDSDATASTANDARDORTOOL:662](https://w3id.org/bridge2ai/standards-datastandardortool-schema/662)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|RIM-ONE DL|Retinal IMage database for Optic Nerve Evaluation||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||Currently, we have released a first data set, aimed at CAD of microaneurysms and dot hemorrhages. These abnormalities are amongst the first signs of the presence of diabetic retinopathy.|True|True|[http://webeye.ophth.uiowa.edu/ROC/](http://webeye.ophth.uiowa.edu/ROC/)|[doi:10.1109/TMI.2009.2033909](doi:10.1109/TMI.2009.2033909)||[STANDARDSDATASTANDARDORTOOL:663](https://w3id.org/bridge2ai/standards-datastandardortool-schema/663)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|ROC|Retinopathy Online Challenge data||
|| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||We developed a pipeline that processes and unifies RNA-seq data from different studies. Using the pipeline, we have processed data from the GTEx and TCGA and have successfully corrected for study-specific biases, allowing comparative analysis across studies.|True|False|[https://github.com/mskcc/RNAseqDB](https://github.com/mskcc/RNAseqDB)|[doi:10.1038/sdata.2018.61](doi:10.1038/sdata.2018.61)|[https://github.com/mskcc/RNAseqDB](https://github.com/mskcc/RNAseqDB)|[STANDARDSDATASTANDARDORTOOL:664](https://w3id.org/bridge2ai/standards-datastandardortool-schema/664)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|RNAseqDB|RNAseqDB||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||95 dyadic conversations from 21 subjects. Each subject converses with another playing one of four characters with emotions; 5 FeelTrace annotations - activation, valence, dominance, power, intensity.|True|True|[https://semaine-db.eu/](https://semaine-db.eu/)|||[STANDARDSDATASTANDARDORTOOL:665](https://w3id.org/bridge2ai/standards-datastandardortool-schema/665)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|SEMAINE|SEMAINE dataset||
| text| [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16)| [STANDARDSORGANIZATION:74](STANDARDSORGANIZATION:74)|A repository of semantic predications (subject-predicate-object triples) extracted from the entire set of PubMed citations.|True|True|[https://lhncbc.nlm.nih.gov/ii/tools/SemRep_SemMedDB_SKR.html](https://lhncbc.nlm.nih.gov/ii/tools/SemRep_SemMedDB_SKR.html)|[doi:10.1093/bioinformatics/bts591](doi:10.1093/bioinformatics/bts591)|[https://github.com/lhncbc/SemRep/tree/master](https://github.com/lhncbc/SemRep/tree/master)|[STANDARDSDATASTANDARDORTOOL:666](https://w3id.org/bridge2ai/standards-datastandardortool-schema/666)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|SemMedDB|Semantic MEDLINE Database||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||10,000 hours of transcribed audio|True|True||[doi:10.48550/arXiv.2106.06909](doi:10.48550/arXiv.2106.06909)|[https://github.com/SpeechColab/GigaSpeech](https://github.com/SpeechColab/GigaSpeech)|[STANDARDSDATASTANDARDORTOOL:667](https://w3id.org/bridge2ai/standards-datastandardortool-schema/667)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|GigaSpeech|Speechcollab GigaSpeech||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||A database of free audio samples of single-word commands, English pronunciations.|True|False|||[https://github.com/JohannesBuchner/spoken-command-recognition](https://github.com/JohannesBuchner/spoken-command-recognition)|[STANDARDSDATASTANDARDORTOOL:668](https://w3id.org/bridge2ai/standards-datastandardortool-schema/668)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Sound Commander|Spoken Commands dataset||
| speechdata text| [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16) [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Text-aligned spoken Wikipedia articles.|True|False|[https://nats.gitlab.io/swc/](https://nats.gitlab.io/swc/)|[doi:10.1007/s10579-017-9410-y](doi:10.1007/s10579-017-9410-y)||[STANDARDSDATASTANDARDORTOOL:669](https://w3id.org/bridge2ai/standards-datastandardortool-schema/669)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|SWC|Spoken Wikipedia Corpora||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||89 fundus images with segmentation and annotated for different diabetic retinopathies|True|False|[https://www.it.lut.fi/project/imageret/diaretdb1/](https://www.it.lut.fi/project/imageret/diaretdb1/)|[doi:10.5244/C.21.15](doi:10.5244/C.21.15)||[STANDARDSDATASTANDARDORTOOL:670](https://w3id.org/bridge2ai/standards-datastandardortool-schema/670)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|DiaRetDb1|Standard Diabetic Retinopathy Database Calibration level 1 dataset||
| proteindata| [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)||The SCOP database, created by manual inspection and abetted by a battery of automated methods, aims to provide a detailed and comprehensive description of the structural and evolutionary relationships between all proteins whose structure is known.|True|False|[http://scop.mrc-lmb.cam.ac.uk/](http://scop.mrc-lmb.cam.ac.uk/)|[doi:10.1093/nar/gkz1064](doi:10.1093/nar/gkz1064)||[STANDARDSDATASTANDARDORTOOL:671](https://w3id.org/bridge2ai/standards-datastandardortool-schema/671)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|SCOP|Structural Classification of Proteins||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||~400 raw images|True|False|[http://cecas.clemson.edu/~ahoover/stare/](http://cecas.clemson.edu/~ahoover/stare/)|[doi:10.1109/TMI.2003.815900](doi:10.1109/TMI.2003.815900)||[STANDARDSDATASTANDARDORTOOL:672](https://w3id.org/bridge2ai/standards-datastandardortool-schema/672)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|STARE|STructured Analysis of the REtina dataset||
| eyedata| [STANDARDSDATATOPIC:24](STANDARDSDATATOPIC:24)||Subbasal nerve plexus Mosaic images acquired in vivo using laser-scanning confocal microscopy of the cornea in healthy subjects and type 2 diabetes mellitus subjects of the same age. Mosaics represent wide-field images of the plexus incorporating 3D nerve path data projected onto a 2D plane.|True|False|[https://figshare.com/collections/SBP_Mosaic_Dataset/3950197](https://figshare.com/collections/SBP_Mosaic_Dataset/3950197)|[doi:10.1038/s41598-018-32410-5](doi:10.1038/s41598-018-32410-5)||[STANDARDSDATASTANDARDORTOOL:673](https://w3id.org/bridge2ai/standards-datastandardortool-schema/673)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|SBP Mosiac|Subbasal nerve plexus Mosaic||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13) [STANDARDSDATATOPIC:26](STANDARDSDATATOPIC:26)||A database of structural and functional annotation for all proteins and genomes. The SUPERFAMILY annotation is based on a collection of hidden Markov models, which represent structural protein domains at the SCOP superfamily level. A superfamily groups together domains which have an evolutionary relationship. The annotation is produced by scanning protein sequences from over 3,200 completely sequenced genomes against the hidden Markov models.|True|False|[https://supfam.org/](https://supfam.org/)|[doi:10.1093/nar/gky1130](doi:10.1093/nar/gky1130)||[STANDARDSDATASTANDARDORTOOL:674](https://w3id.org/bridge2ai/standards-datastandardortool-schema/674)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|SUPERFAMILY|SUPERFAMILY database||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||4 male actors in 7 different emotions, 480 British English utterances in total, including video of speaker faces.|True|True|[http://kahlan.eps.surrey.ac.uk/savee/](http://kahlan.eps.surrey.ac.uk/savee/)|||[STANDARDSDATASTANDARDORTOOL:675](https://w3id.org/bridge2ai/standards-datastandardortool-schema/675)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|SAVEE|Surrey Audio-Visual Expressed Emotion Dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||A database of sentences, translations, and spoken audio for use in language learning. This download contains spoken English recorded by their community.|True|False|[https://tatoeba.org/eng/downloads](https://tatoeba.org/eng/downloads)|||[STANDARDSDATASTANDARDORTOOL:676](https://w3id.org/bridge2ai/standards-datastandardortool-schema/676)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Tatoeba|Tatoeba dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Audio talks and their transcriptions available on the TED website.|True|False|[https://www.openslr.org/51/](https://www.openslr.org/51/)|||[STANDARDSDATASTANDARDORTOOL:677](https://w3id.org/bridge2ai/standards-datastandardortool-schema/677)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|Ted-LIUM|Ted-LIUM corpus||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||The Cancer Genome Atlas (TCGA), a landmark cancer genomics program, molecularly characterized over 20,000 primary cancer and matched normal samples spanning 33 cancer types.|True|True|[https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga](https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga)|[doi:10.1038/ng.2764](doi:10.1038/ng.2764)||[STANDARDSDATASTANDARDORTOOL:678](https://w3id.org/bridge2ai/standards-datastandardortool-schema/678)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|TCGA|The Cancer Genome Atlas||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Speech dataset. 7356 files; 24 professional actors vocalizing lexically-matched statements and songs in a neutral North American accent.|True|False|[https://zenodo.org/record/1188976#.XrC7a5NKjOR](https://zenodo.org/record/1188976#.XrC7a5NKjOR)|[doi:10.1371/journal.pone.0196391](doi:10.1371/journal.pone.0196391)||[STANDARDSDATASTANDARDORTOOL:679](https://w3id.org/bridge2ai/standards-datastandardortool-schema/679)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|RAVDESS|The Ryerson Audio-Visual Database of Emotional Speech and Song||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. It includes time-aligned orthographic, phonetic and word transcriptions as well as a speech waveform file for each utterance.|False|True|[https://catalog.ldc.upenn.edu/LDC93S1](https://catalog.ldc.upenn.edu/LDC93S1)|||[STANDARDSDATASTANDARDORTOOL:680](https://w3id.org/bridge2ai/standards-datastandardortool-schema/680)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|TIMIT|TIMIT Acoustic-Phonetic Continuous Speech Corpus||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Speech dataset. 2800 recordings by 2 actresses.|True|False|[https://tspace.library.utoronto.ca/handle/1807/24487](https://tspace.library.utoronto.ca/handle/1807/24487)||[https://borealisdata.ca/dataset.xhtml?persistentId=doi:10.5683/SP2/E8H2MF](https://borealisdata.ca/dataset.xhtml?persistentId=doi:10.5683/SP2/E8H2MF)|[STANDARDSDATASTANDARDORTOOL:681](https://w3id.org/bridge2ai/standards-datastandardortool-schema/681)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|TESS|Toronto emotional speech set||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||Human non-speech emotion vocalizations.|True|False|[https://zenodo.org/record/4066235](https://zenodo.org/record/4066235)|||[STANDARDSDATASTANDARDORTOOL:682](https://w3id.org/bridge2ai/standards-datastandardortool-schema/682)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|VIVAE|Variably Intense Vocalizations of Affect and Emotion Corpus||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||A speech dataset targeting acoustically challenging and reverberant environments with robust labels and truth data for transcription, denoising, and speaker identification.|True|False|[https://iqtlabs.github.io/voices/](https://iqtlabs.github.io/voices/)|||[STANDARDSDATASTANDARDORTOOL:683](https://w3id.org/bridge2ai/standards-datastandardortool-schema/683)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|VOiCES|Voices Obscured in Complex Environmental Settings Dataset||
| speechdata| [STANDARDSDATATOPIC:36](STANDARDSDATATOPIC:36)||100K hours of unlabelled speech data for 23 languages, 1.8K hours of transcribed speech data for 16 languages, and 17.3K hours of speech-to-speech interpretation data for 16x15 directions.|True|False||[doi:10.18653/v1/2021.acl-long.80](doi:10.18653/v1/2021.acl-long.80)|[https://github.com/facebookresearch/voxpopuli](https://github.com/facebookresearch/voxpopuli)|[STANDARDSDATASTANDARDORTOOL:684](https://w3id.org/bridge2ai/standards-datastandardortool-schema/684)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|VoxPopuli|VoxPopuli||
| drugdata| [STANDARDSDATATOPIC:8](STANDARDSDATATOPIC:8)||WHODrug contains individual trade names, active ingredients and additional information such as marketing authorisation holder, country of sale, pharmaceutical form and strength. All related medications are linked using a structured WHODrug alphanumeric code, connecting trade names and variation of the ingredient with the active moiety of the ingredient.|True|True|[https://who-umc.org/whodrug/whodrug-global/](https://who-umc.org/whodrug/whodrug-global/)|[doi:10.1007/s43441-020-00130-6](doi:10.1007/s43441-020-00130-6)|[https://who-umc.org/whodrug/whodrug-global/applications/download-area/](https://who-umc.org/whodrug/whodrug-global/applications/download-area/)|[STANDARDSDATASTANDARDORTOOL:685](https://w3id.org/bridge2ai/standards-datastandardortool-schema/685)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|WHODrug|WHODrug medicinal information dictionary||
|| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||WikiPathways is a database of biological pathways maintained by and for the scientific community.|True|False|[https://www.wikipathways.org/index.php/WikiPathways](https://www.wikipathways.org/index.php/WikiPathways)|[doi:10.1093/nar/gkaa1024](doi:10.1093/nar/gkaa1024)||[STANDARDSDATASTANDARDORTOOL:686](https://w3id.org/bridge2ai/standards-datastandardortool-schema/686)|[ReferenceDataOrDataset](ReferenceDataOrDataset)|WikiPathways|WikiPathways database||
|| [STANDARDSDATATOPIC:19](STANDARDSDATATOPIC:19)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|This paper proposed a pipeline for the integration of multiple microscopy imaging modalities into the PACS-DICOM universe, including the numerous metadata elements. A proof-of-concept system was developed, for validation purposes, and integrated with the Dicoogle open-source PACS, providing image storage, metadata indexing and visualization.|False|True||[doi:10.1109/ISCC53001.2021.9631529](doi:10.1109/ISCC53001.2021.9631529)||[STANDARDSDATASTANDARDORTOOL:687](https://w3id.org/bridge2ai/standards-datastandardortool-schema/687)|[ReferenceImplementation](ReferenceImplementation)|Gupta2021|A DICOM Standard Pipeline for Microscope Imaging Modalities||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|...we offer an architecture that utilizes a resource server based on GraphQL and HL7 FHIR that establishes communication between two heterogeneous EHRs. This paper describes how the proposed architecture is implemented to achieve interoperability between two heterogeneous EHRs, HL7 FHIR and OpenMRS. The presented approach establishes secure communication between the EHRs and provides accurate mappings that enable timely health information exchange between EHRs.|True|False||[doi:10.1177/14604582211043920](doi:10.1177/14604582211043920)||[STANDARDSDATASTANDARDORTOOL:688](https://w3id.org/bridge2ai/standards-datastandardortool-schema/688)|[ReferenceImplementation](ReferenceImplementation)|MukhiyaLamo2021|An HL7 FHIR and GraphQL approach for interoperability between heterogeneous Electronic Health Record systems||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4) [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:15, openEHR](STANDARDSORGANIZATION:15, openEHR)|This work investigates the mapping and data interoperability between healthcare and research standards - EN13606 used for the EHRs and the Clinical Data Interchange Standards Consortium Operational Data Model (CDISC ODM) used for clinical research.|True|False||[doi:10.1177/2055207618777676](doi:10.1177/2055207618777676)||[STANDARDSDATASTANDARDORTOOL:689](https://w3id.org/bridge2ai/standards-datastandardortool-schema/689)|[ReferenceImplementation](ReferenceImplementation)|Tapuria2018|Comparison and transformation between CDISC ODM and EN13606 EHR standards in connecting EHR data with clinical trial research data||
| datasheets| [STANDARDSDATATOPIC:32](STANDARDSDATATOPIC:32)||This datasheet describes the Pile, a 825 GiB dataset of human-authored text compiled by EleutherAI for use in large-scale language modeling. The Pile is comprised of 22 different text sources, ranging from original scrapes done for this project, to text data made available by the data owners, to third-party scrapes available online.|True|False||[doi:0.48550/arXiv.2201.07311](doi:0.48550/arXiv.2201.07311)||[STANDARDSDATASTANDARDORTOOL:690](https://w3id.org/bridge2ai/standards-datastandardortool-schema/690)|[ReferenceImplementation](ReferenceImplementation)|Biderman2022|Datasheet for the Pile||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|The small animal imaging Digital Imaging and Communications in Medicine (DICOM) acquisition context structured report (SR) was developed to incorporate pre-clinical data in an established DICOM format for rapid queries and comparison of clinical and non-clinical datasets. Established terminologies (i.e., anesthesia, mouse model nomenclature, veterinary definitions, NCI Metathesaurus) were utilized to assist in defining terms implemented in pre-clinical imaging and new codes were added to integrate the specific small animal procedures and handling processes, such as housing, biosafety level, and pre-imaging rodent preparation.|True|False||[doi:10.3390/tomography7010001](doi:10.3390/tomography7010001)||[STANDARDSDATASTANDARDORTOOL:691](https://w3id.org/bridge2ai/standards-datastandardortool-schema/691)|[ReferenceImplementation](ReferenceImplementation)|Kalen2021|Design and Implementation of the Pre-Clinical DICOM Standard in Multi-Cohort Murine Studies||
| multimodal|| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40) [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|We developed a system called FHIR-Ontop-OMOP to generate virtual clinical KGs from the OMOP relational databases. We leveraged an OMOP CDM-based Medical Information Mart for Intensive Care (MIMIC-III) data repository to evaluate the FHIR-Ontop-OMOP system in terms of the faithfulness of data transformation and the conformance of the generated CKGs to the FHIR RDF specification.|True|False||[doi:10.1016/j.jbi.2022.104201](doi:10.1016/j.jbi.2022.104201)|[https://github.com/fhircat/FHIROntopOMOP](https://github.com/fhircat/FHIROntopOMOP)|[STANDARDSDATASTANDARDORTOOL:692](https://w3id.org/bridge2ai/standards-datastandardortool-schema/692)|[ReferenceImplementation](ReferenceImplementation)|Xiao2022|FHIR-Ontop-OMOP - Building clinical knowledge graphs in FHIR RDF with the OMOP Common data Model||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9) [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|The Electronic Medical Records and Genomics (eMERGE) Network’s Phase III program initially used a commercially developed XML message format for standardized and structured representation of genetic results for electronic health record (EHR) integration. In a desire to move towards a standard representation, the network created a new standardized format based upon Health Level Seven Fast Healthcare Interoperability Resources (HL7® FHIR®), to represent clinical genomics results. These new standards improve the utility of HL7® FHIR® as an international healthcare interoperability standard for management of genetic data from patients.|True|False||[doi:10.1016/j.jbi.2021.103795](doi:10.1016/j.jbi.2021.103795)||[STANDARDSDATASTANDARDORTOOL:693](https://w3id.org/bridge2ai/standards-datastandardortool-schema/693)|[ReferenceImplementation](ReferenceImplementation)|Murugan2021|Genomic considerations for FHIR; eMERGE implementation lessons||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)||A complete implementation of the HL7 FHIR standard for healthcare interoperability in Java.|True|False|[https://hapifhir.io/](https://hapifhir.io/)|||[STANDARDSDATASTANDARDORTOOL:694](https://w3id.org/bridge2ai/standards-datastandardortool-schema/694)|[ReferenceImplementation](ReferenceImplementation)|HAPI FHIR|HAPI FHIR||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|The National COVID Cohort Collaborative (N3C) table of laboratory measurement data—over 3.1 billion patient records and over 19 000 unique measurement concepts in the Observational Medical Outcomes Partnership (OMOP) common-data-model format from 55 data partners. We grouped ontologically similar OMOP concepts together for 52 variables relevant to COVID-19 research, and developed a unit-harmonization pipeline comprised of (1) selecting a canonical unit for each measurement variable, (2) arriving at a formula for conversion, (3) obtaining clinical review of each formula, (4) applying the formula to convert data values in each unit into the target canonical unit, and (5) removing any harmonized value that fell outside of accepted value ranges for the variable.|True|False||[doi:10.1093/jamia/ocac054](doi:10.1093/jamia/ocac054)||[STANDARDSDATASTANDARDORTOOL:695](https://w3id.org/bridge2ai/standards-datastandardortool-schema/695)|[ReferenceImplementation](ReferenceImplementation)|Bradwell2022|Harmonizing units and values of quantitative data elements in a very large nationally pooled electronic health record (EHR) dataset||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15) [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40) [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76) [STANDARDSORGANIZATION:79](STANDARDSORGANIZATION:79)|To overcome the hurdle of disparate data sources and repositories with heterogeneous data formats a metadata crosswalk was initiated, based on existing standards. FAIR Principles were included, as well as data format specifications. The metadata crosswalk is the foundation of data provision between a Medical Data Integration Center (MeDIC) and researchers, providing a selection of metadata information for research design and requests. Based on the crosswalk, metadata items were prioritized and categorized to demonstrate that not one single predefined standard meets all requirements of a MeDIC and only a maximum data set of metadata is suitable for use. The development of a convergence format including the maximum data set is the anticipated solution for an automated transformation of metadata in a MeDIC.|True|False||[doi:10.1038/s41597-022-01792-7](doi:10.1038/s41597-022-01792-7)||[STANDARDSDATASTANDARDORTOOL:696](https://w3id.org/bridge2ai/standards-datastandardortool-schema/696)|[ReferenceImplementation](ReferenceImplementation)|Bönisch2022|Harvesting metadata in clinical care - a crosswalk between FHIR, OMOP, CDISC and openEHR metadata||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|This paper provides insights into how mHealth4Afrika is leveraging HL7 FHIR to support standards-based data exchange and interoperability between Electronic Medical Records and DHIS2. This work is currently being validated in the field.|True|False||[doi:10.3233/SHTI190175](doi:10.3233/SHTI190175)||[STANDARDSDATASTANDARDORTOOL:697](https://w3id.org/bridge2ai/standards-datastandardortool-schema/697)|[ReferenceImplementation](ReferenceImplementation)|Baskaya2019|Health4Afrika - Implementing HL7 FHIR Based Interoperability||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|COVID-19 data from 2 large countries in the Global South were harmonized and analyzed using a standardized health informatics framework developed by an international community of health informaticians.|True|False||[doi:10.1093/jamia/ocac180](doi:10.1093/jamia/ocac180)|[https://github.com/ohdsi-studies/EhdenCovidUseCase](https://github.com/ohdsi-studies/EhdenCovidUseCase)|[STANDARDSDATASTANDARDORTOOL:698](https://w3id.org/bridge2ai/standards-datastandardortool-schema/698)|[ReferenceImplementation](ReferenceImplementation)|PereiraPintoJunior2022|Integrating real-world data from Brazil and Pakistan into the OMOP common data model and standardized health analytics framework to characterize COVID-19 in the Global South||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4) [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|Using a single tool, i) biomedical images can be imported and inspected, ii) the target can be identified and segmented, iii) features can be extracted from the target, iv) reduced and selected, and v) used to build a predictive model using machine learning algorithms. As result, two different feature extractors can be chosen, a Matlab-based extractor, and the Pyradiomics extractor naturally integrated into matRadiomics.|True|False||[doi:10.3390/jimaging8080221](doi:10.3390/jimaging8080221)||[STANDARDSDATASTANDARDORTOOL:699](https://w3id.org/bridge2ai/standards-datastandardortool-schema/699)|[ReferenceImplementation](ReferenceImplementation)|Pasini2022|matRadiomics - A Novel and Complete Radiomics Framework, from Image Visualization to Predictive Model||
| multimodal|||We propose a solution to model patient trajectories that combines different types of information (e.g. clinical text, standard codes) and considers the temporal aspect of clinical data. This solution leverages two different architectures - one supporting flexible sets of input features, to convert patient admissions into dense representations; and a second exploring extracted admission representations in a recurrent-based architecture, where patient trajectories are processed in sub-sequences using a sliding window mechanism.|True|False||[doi:10.1016/j.jbi.2022.104195](doi:10.1016/j.jbi.2022.104195)|[https://github.com/bioinformatics-ua/PatientTM](https://github.com/bioinformatics-ua/PatientTM)|[STANDARDSDATASTANDARDORTOOL:700](https://w3id.org/bridge2ai/standards-datastandardortool-schema/700)|[ReferenceImplementation](ReferenceImplementation)|PatientTM|Modelling patient trajectories using multimodal information||
| datasheets| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||Following the structured format of Datasheets for Datasets, this paper expands on the original CheXpert paper and other sources to show the critical role played by radiologists in the creation of reliable labels and to describe the different aspects of the dataset composition in detail. Such structured documentation intends to increase the awareness in the machine learning and medical communities of the strengths, applications, and evolution of CheXpert, thereby advancing the field of medical image analysis.|True|False||[doi:10.48550/arXiv.2105.03020](doi:10.48550/arXiv.2105.03020)||[STANDARDSDATASTANDARDORTOOL:701](https://w3id.org/bridge2ai/standards-datastandardortool-schema/701)|[ReferenceImplementation](ReferenceImplementation)|Garbin2021|Structured dataset documentation - a datasheet for CheXpert||
||| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98)|One of the critical tools for early detection and subsequent evaluation of the incidence of lung diseases is chest radiography. This study presents a real-world implementation of a convolutional neural network (CNN) based Carebot Covid app to detect COVID-19 from chest X-ray (CXR) images. Our proposed model takes the form of a simple and intuitive application. Used CNN can be deployed as a STOW-RS prediction endpoint for direct implementation into DICOM viewers.|True|False||[doi:10.48550/arXiv.2203.10596](doi:10.48550/arXiv.2203.10596)||[STANDARDSDATASTANDARDORTOOL:702](https://w3id.org/bridge2ai/standards-datastandardortool-schema/702)|[ReferenceImplementation](ReferenceImplementation)|Kvak2022|Towards Clinical Practice - Design and Implementation of Convolutional Neural Network-Based Assistive Diagnosis System for COVID-19 Case Detection from Chest X-Ray Images||
||| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|We converted UK Biobank data to OMOP CDM v. 5.3. We transformed participant research data on diseases collected at recruitment and electronic health records (EHR) from primary care, hospitalizations, cancer registrations, and mortality from providers in England, Scotland, and Wales. We performed syntactic and semantic validations and compared comorbidities and risk factors between source and transformed data.|True|False||[doi:10.1093/jamia/ocac203](doi:10.1093/jamia/ocac203)||[STANDARDSDATASTANDARDORTOOL:703](https://w3id.org/bridge2ai/standards-datastandardortool-schema/703)|[ReferenceImplementation](ReferenceImplementation)|Papez2022|Transforming and evaluating the UK Biobank to the OMOP Common Data Model for COVID-19 research and beyond||
| dataregistry softwareregistry| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)||Registry of software tools, databases and services for bioinformatics and the life sciences.|True|False|[https://bio.tools/](https://bio.tools/)||[https://github.com/bio-tools/biotoolsregistry/](https://github.com/bio-tools/biotoolsregistry/)|[STANDARDSDATASTANDARDORTOOL:704](https://w3id.org/bridge2ai/standards-datastandardortool-schema/704)|[Registry](Registry)|bio.tools|bio.tools||
| softwareregistry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||The mission of the Bioconductor project is to develop, support, and disseminate free open source software that facilitates rigorous and reproducible analysis of data from current and emerging biological assays. We are dedicated to building a diverse, collaborative, and welcoming community of developers and data scientists.|True|False|[https://www.bioconductor.org/](https://www.bioconductor.org/)||[https://github.com/Bioconductor/BiocManager](https://github.com/Bioconductor/BiocManager)|[STANDARDSDATASTANDARDORTOOL:705](https://w3id.org/bridge2ai/standards-datastandardortool-schema/705)|[Registry](Registry)|Bioconductor|Bioconductor||
| ontologyregistry| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)||An ontology registry.|True|False|[https://bioportal.bioontology.org/](https://bioportal.bioontology.org/)||[https://github.com/ncbo](https://github.com/ncbo)|[STANDARDSDATASTANDARDORTOOL:706](https://w3id.org/bridge2ai/standards-datastandardortool-schema/706)|[Registry](Registry)|BioPortal|BioPortal||
| standardsregistry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A registry of prefixes and identifier formats used in biomedical data sets, knowledge bases, and ontologies.|True|False|[https://bioregistry.io/](https://bioregistry.io/)|[doi:10.1101/2022.07.08.499378](doi:10.1101/2022.07.08.499378)|[https://github.com/biopragmatics/bioregistry](https://github.com/biopragmatics/bioregistry)|[STANDARDSDATASTANDARDORTOOL:707](https://w3id.org/bridge2ai/standards-datastandardortool-schema/707)|[Registry](Registry)|Bioregistry|Bioregistry||
| standardsregistry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Standards, tools, reference implementations, and related resources.|True|False|||[https://github.com/bridge2ai/b2ai-standards-registry](https://github.com/bridge2ai/b2ai-standards-registry)|[STANDARDSDATASTANDARDORTOOL:708](https://w3id.org/bridge2ai/standards-datastandardortool-schema/708)|[Registry](Registry)|Bridge2AI registry|Bridge to Artificial Intelligence Registry||
||| [STANDARDSORGANIZATION:15](STANDARDSORGANIZATION:15)|CDISC launched the CDISC Shared Health And Research Electronic library (SHARE) to provide the standards metadata in machine-readable formats to facilitate the automated management and implementation of the standards.|True|True|[https://www.cdisc.org/faq/share/what-cdisc-share](https://www.cdisc.org/faq/share/what-cdisc-share)|[PUBMED:29888049](PUBMED:29888049)||[STANDARDSDATASTANDARDORTOOL:709](https://w3id.org/bridge2ai/standards-datastandardortool-schema/709)|[Registry](Registry)|CDISC SHARE|CDISC Shared Health And Research Electronic library||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A catalog of worldwide biological databases maintained by the China National Center for Bioinformation,|True|False|[https://ngdc.cncb.ac.cn/databasecommons/](https://ngdc.cncb.ac.cn/databasecommons/)|[doi:10.1016/j.gpb.2022.12.004](doi:10.1016/j.gpb.2022.12.004)||[STANDARDSDATASTANDARDORTOOL:710](https://w3id.org/bridge2ai/standards-datastandardortool-schema/710)|[Registry](Registry)|Database Commons|Database Commons||
| softwareregistry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|A free and open source platform for sharing reusable and scalable analytical tools and workflows.|True|False|[https://dockstore.org/](https://dockstore.org/)||[https://github.com/dockstore/dockstore](https://github.com/dockstore/dockstore)|[STANDARDSDATASTANDARDORTOOL:711](https://w3id.org/bridge2ai/standards-datastandardortool-schema/711)|[Registry](Registry)|Dockstore|Dockstore||
| standardsregistry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||standards and databases|True|False|[https://fairsharing.org/](https://fairsharing.org/)||[https://github.com/FAIRsharing](https://github.com/FAIRsharing)|[STANDARDSDATASTANDARDORTOOL:712](https://w3id.org/bridge2ai/standards-datastandardortool-schema/712)|[Registry](Registry)|Fairsharing|Fairsharing||
| standardsregistry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||schemas and machine-actionable standards|True|False|[https://linkml.io/linkml-registry/registry/](https://linkml.io/linkml-registry/registry/)||[https://github.com/linkml/linkml-registry/](https://github.com/linkml/linkml-registry/)|[STANDARDSDATASTANDARDORTOOL:713](https://w3id.org/bridge2ai/standards-datastandardortool-schema/713)|[DataStandardOrTool](DataStandardOrTool)|LinkML registry|LinkML schema registry||
| standardsregistry| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4) [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7)| [STANDARDSORGANIZATION:71](STANDARDSORGANIZATION:71)|Registry and repository for oncology research common data elements and forms.|True|False|[https://datascience.cancer.gov/resources/metadata](https://datascience.cancer.gov/resources/metadata)||[https://cdebrowser.nci.nih.gov/cdebrowserClient/cdeBrowser.html#/search](https://cdebrowser.nci.nih.gov/cdebrowserClient/cdeBrowser.html#/search)|[STANDARDSDATASTANDARDORTOOL:714](https://w3id.org/bridge2ai/standards-datastandardortool-schema/714)|[Registry](Registry)|NCI caDSR|National Cancer Institute Cancer Data Standards Repository||
| dataregistry|||The primary purpose of NRDR is to aid facilities with their quality improvement programs and efforts to improve patient care by comparing facility data to that of their region and the nation. A practice or facility may choose to participate in any or all registries as appropriate for their practice. When a facility joins more than one registry, the warehouse allows information to be shared across registries within the facility.|False|True|[https://nrdr.acr.org/Portal/Nrdr/Main/page.aspx](https://nrdr.acr.org/Portal/Nrdr/Main/page.aspx)|[doi:10.1016/j.jacr.2011.05.014](doi:10.1016/j.jacr.2011.05.014)||[STANDARDSDATASTANDARDORTOOL:715](https://w3id.org/bridge2ai/standards-datastandardortool-schema/715)|[Registry](Registry)|NRDR|National Radiology Data Registry||
| ontologyregistry| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [obofoundry](obofoundry)|Ontologies.|True|False|[https://obofoundry.org/](https://obofoundry.org/)|[doi:10.1093/database/baab069](doi:10.1093/database/baab069)||[STANDARDSDATASTANDARDORTOOL:716](https://w3id.org/bridge2ai/standards-datastandardortool-schema/716)|[Registry](Registry)|OBO Foundry|Open Biological and Biomedical Ontology Foundry||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A free and open resource with Machine Learning papers, code, datasets, methods and evaluation tables.|True|False|[https://paperswithcode.com/](https://paperswithcode.com/)||[https://github.com/paperswithcode](https://github.com/paperswithcode)|[STANDARDSDATASTANDARDORTOOL:717](https://w3id.org/bridge2ai/standards-datastandardortool-schema/717)|[Registry](Registry)|PwC|Papers With Code||
| dataregistry|||re3data is a global registry of research data repositories. The registry covers research data repositories from different academic disciplines. re3data presents repositories for the permanent storage and access of data sets to researchers, funding bodies, publishers and scholarly institutions. re3data aims to promote a culture of sharing, increased access and better visibility of research data.|True|False|[https://www.re3data.org/](https://www.re3data.org/)|[doi:10.5281/zenodo.6697943](doi:10.5281/zenodo.6697943)||[STANDARDSDATASTANDARDORTOOL:718](https://w3id.org/bridge2ai/standards-datastandardortool-schema/718)|[DataStandardOrTool](DataStandardOrTool)|r3data|Registry of Research Data Repositories||
| dataregistry|| [RSNA](RSNA)|The joint RSNA and American College of Radiology (ACR) 3D printing clinical data registry collects 3D printing data at the point of clinical care. With the goal of improving both patient care and characterizing resource utilization, the brand-new registry collects anonymized 3D printing case information, clinical indications and intended uses for printed models, source imaging, model construction techniques and effort, 3D printing techniques and effort, and the clinical impact of the models.|False|True|[https://www.rsna.org/practice-tools/RSNA-ACR-3D-printing-registry](https://www.rsna.org/practice-tools/RSNA-ACR-3D-printing-registry)|||[STANDARDSDATASTANDARDORTOOL:719](https://w3id.org/bridge2ai/standards-datastandardortool-schema/719)|[Registry](Registry)|3DP Registry|RSNA-ACR 3D Printing Registry||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|A framework for transforming free-text problem descriptions into standardized Health Level 7 (HL7) Fast Healthcare Interoperability Resources (FHIR) models.|True|False||[doi:10.1016/j.jbi.2020.103541](doi:10.1016/j.jbi.2020.103541)|[https://github.com/OHNLP/clinical-problem-standardization](https://github.com/OHNLP/clinical-problem-standardization)|[STANDARDSDATASTANDARDORTOOL:720](https://w3id.org/bridge2ai/standards-datastandardortool-schema/720)|[SoftwareOrTool](SoftwareOrTool)|clinical-problem-standardization|A corpus-driven standardization framework for encoding clinical problems with HL7 FHIR||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|A Research Exploration System designed to improved the transparency of observational data research. ARES is an opinionated framework that delineates three levels of observational data assessment.|True|False|||[https://github.com/OHDSI/Ares](https://github.com/OHDSI/Ares)|[STANDARDSDATASTANDARDORTOOL:721](https://w3id.org/bridge2ai/standards-datastandardortool-schema/721)|[SoftwareOrTool](SoftwareOrTool)|ARES|A Research Exploration System||
| machinelearningframework| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Aesara is a Python library that allows one to define, optimize, and efficiently evaluate mathematical expressions involving multi-dimensional arrays.|True|False|||[https://github.com/aesara-devs/aesara](https://github.com/aesara-devs/aesara)|[STANDARDSDATASTANDARDORTOOL:722](https://w3id.org/bridge2ai/standards-datastandardortool-schema/722)|[SoftwareOrTool](SoftwareOrTool)|Aesara|Aesara||
| cloudservice| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Cloud computing platform.|False|True|[https://aws.amazon.com/](https://aws.amazon.com/)|||[STANDARDSDATASTANDARDORTOOL:723](https://w3id.org/bridge2ai/standards-datastandardortool-schema/723)|[SoftwareOrTool](SoftwareOrTool)|AWS|Amazon Web Services||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Amundsen is a data discovery and metadata engine for improving the productivity of data analysts, data scientists and engineers when interacting with data. It does that today by indexing data resources (tables, dashboards, streams, etc.) and powering a page-rank style search based on usage patterns (e.g. highly queried tables show up earlier than less queried tables).|True|False|[https://www.amundsen.io/](https://www.amundsen.io/)||[https://github.com/amundsen-io/amundsen](https://github.com/amundsen-io/amundsen)|[STANDARDSDATASTANDARDORTOOL:724](https://w3id.org/bridge2ai/standards-datastandardortool-schema/724)|[SoftwareOrTool](SoftwareOrTool)|Amundsen|Amundsen||
| toolkit| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20)||Anduril is a workflow platform for analyzing large data sets. Anduril provides facilities for analyzing high-thoughput data in biomedical research, and the platform is fully extensible by third parties.|True|False|[https://anduril.org/site/](https://anduril.org/site/)|[doi:10.1093/bioinformatics/btz133](doi:10.1093/bioinformatics/btz133)|[https://bitbucket.org/anduril-dev/anduril/src/stable/](https://bitbucket.org/anduril-dev/anduril/src/stable/)|[STANDARDSDATASTANDARDORTOOL:725](https://w3id.org/bridge2ai/standards-datastandardortool-schema/725)|[SoftwareOrTool](SoftwareOrTool)|Anduril|Anduril||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:5](STANDARDSORGANIZATION:5)|Apache Atlas provides open metadata management and governance capabilities for organizations to build a catalog of their data assets, classify and govern these assets and provide collaboration capabilities around these data assets for data scientists, analysts and the data governance team.|True|False|[https://atlas.apache.org/](https://atlas.apache.org/)||[https://github.com/apache/atlas](https://github.com/apache/atlas)|[STANDARDSDATASTANDARDORTOOL:726](https://w3id.org/bridge2ai/standards-datastandardortool-schema/726)|[SoftwareOrTool](SoftwareOrTool)|Apache Atlas|Apache Atlas||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:5](STANDARDSORGANIZATION:5)|Apache Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs.|True|False|[https://spark.apache.org/docs/latest/index.html](https://spark.apache.org/docs/latest/index.html)||[https://github.com/apache/spark](https://github.com/apache/spark)|[STANDARDSDATASTANDARDORTOOL:727](https://w3id.org/bridge2ai/standards-datastandardortool-schema/727)|[SoftwareOrTool](SoftwareOrTool)|Spark|Apache Spark||
| deprecated workflowlanguage| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Taverna is a domain-independent suite of tools used to design and execute data-driven workflows.|True|False|[https://incubator.apache.org/projects/taverna.html](https://incubator.apache.org/projects/taverna.html)|||[STANDARDSDATASTANDARDORTOOL:728](https://w3id.org/bridge2ai/standards-datastandardortool-schema/728)|[SoftwareOrTool](SoftwareOrTool)|Taverna|Apache Taverna||
| datavisualization notebookplatform| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Appyters extend the Jupyter Notebook language to support external, end-user configurable variables. Appyters can be considered a meta Jupyter Notebook language that is compatible with standard Jupyter Notebook execution.|True|False|[https://appyters.maayanlab.cloud/](https://appyters.maayanlab.cloud/)|[doi:10.1016/j.patter.2021.100213](doi:10.1016/j.patter.2021.100213)|[https://github.com/MaayanLab/appyter-catalog](https://github.com/MaayanLab/appyter-catalog)|[STANDARDSDATASTANDARDORTOOL:729](https://w3id.org/bridge2ai/standards-datastandardortool-schema/729)|[SoftwareOrTool](SoftwareOrTool)|Appyters|Appyters||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|A resource of searchable and loadable standardized vocabularies.|True|False|[https://athena.ohdsi.org/search-terms/terms](https://athena.ohdsi.org/search-terms/terms)||[https://github.com/OHDSI/Athena](https://github.com/OHDSI/Athena)|[STANDARDSDATASTANDARDORTOOL:730](https://w3id.org/bridge2ai/standards-datastandardortool-schema/730)|[SoftwareOrTool](SoftwareOrTool)|ATHENA|ATHENA||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|An open source software tool for researchers to conduct scientific analyses on standardized observational data converted to the OMOP Common Data Model V5. Researchers can create cohorts by defining groups of people based on an exposure to a drug or diagnosis of a particular condition using healthcare claims data.|True|False|[https://atlas-demo.ohdsi.org/#/home](https://atlas-demo.ohdsi.org/#/home)||[https://github.com/OHDSI/Atlas](https://github.com/OHDSI/Atlas)|[STANDARDSDATASTANDARDORTOOL:731](https://w3id.org/bridge2ai/standards-datastandardortool-schema/731)|[SoftwareOrTool](SoftwareOrTool)|ATLAS|ATLAS||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4) [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)||A database of continuously-recorded physiological waveform data and other associated clinical and medical device data. Also the platform for storage and retrieval of clinical waveform data.|False|True|[https://laussenlabs.ca/atriumdb/](https://laussenlabs.ca/atriumdb/)|[doi:10.1088/1361-6579/ab7cb5](doi:10.1088/1361-6579/ab7cb5)||[STANDARDSDATASTANDARDORTOOL:732](https://w3id.org/bridge2ai/standards-datastandardortool-schema/732)|[SoftwareOrTool](SoftwareOrTool)|AtriumDB|AtriumDB||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|Provides descriptive statistics on an OMOP CDM database.|True|False|[https://ohdsi.github.io/TheBookOfOhdsi/DataQuality.html#data-quality-checks](https://ohdsi.github.io/TheBookOfOhdsi/DataQuality.html#data-quality-checks)||[https://github.com/OHDSI/Achilles](https://github.com/OHDSI/Achilles)|[STANDARDSDATASTANDARDORTOOL:733](https://w3id.org/bridge2ai/standards-datastandardortool-schema/733)|[SoftwareOrTool](SoftwareOrTool)|ACHILLES|Automated Characterization of Health Information at Large-scale Longitudinal Evidence System||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [Meta](Meta)|A Python package for balancing biased data samples.|True|False|[https://import-balance.org/](https://import-balance.org/)||[https://github.com/facebookresearch/balance](https://github.com/facebookresearch/balance)|[STANDARDSDATASTANDARDORTOOL:734](https://w3id.org/bridge2ai/standards-datastandardortool-schema/734)|[SoftwareOrTool](SoftwareOrTool)|balance|balance package||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:37](STANDARDSORGANIZATION:37)|A fully managed, serverless data warehouse that enables scalable analysis over petabytes of data. It is a Platform as a Service (PaaS) that supports querying using ANSI SQL.|False|True|[https://cloud.google.com/bigquery](https://cloud.google.com/bigquery)|||[STANDARDSDATASTANDARDORTOOL:735](https://w3id.org/bridge2ai/standards-datastandardortool-schema/735)|[SoftwareOrTool](SoftwareOrTool)|BigQuery|BigQuery||
| toolkit| [STANDARDSDATATOPIC:1](STANDARDSDATATOPIC:1)||Biopython is a set of freely available tools for biological computation written in Python by an international team of developers. It is a distributed collaborative effort to develop Python libraries and applications which address the needs of current and future work in bioinformatics. The source code is made available under the Biopython License, which is extremely liberal and compatible with almost every license in the world.|True|False|[https://biopython.org/](https://biopython.org/)||[https://github.com/biopython/biopython](https://github.com/biopython/biopython)|[STANDARDSDATASTANDARDORTOOL:736](https://w3id.org/bridge2ai/standards-datastandardortool-schema/736)|[SoftwareOrTool](SoftwareOrTool)|Biopython|Biopython||
| toolkit| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20)||This package bundles popular tasks in computational molecular biology into a uniform Python library.|True|False|[https://www.biotite-python.org/](https://www.biotite-python.org/)||[https://github.com/biotite-dev/biotite](https://github.com/biotite-dev/biotite)|[STANDARDSDATASTANDARDORTOOL:737](https://w3id.org/bridge2ai/standards-datastandardortool-schema/737)|[SoftwareOrTool](SoftwareOrTool)|Biotite|Biotite||
|| [STANDARDSDATATOPIC:22](STANDARDSDATATOPIC:22)||A toolbox for the statistical analysis and context decoding of neuroimaging data. It implements both univariate and multivariate linear models and interfaces with the BigBrain Atlas, Allen Human Brain Atlas and Nimare databases.|True|False|[https://brainstat.readthedocs.io/](https://brainstat.readthedocs.io/)|[doi:10.1016/j.neuroimage.2022.119807](doi:10.1016/j.neuroimage.2022.119807)|[https://github.com/MICA-MNI/BrainStat](https://github.com/MICA-MNI/BrainStat)|[STANDARDSDATASTANDARDORTOOL:738](https://w3id.org/bridge2ai/standards-datastandardortool-schema/738)|[SoftwareOrTool](SoftwareOrTool)|BrainStat|BrainStat||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [7B](7B)|A data analysis and sharing platform designed to accelerate discovery in a scalable, cloud-based compute environment where data, results, and workflows are shared among the world's research community. Developed by Seven Bridges and funded in-part by a grant from the National Institutes of Health (NIH) Common Fund, CAVATICA is continuously updated with new tools and datasets.|False|True|[https://www.cavatica.org/](https://www.cavatica.org/)|||[STANDARDSDATASTANDARDORTOOL:739](https://w3id.org/bridge2ai/standards-datastandardortool-schema/739)|[SoftwareOrTool](SoftwareOrTool)|Cavatica|Cavatica data analysis platform||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Celery is a simple, flexible, and reliable distributed system to process vast amounts of messages, while providing operations with the tools required to maintain such a system. It’s a task queue with focus on real-time processing, while also supporting task scheduling.|True|False|[https://docs.celeryq.dev/en/latest/](https://docs.celeryq.dev/en/latest/)||[https://github.com/celery/celery](https://github.com/celery/celery)|[STANDARDSDATASTANDARDORTOOL:740](https://w3id.org/bridge2ai/standards-datastandardortool-schema/740)|[SoftwareOrTool](SoftwareOrTool)|Celery|Celery - Distributed Task Queue||
|| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||An updated version of the CliXO (Clique eXtracted Ontology) algorithm for inferring gene ontology terms from pairwise gene similarity data.|True|False||[doi:10.1126/science.abf3067](doi:10.1126/science.abf3067)|[https://github.com/fanzheng10/CliXO-1.0](https://github.com/fanzheng10/CliXO-1.0)|[STANDARDSDATASTANDARDORTOOL:741](https://w3id.org/bridge2ai/standards-datastandardortool-schema/741)|[SoftwareOrTool](SoftwareOrTool)|CLiXO|Clique eXtracted Ontology||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Platform for managing machine learning models.|False|True|[https://www.comet.com/](https://www.comet.com/)||[https://github.com/comet-ml](https://github.com/comet-ml)|[STANDARDSDATASTANDARDORTOOL:742](https://w3id.org/bridge2ai/standards-datastandardortool-schema/742)|[SoftwareOrTool](SoftwareOrTool)|Comet|Comet||
|| [STANDARDSDATATOPIC:12, Networks and Pathways](STANDARDSDATATOPIC:12, Networks and Pathways)||Performs multiscale community detection and functional enrichment for network analysis through a service-oriented architecture. These features are provided by integrating popular community detection algorithms and enrichment tools. All the algorithms and tools run remotely on a dedicated server.|True|False|[https://cdaps.readthedocs.io/](https://cdaps.readthedocs.io/)|[doi:10.1371/journal.pcbi.1008239](doi:10.1371/journal.pcbi.1008239)|[https://github.com/cytoscape/cy-community-detection](https://github.com/cytoscape/cy-community-detection)|[STANDARDSDATASTANDARDORTOOL:743](https://w3id.org/bridge2ai/standards-datastandardortool-schema/743)|[SoftwareOrTool](SoftwareOrTool)|CDAPS|Community Detection APplication and Service||
|| [STANDARDSDATATOPIC:12](STANDARDSDATATOPIC:12) [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||Builds a CDAPS compatible community detection Docker image using CliXO.|True|False|||[https://github.com/idekerlab/cdclixo](https://github.com/idekerlab/cdclixo)|[STANDARDSDATASTANDARDORTOOL:744](https://w3id.org/bridge2ai/standards-datastandardortool-schema/744)|[SoftwareOrTool](SoftwareOrTool)|CD-CLiXO|Community Detection CliXO||
| datamodel| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A framework for rigorous self-validated data modeling and integrative, reproducible data analysis|True|False||[doi:10.1093/gigascience/giac089](doi:10.1093/gigascience/giac089)|[https://github.com/jmchandonia/CORAL](https://github.com/jmchandonia/CORAL)|[STANDARDSDATASTANDARDORTOOL:745](https://w3id.org/bridge2ai/standards-datastandardortool-schema/745)|[SoftwareOrTool](SoftwareOrTool)|CORAL|Contextual Ontology-based Repository Analysis Library||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Continuous Machine Learning (CML) is an open-source library for implementing continuous integration & delivery (CI/CD) in machine learning projects. Use it to automate parts of your development workflow, including model training and evaluation, comparing ML experiments across your project history, and monitoring changing datasets.|True|False|[https://cml.dev/](https://cml.dev/)||[https://github.com/iterative/cml](https://github.com/iterative/cml)|[STANDARDSDATASTANDARDORTOOL:746](https://w3id.org/bridge2ai/standards-datastandardortool-schema/746)|[SoftwareOrTool](SoftwareOrTool)|CML library|Continuous Machine Learning||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Cromwell is an open-source Workflow Management System for bioinformatics.|True|False|[https://cromwell.readthedocs.io/en/stable/](https://cromwell.readthedocs.io/en/stable/)|[doi:10.7490/f1000research.1114634.1](doi:10.7490/f1000research.1114634.1)|[https://github.com/broadinstitute/cromwell](https://github.com/broadinstitute/cromwell)|[STANDARDSDATASTANDARDORTOOL:747](https://w3id.org/bridge2ai/standards-datastandardortool-schema/747)|[SoftwareOrTool](SoftwareOrTool)|Cromwell|Cromwell Workflow Management System||
|| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||An open source software platform for visualizing complex networks and integrating these with any type of attribute data.|True|False|[https://cytoscape.org/](https://cytoscape.org/)||[https://github.com/cytoscape/cytoscape](https://github.com/cytoscape/cytoscape)|[STANDARDSDATASTANDARDORTOOL:748](https://w3id.org/bridge2ai/standards-datastandardortool-schema/748)|[SoftwareOrTool](SoftwareOrTool)|Cytoscape|Cytoscape software||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Open source orchestration platform for the development, production, and observation of data assets.|False|True|[https://dagster.io/](https://dagster.io/)||[https://github.com/dagster-io/dagster](https://github.com/dagster-io/dagster)|[STANDARDSDATASTANDARDORTOOL:749](https://w3id.org/bridge2ai/standards-datastandardortool-schema/749)|[SoftwareOrTool](SoftwareOrTool)|Dagster|Dagster||
| scrnaseqanalysis| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||A Python toolkit to support deep learning models for analyzing single-cell gene expression at scale.|True|False|[https://omicsml.ai/](https://omicsml.ai/)||[https://github.com/OmicsML/dance](https://github.com/OmicsML/dance)|[STANDARDSDATASTANDARDORTOOL:750](https://w3id.org/bridge2ai/standards-datastandardortool-schema/750)|[SoftwareOrTool](SoftwareOrTool)|DANCE|DANCE platform||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|generic interface to data repositories|True|False|[https://ga4gh.github.io/data-repository-service-schemas/preview/release/drs-1.2.0/docs/](https://ga4gh.github.io/data-repository-service-schemas/preview/release/drs-1.2.0/docs/)|||[STANDARDSDATASTANDARDORTOOL:751](https://w3id.org/bridge2ai/standards-datastandardortool-schema/751)|[SoftwareOrTool](SoftwareOrTool)|DRS|Data Repository Service||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Open-source version control system for machine learning and data set management.|True|False|[https://dvc.org/](https://dvc.org/)||[https://github.com/iterative/dvc](https://github.com/iterative/dvc)|[STANDARDSDATASTANDARDORTOOL:752](https://w3id.org/bridge2ai/standards-datastandardortool-schema/752)|[SoftwareOrTool](SoftwareOrTool)|DVC|Data Version Control||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||An open-source metadata platform.|True|False|[https://datahubproject.io/](https://datahubproject.io/)||[https://github.com/linkedin/datahub](https://github.com/linkedin/datahub)|[STANDARDSDATASTANDARDORTOOL:753](https://w3id.org/bridge2ai/standards-datastandardortool-schema/753)|[SoftwareOrTool](SoftwareOrTool)|DataHub|DataHub||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A tool for exploring and publishing data. It helps people take data of any shape, analyze and explore it, and publish it as an interactive website and accompanying API.|True|False|[https://datasette.io/](https://datasette.io/)||[https://github.com/simonw/datasette](https://github.com/simonw/datasette)|[STANDARDSDATASTANDARDORTOOL:754](https://w3id.org/bridge2ai/standards-datastandardortool-schema/754)|[SoftwareOrTool](SoftwareOrTool)|Datasette|Datasette||
| scrnaseqanalysis| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||An analysis method for scRNA-seq data that clusters single cells into genetically distinct subclones and reconstructs the phylogenetic tree relating the subclones.|True|False||[doi:10.1186/s13059-019-1922-x](doi:10.1186/s13059-019-1922-x)|[https://github.com/zhouzilu/DENDRO](https://github.com/zhouzilu/DENDRO)|[STANDARDSDATASTANDARDORTOOL:755](https://w3id.org/bridge2ai/standards-datastandardortool-schema/755)|[SoftwareOrTool](SoftwareOrTool)|DENDRO|DENDRO||
| machinelearningframework| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Determined is an open-source deep learning training platform.|True|False|[https://www.determined.ai/](https://www.determined.ai/)||[https://github.com/determined-ai/determined](https://github.com/determined-ai/determined)|[STANDARDSDATASTANDARDORTOOL:756](https://w3id.org/bridge2ai/standards-datastandardortool-schema/756)|[SoftwareOrTool](SoftwareOrTool)|Determined|Determined||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||Dicoogle is an open source Picture Archiving and Communications System (PACS) archive. Its modular architecture allows the quick development of new functionalities, due the availability of a Software Development Kit (SDK).|True|False|[https://dicoogle.com/](https://dicoogle.com/)|[doi:10.1109/ISCC50000.2020.9219545](doi:10.1109/ISCC50000.2020.9219545)|[https://github.com/bioinformatics-ua/dicoogle](https://github.com/bioinformatics-ua/dicoogle)|[STANDARDSDATASTANDARDORTOOL:757](https://w3id.org/bridge2ai/standards-datastandardortool-schema/757)|[SoftwareOrTool](SoftwareOrTool)|Dicoogle|Dicoogle Picture Archiving and Communications System||
| cloudservice| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Cloud computing platform.|False|True|[https://www.digitalocean.com/](https://www.digitalocean.com/)|||[STANDARDSDATASTANDARDORTOOL:758](https://w3id.org/bridge2ai/standards-datastandardortool-schema/758)|[SoftwareOrTool](SoftwareOrTool)|DigitalOcean|DigitalOcean||
| scrnaseqanalysis| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||An approach that detects doublet cell capture artifacts in scRNA-seq data with a combination of deconvolution analyses and the identification of unique cell-state gene expression.|True|False||[doi:10.1016/j.celrep.2019.09.082](doi:10.1016/j.celrep.2019.09.082)|[https://github.com/EDePasquale/DoubletDecon](https://github.com/EDePasquale/DoubletDecon)|[STANDARDSDATASTANDARDORTOOL:759](https://w3id.org/bridge2ai/standards-datastandardortool-schema/759)|[SoftwareOrTool](SoftwareOrTool)|DoubletDecon|DoubletDecon||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Open metadata and governance for enterprises - automatically capturing, managing and exchanging metadata between tools and platforms, no matter the vendor.|True|False|[https://egeria-project.org/](https://egeria-project.org/)||[https://github.com/odpi/egeria](https://github.com/odpi/egeria)|[STANDARDSDATASTANDARDORTOOL:760](https://w3id.org/bridge2ai/standards-datastandardortool-schema/760)|[SoftwareOrTool](SoftwareOrTool)|Egeria|Egeria||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Eido is used to 1) validate or 2) convert format of sample metadata. Sample metadata is stored according to the standard PEP specification. For validation, eido is based on JSON Schema and extends it with new features, like required input files.|True|False|[http://eido.databio.org/](http://eido.databio.org/)|[doi:10.1093/gigascience/giab077](doi:10.1093/gigascience/giab077)|[https://github.com/pepkit/eido](https://github.com/pepkit/eido)|[STANDARDSDATASTANDARDORTOOL:761](https://w3id.org/bridge2ai/standards-datastandardortool-schema/761)|[SoftwareOrTool](SoftwareOrTool)|Eido|Eido||
| scrnaseqanalysis| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||A simple denoising strategy for scRNA-seq data based on principal component analysis (PCA).|True|False||[doi:10.1101/655365](doi:10.1101/655365)|[https://github.com/yanailab/enhance](https://github.com/yanailab/enhance)|[STANDARDSDATASTANDARDORTOOL:762](https://w3id.org/bridge2ai/standards-datastandardortool-schema/762)|[SoftwareOrTool](SoftwareOrTool)|ENHANCE|Expression denoising heuristic using aggregation of neighbors and principal component extraction||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||FAIR Data Point (FDP) is a REST API for creating, storing, and serving FAIR metadata. This FDP implementation also presents a Web-based graphical user interface (GUI). The metadata contents are generated semi-automatically according to the FAIR Data Point software specification document.|True|False||[doi:10.1162/dint_a_00160](doi:10.1162/dint_a_00160)|[https://github.com/FAIRDataTeam/FAIRDataPoint](https://github.com/FAIRDataTeam/FAIRDataPoint)|[STANDARDSDATASTANDARDORTOOL:763](https://w3id.org/bridge2ai/standards-datastandardortool-schema/763)|[SoftwareOrTool](SoftwareOrTool)|FDP|FAIR Data Point||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A reusable computational framework, enabling simplified access to modern scalable cloud-based components. FAIRSCAPE fully implements the FAIR data principles and extends them to provide fully FAIR Evidence, including machine-interpretable provenance of datasets, software and computations, as metadata for all computed results.|True|False|[https://fairscape.github.io/](https://fairscape.github.io/)|[doi:10.1007/s12021-021-09529-4](doi:10.1007/s12021-021-09529-4)|[https://github.com/fairscape/fairscape](https://github.com/fairscape/fairscape)|[STANDARDSDATASTANDARDORTOOL:764](https://w3id.org/bridge2ai/standards-datastandardortool-schema/764)|[SoftwareOrTool](SoftwareOrTool)|FAIRSCAPE|FAIRSCAPE digital commons framework||
| machinelearningframework| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library.|True|False|[https://github.com/fastai/fastai](https://github.com/fastai/fastai)|||[STANDARDSDATASTANDARDORTOOL:765](https://w3id.org/bridge2ai/standards-datastandardortool-schema/765)|[SoftwareOrTool](SoftwareOrTool)|FastAI|FastAI||
| toolkit| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20)||Galaxy is an open source, web-based platform for data intensive biomedical research.|True|False|[https://usegalaxy.org/](https://usegalaxy.org/)|[doi:10.1093/nar/gky379](doi:10.1093/nar/gky379)|[https://github.com/galaxyproject/galaxy](https://github.com/galaxyproject/galaxy)|[STANDARDSDATASTANDARDORTOOL:766](https://w3id.org/bridge2ai/standards-datastandardortool-schema/766)|[SoftwareOrTool](SoftwareOrTool)|Galaxy|Galaxy||
| cloudservice| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:37](STANDARDSORGANIZATION:37)|Cloud computing platform.|False|True|[https://cloud.google.com/](https://cloud.google.com/)|||[STANDARDSDATASTANDARDORTOOL:767](https://w3id.org/bridge2ai/standards-datastandardortool-schema/767)|[SoftwareOrTool](SoftwareOrTool)|GCP|Google Cloud Platform||
| graphdataplatform machinelearningframework| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||A fast graph processing and embedding library, designed to scale with big graphs and to run on both off-the-shelf laptop and desktop computers and High Performance Computing clusters of workstations.|True|False||[doi:10.48550/arXiv.2110.06196](doi:10.48550/arXiv.2110.06196)|[https://github.com/AnacletoLAB/grape](https://github.com/AnacletoLAB/grape)|[STANDARDSDATASTANDARDORTOOL:768](https://w3id.org/bridge2ai/standards-datastandardortool-schema/768)|[SoftwareOrTool](SoftwareOrTool)|GrAPE|Graph Representation leArning, Predictions and Evaluation library||
|| [STANDARDSDATATOPIC:32](STANDARDSDATATOPIC:32) [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16)||HESML is an efficient, scalable and large Java software library of ontology-based semantic similarity measures and Information Content (IC) models based on WordNet, SNOMED-CT, MeSH or any other OBO-based ontology.|True|False|[http://hesml.lsi.uned.es/](http://hesml.lsi.uned.es/)|[doi:10.1186/S12859-021-04539-0](doi:10.1186/S12859-021-04539-0)|[https://github.com/jjlastra/HESML](https://github.com/jjlastra/HESML)|[STANDARDSDATASTANDARDORTOOL:769](https://w3id.org/bridge2ai/standards-datastandardortool-schema/769)|[SoftwareOrTool](SoftwareOrTool)|HESML|Half-Edge Semantic Measures Library||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Version control for tensor data.|True|False|[https://hangar-py.readthedocs.io/en/stable/](https://hangar-py.readthedocs.io/en/stable/)||[https://github.com/tensorwerk/hangar-py](https://github.com/tensorwerk/hangar-py)|[STANDARDSDATASTANDARDORTOOL:770](https://w3id.org/bridge2ai/standards-datastandardortool-schema/770)|[SoftwareOrTool](SoftwareOrTool)|Hangar|Hangar||
|| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|HADES (formally known as the OHDSI Methods Library) is a set of open source R packages for large scale analytics, including population characterization, population-level causal effect estimation, and patient-level prediction.|True|False|[https://ohdsi.github.io/Hades/](https://ohdsi.github.io/Hades/)||[https://github.com/OHDSI/Hades](https://github.com/OHDSI/Hades)|[STANDARDSDATASTANDARDORTOOL:771](https://w3id.org/bridge2ai/standards-datastandardortool-schema/771)|[SoftwareOrTool](SoftwareOrTool)|HADES|Health Analytics Data-to-Evidence Suite||
| multimodal|||A unified Holistic AI in Medicine (HAIM) framework to facilitate the generation and testing of AI systems that leverage multimodal inputs.|True|False||[doi:10.1038/s41746-022-00689-4](doi:10.1038/s41746-022-00689-4)|[https://github.com/lrsoenksen/HAIM](https://github.com/lrsoenksen/HAIM)|[STANDARDSDATASTANDARDORTOOL:772](https://w3id.org/bridge2ai/standards-datastandardortool-schema/772)|[SoftwareOrTool](SoftwareOrTool)|HAIM|Holistic AI in Medicine framework||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)||A Python library to facilitate the rapid development of high throughput sequencing data analysis scripts. HTSeq offers parsers for many common data formats in HTS projects, as well as classes to represent data, such as genomic coordinates, sequences, sequencing reads, alignments, gene model information and variant calls, and provides data structures that allow for querying via genomic coordinates.|True|False||[doi:10.1093/bioinformatics/btu638](doi:10.1093/bioinformatics/btu638)|[https://github.com/htseq/htseq](https://github.com/htseq/htseq)|[STANDARDSDATASTANDARDORTOOL:773](https://w3id.org/bridge2ai/standards-datastandardortool-schema/773)|[SoftwareOrTool](SoftwareOrTool)|HTSeq|HTSeq||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||A plugin powered hybrid computing platform for deploying deep learning applications such as advanced image analysis tools. ImJoy runs on mobile and desktop environment cross different operating systems, plugins can run in the browser, localhost, remote and cloud servers.|True|False|[https://imjoy.io/](https://imjoy.io/)|[doi:10.1038/s41592-019-0627-0](doi:10.1038/s41592-019-0627-0)|[https://github.com/imjoy-team/ImJoy](https://github.com/imjoy-team/ImJoy)|[STANDARDSDATASTANDARDORTOOL:774](https://w3id.org/bridge2ai/standards-datastandardortool-schema/774)|[SoftwareOrTool](SoftwareOrTool)|ImJoy|ImJoy||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)| [i2b2](i2b2)|A system for searching and exchanging clinical data.|True|False|[https://www.i2b2.org/software/index.html](https://www.i2b2.org/software/index.html)|[doi:10.1093/jamia/ocv188](doi:10.1093/jamia/ocv188)|[https://github.com/i2b2](https://github.com/i2b2)|[STANDARDSDATASTANDARDORTOOL:775](https://w3id.org/bridge2ai/standards-datastandardortool-schema/775)|[SoftwareOrTool](SoftwareOrTool)|i2b2|Informatics for Integrating Biology and the Bedside platform||
|| [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||The Insight Toolkit (ITK) is an open-source, cross-platform toolkit for N-dimensional scientific image processing, segmentation, and registration.|True|False|[https://itk.org/](https://itk.org/)||[https://github.com/InsightSoftwareConsortium/ITK](https://github.com/InsightSoftwareConsortium/ITK)|[STANDARDSDATASTANDARDORTOOL:776](https://w3id.org/bridge2ai/standards-datastandardortool-schema/776)|[SoftwareOrTool](SoftwareOrTool)|ITK|Insight Segmentation and Registration Toolkit||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9) [STANDARDSDATATOPIC:15](STANDARDSDATATOPIC:15)||A free and open-source web application to digitize, process and explore multimodal patient data. IMPatienT has a modular architecture, including four components to (i) create a standard vocabulary for a domain, (ii) digitize and process free-text data by mapping it to a set of standard terms, (iii) annotate images and perform image segmentation, and (iv) generate an automatic visualization dashboard to provide insight on the data and perform automatic diagnosis suggestions.|True|False|[https://impatient.lbgi.fr](https://impatient.lbgi.fr)||[https://github.com/lambda-science/IMPatienT](https://github.com/lambda-science/IMPatienT)|[STANDARDSDATASTANDARDORTOOL:777](https://w3id.org/bridge2ai/standards-datastandardortool-schema/777)|[SoftwareOrTool](SoftwareOrTool)|IMPatienT|Integrated digital Multimodal PATIENt daTa framework||
|| [STANDARDSDATATOPIC:27](STANDARDSDATATOPIC:27)||An open source C++ and Python toolbox for solving complex modeling problems, and a number of applications for tackling some common problems in a user-friendly way. IMP can also be used from the Chimera molecular modeling system, or via one of several web applications.|True|False|[https://integrativemodeling.org/](https://integrativemodeling.org/)||[https://github.com/salilab/imp](https://github.com/salilab/imp)|[STANDARDSDATASTANDARDORTOOL:778](https://w3id.org/bridge2ai/standards-datastandardortool-schema/778)|[SoftwareOrTool](SoftwareOrTool)|IMP|Integrative Modeling Platform||
| notebookplatform| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A web-based notebook environment for interactive computing.|True|False|[https://jupyter.org/](https://jupyter.org/)||[https://github.com/jupyter/notebook](https://github.com/jupyter/notebook)|[STANDARDSDATASTANDARDORTOOL:779](https://w3id.org/bridge2ai/standards-datastandardortool-schema/779)|[SoftwareOrTool](SoftwareOrTool)|Jupyter|Jupyter Notebook||
|| [STANDARDSDATATOPIC:37](STANDARDSDATATOPIC:37)||Toolkit for speech recognition.|True|False|[https://kaldi-asr.org/](https://kaldi-asr.org/)||[https://github.com/kaldi-asr/kaldi](https://github.com/kaldi-asr/kaldi)|[STANDARDSDATASTANDARDORTOOL:780](https://w3id.org/bridge2ai/standards-datastandardortool-schema/780)|[SoftwareOrTool](SoftwareOrTool)|Kaldi|Kaldi Speech Recognition Toolkit||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Version control for machine learning. A Python library that uploads files and metadata (like hyperparameters) to Amazon S3 or Google Cloud Storage.|True|False|[https://keepsake.ai/](https://keepsake.ai/)||[https://github.com/replicate/keepsake](https://github.com/replicate/keepsake)|[STANDARDSDATASTANDARDORTOOL:781](https://w3id.org/bridge2ai/standards-datastandardortool-schema/781)|[SoftwareOrTool](SoftwareOrTool)|Keepsake|Keepsake||
||||A freely available software library for working efficiently with fixed length DNA words, or k-mers. khmer provides implementations of a probabilistic k-mer counting data structure, a compressible De Bruijn graph representation, De Bruijn graph partitioning, and digital normalization.|True|False|[https://khmer.readthedocs.io/](https://khmer.readthedocs.io/)|[doi:10.12688/f1000research.6924.1](doi:10.12688/f1000research.6924.1)|[https://github.com/dib-lab/khmer/](https://github.com/dib-lab/khmer/)|[STANDARDSDATASTANDARDORTOOL:782](https://w3id.org/bridge2ai/standards-datastandardortool-schema/782)|[SoftwareOrTool](SoftwareOrTool)|khmer|khmer||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|Transform csv, json, yaml, jsonl, and xml and converting them to a target csv, json, or jsonl format based on your dataclass model. Koza also can output data in the KGX format. Write data transforms in semi-declarative Python. Configure source files, expected columns/json properties and path filters, field filters, and metadata in yaml. Create or import mapping files to be used in ingests (eg id mapping, type mappings). Create and use translation tables to map between source and target vocabularies.|True|False|||[https://github.com/monarch-initiative/koza](https://github.com/monarch-initiative/koza)|[STANDARDSDATASTANDARDORTOOL:783](https://w3id.org/bridge2ai/standards-datastandardortool-schema/783)|[SoftwareOrTool](SoftwareOrTool)|Koza|Koza data transformation framework||
|| [STANDARDSDATATOPIC:7](STANDARDSDATATOPIC:7) [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25) [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|Performs phenotype-driven prioritization of candidate diseases and genes in the setting of genomic diagnostics (exome or genome) in which the phenotypic abnormalities are described as Human Phenotype Ontology (HPO) terms.|True|False|[https://lirical.readthedocs.io/](https://lirical.readthedocs.io/)|[doi:10.1016/j.ajhg.2020.06.021](doi:10.1016/j.ajhg.2020.06.021)|[https://github.com/TheJacksonLaboratory/LIRICAL](https://github.com/TheJacksonLaboratory/LIRICAL)|[STANDARDSDATASTANDARDORTOOL:784](https://w3id.org/bridge2ai/standards-datastandardortool-schema/784)|[SoftwareOrTool](SoftwareOrTool)|LIRICAL|LIkelihood Ratio Interpretation of Clinical AbnormaLities||
| cloudservice| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Cloud computing platform.|False|True|[https://www.linode.com/](https://www.linode.com/)|||[STANDARDSDATASTANDARDORTOOL:785](https://w3id.org/bridge2ai/standards-datastandardortool-schema/785)|[SoftwareOrTool](SoftwareOrTool)|Linode|Linode||
| scrnaseqanalysis| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||A method for imputing missing values in scRNA-seq data.|True|False|[https://www.krishnaswamylab.org/projects/magic](https://www.krishnaswamylab.org/projects/magic)|[doi:10.1016/j.cell.2018.05.061](doi:10.1016/j.cell.2018.05.061)|[https://github.com/KrishnaswamyLab/MAGIC](https://github.com/KrishnaswamyLab/MAGIC)|[STANDARDSDATASTANDARDORTOOL:786](https://w3id.org/bridge2ai/standards-datastandardortool-schema/786)|[SoftwareOrTool](SoftwareOrTool)|MAGIC|Markov Affinity-based Graph Imputation of Cells||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Marquez is an open source metadata service for the collection, aggregation, and visualization of a data ecosystem's metadata. It maintains the provenance of how datasets are consumed and produced, provides global visibility into job runtime and frequency of dataset access, centralization of dataset lifecycle management, and much more. Marquez was released and open sourced by WeWork.|True|False|[https://lfaidata.foundation/projects/marquez/](https://lfaidata.foundation/projects/marquez/)||[https://github.com/MarquezProject/marquez](https://github.com/MarquezProject/marquez)|[STANDARDSDATASTANDARDORTOOL:787](https://w3id.org/bridge2ai/standards-datastandardortool-schema/787)|[SoftwareOrTool](SoftwareOrTool)|Marquez|Marquez||
| machinelearningframework| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||MONAI is a PyTorch-based, open-source framework for deep learning in healthcare imaging, part of PyTorch Ecosystem.|True|False|[https://monai.io/](https://monai.io/)||[https://github.com/Project-MONAI/MONAI](https://github.com/Project-MONAI/MONAI)|[STANDARDSDATASTANDARDORTOOL:788](https://w3id.org/bridge2ai/standards-datastandardortool-schema/788)|[SoftwareOrTool](SoftwareOrTool)|MONAI|Medical Open Network for AI||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [Netflix](Netflix)|Metacat is a unified metadata exploration API service. You can explore Hive, RDS, Teradata, Redshift, S3 and Cassandra. Metacat provides you information about what data you have, where it resides and how to process it.|True|False|||[https://github.com/Netflix/metacat](https://github.com/Netflix/metacat)|[STANDARDSDATASTANDARDORTOOL:789](https://w3id.org/bridge2ai/standards-datastandardortool-schema/789)|[SoftwareOrTool](SoftwareOrTool)|Metacat|Metacat||
| cloudservice| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:56](STANDARDSORGANIZATION:56)|Cloud computing platform.|False|True|[https://azure.microsoft.com/](https://azure.microsoft.com/)|||[STANDARDSDATASTANDARDORTOOL:790](https://w3id.org/bridge2ai/standards-datastandardortool-schema/790)|[SoftwareOrTool](SoftwareOrTool)|Azure|Microsoft Azure||
| cloudservice| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||S3 compatible object storage. Native to Kubernetes, MinIO is the only object storage suite available on every public cloud, every Kubernetes distribution, the private cloud and the edge. MinIO is software-defined and is 100% open source under GNU AGPL v3.|True|False|[https://min.io/](https://min.io/)||[https://github.com/minio/](https://github.com/minio/)|[STANDARDSDATASTANDARDORTOOL:791](https://w3id.org/bridge2ai/standards-datastandardortool-schema/791)|[SoftwareOrTool](SoftwareOrTool)|MinIO|MinIO||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:37](STANDARDSORGANIZATION:37)|ML Metadata (MLMD) is a library for recording and retrieving metadata associated with ML developer and data scientist workflows.|True|False|[https://www.tensorflow.org/tfx/guide/mlmd](https://www.tensorflow.org/tfx/guide/mlmd)||[https://github.com/google/ml-metadata](https://github.com/google/ml-metadata)|[STANDARDSDATASTANDARDORTOOL:792](https://w3id.org/bridge2ai/standards-datastandardortool-schema/792)|[SoftwareOrTool](SoftwareOrTool)|MLMD|ML Metadata||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||MLflow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry|True|False|[https://mlflow.org/](https://mlflow.org/)||[https://github.com/mlflow/mlflow/](https://github.com/mlflow/mlflow/)|[STANDARDSDATASTANDARDORTOOL:793](https://w3id.org/bridge2ai/standards-datastandardortool-schema/793)|[SoftwareOrTool](SoftwareOrTool)|MLflow|MLflow platform||
| machinelearningframework| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Embeds flexible and recombinable ML models into standardized processes for training and real operations. In addition, it integrates numerous common open source frameworks and thus standardizes their use.|True|False|[https://mlpro.readthedocs.io/](https://mlpro.readthedocs.io/)|[doi:10.1016/j.simpa.2022.100421](doi:10.1016/j.simpa.2022.100421)|[https://github.com/fhswf/MLPro](https://github.com/fhswf/MLPro)|[STANDARDSDATASTANDARDORTOOL:794](https://w3id.org/bridge2ai/standards-datastandardortool-schema/794)|[SoftwareOrTool](SoftwareOrTool)|MLPro|MLPro framework||
| scrnaseqanalysis| [STANDARDSDATATOPIC:23](STANDARDSDATATOPIC:23)||A novel joint clustering framework that can be applied to several types of single-cell multi-omics data. A selective automatic doublet detection module that can identify and filter out doublets is introduced in the pretraining stage to improve data quality. Omics-specific autoencoders are introduced to characterize the multi-omics data.|True|False|[https://zenodo.org/record/7306504](https://zenodo.org/record/7306504)|[doi:10.1093/bioinformatics/btac736](doi:10.1093/bioinformatics/btac736)||[STANDARDSDATASTANDARDORTOOL:795](https://w3id.org/bridge2ai/standards-datastandardortool-schema/795)|[SoftwareOrTool](SoftwareOrTool)|MoClust|MoClust||
| modelcards| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:37](STANDARDSORGANIZATION:37)|The Model Card Toolkit (MCT) streamlines and automates generation of Model Cards, machine learning documents that provide context and transparency into a model's development and performance.|True|False||[doi:10.48550/arXiv.1810.03993](doi:10.48550/arXiv.1810.03993)|[https://github.com/tensorflow/model-card-toolkit](https://github.com/tensorflow/model-card-toolkit)|[STANDARDSDATASTANDARDORTOOL:796](https://w3id.org/bridge2ai/standards-datastandardortool-schema/796)|[SoftwareOrTool](SoftwareOrTool)|MCT|Model Card Toolkit||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A non-relational document database that provides support for JSON-like storage.|True|False|[https://www.mongodb.com/](https://www.mongodb.com/)||[https://github.com/mongodb/mongo](https://github.com/mongodb/mongo)|[STANDARDSDATASTANDARDORTOOL:797](https://w3id.org/bridge2ai/standards-datastandardortool-schema/797)|[SoftwareOrTool](SoftwareOrTool)|MongoDB|MongoDB||
|| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||An algorithm that uses reversed graph embedding to describe multiple fate decisions in a fully unsupervised manner.|True|False||[doi:10.1038/nmeth.4402](doi:10.1038/nmeth.4402)|[https://github.com/cole-trapnell-lab/monocle-release](https://github.com/cole-trapnell-lab/monocle-release)|[STANDARDSDATASTANDARDORTOOL:798](https://w3id.org/bridge2ai/standards-datastandardortool-schema/798)|[SoftwareOrTool](SoftwareOrTool)|Monocle2|Monocle 2||
| multimodal| [STANDARDSDATATOPIC:23](STANDARDSDATATOPIC:23)||MIMaL is a new method for integrating multiomic data using SHAP model explanations.|True|False|[https://mimal.app/](https://mimal.app/)|[doi:10.1093/bioinformatics/btac631](doi:10.1093/bioinformatics/btac631)|[https://github.com/jessegmeyerlab/MIMaL](https://github.com/jessegmeyerlab/MIMaL)|[STANDARDSDATASTANDARDORTOOL:799](https://w3id.org/bridge2ai/standards-datastandardortool-schema/799)|[SoftwareOrTool](SoftwareOrTool)|MIMaL|Multi-Omic Integration by Machine Learning||
| multimodal| [STANDARDSDATATOPIC:26, Proteome](STANDARDSDATATOPIC:26, Proteome)||MuSIC is a hierarchical map of human cell architecture created from integrating immunofluorescence images in the Human Protein Atlas with affinity purification experiments from the BioPlex resource. Integration involves configuring each approach to produce a general measure of protein distance, then calibrating the two measures using machine learning.|True|False|[https://nrnb.org/music/](https://nrnb.org/music/)|[doi:10.1038/s41586-021-04115-9](doi:10.1038/s41586-021-04115-9)|[https://github.com/idekerlab/MuSIC](https://github.com/idekerlab/MuSIC)|[STANDARDSDATASTANDARDORTOOL:800](https://w3id.org/bridge2ai/standards-datastandardortool-schema/800)|[SoftwareOrTool](SoftwareOrTool)|MuSIC|Multi-Scale Integrated Cell pipeline||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A relational database management system developed by Oracle that is based on structured query language (SQL).|True|False|[https://www.mysql.com/](https://www.mysql.com/)||[https://github.com/mysql/mysql-server](https://github.com/mysql/mysql-server)|[STANDARDSDATASTANDARDORTOOL:801](https://w3id.org/bridge2ai/standards-datastandardortool-schema/801)|[SoftwareOrTool](SoftwareOrTool)|MySQL|MySQL||
| graphdataplatform| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||A popular graph database platform.|True|False|[https://neo4j.com/](https://neo4j.com/)||[https://github.com/neo4j/neo4j](https://github.com/neo4j/neo4j)|[STANDARDSDATASTANDARDORTOOL:802](https://w3id.org/bridge2ai/standards-datastandardortool-schema/802)|[SoftwareOrTool](SoftwareOrTool)|Neo4j|Neo4j Graph Data Platform||
|| [STANDARDSDATATOPIC:16](STANDARDSDATATOPIC:16)||Starting from a set of fulltext obtained from PubMed, through an easy-to-use web interface, interactively extracts a group of biological elements stored into a selected list of ontological databases and then synthesizes a network with inferred relations among such elements.|True|False|[https://netme.click/#/](https://netme.click/#/)|[doi:10.1007/S41109-021-00435-X](doi:10.1007/S41109-021-00435-X)||[STANDARDSDATASTANDARDORTOOL:803](https://w3id.org/bridge2ai/standards-datastandardortool-schema/803)|[SoftwareOrTool](SoftwareOrTool)|NETME|NETME||
| scrnaseqanalysis| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||A network analysis pipeline for RNA-Seq time series data.|True|False||[doi:10.1186/S12859-021-04554-1](doi:10.1186/S12859-021-04554-1)|[https://github.com/igbb-popescu-lab/NetSeekR](https://github.com/igbb-popescu-lab/NetSeekR)|[STANDARDSDATASTANDARDORTOOL:804](https://w3id.org/bridge2ai/standards-datastandardortool-schema/804)|[SoftwareOrTool](SoftwareOrTool)|NetSeekR|NetSeekR network analysis R package||
| graphdataplatform| [STANDARDSDATATOPIC:21](STANDARDSDATATOPIC:21)||The NDEx Project provides an open-source framework where scientists and organizations can store, share, manipulate, and publish biological network knowledge.|True|True|[https://www.ndexbio.org/](https://www.ndexbio.org/)|||[STANDARDSDATASTANDARDORTOOL:805](https://w3id.org/bridge2ai/standards-datastandardortool-schema/805)|[SoftwareOrTool](SoftwareOrTool)|NDEx|Network Data Exchange||
| scrnaseqanalysis| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||A R/Bioconductor tool for cell type annotation using single-cell RNA-seq data. It is a supervised cell label assignment method that uses existing scRNA-seq data with known labels to train a neural network-based classifier, and then predict cell labels in single-cell RNA-seq data of interest.|True|False||[doi:10.1038/s41598-021-04473-4](doi:10.1038/s41598-021-04473-4)|[https://github.com/haoharryfeng/NeuCA](https://github.com/haoharryfeng/NeuCA)|[STANDARDSDATASTANDARDORTOOL:806](https://w3id.org/bridge2ai/standards-datastandardortool-schema/806)|[SoftwareOrTool](SoftwareOrTool)|NeuCA|NeuCA - Neural-network based Cell Annotation tool||
|| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20)| [STANDARDSORGANIZATION:90](STANDARDSORGANIZATION:90)|Enables scalable and reproducible scientific workflows using software containers. It allows the adaptation of pipelines written in the most common scripting languages.|True|False|[https://www.nextflow.io/](https://www.nextflow.io/)||[https://github.com/nextflow-io/nextflow](https://github.com/nextflow-io/nextflow)|[STANDARDSDATASTANDARDORTOOL:807](https://w3id.org/bridge2ai/standards-datastandardortool-schema/807)|[SoftwareOrTool](SoftwareOrTool)|Nextflow|Nextflow||
| cloudplatform| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)| [STANDARDSORGANIZATION:67 NHGRI](STANDARDSORGANIZATION:67 NHGRI)|AnVIL is NHGRI's Genomic Data Science Analysis, Visualization, and Informatics Lab-Space.|True|True|[https://anvilproject.org/](https://anvilproject.org/)||[https://github.com/anvilproject](https://github.com/anvilproject)|[STANDARDSDATASTANDARDORTOOL:808](https://w3id.org/bridge2ai/standards-datastandardortool-schema/808)|[SoftwareOrTool](SoftwareOrTool)|AnVIL|NHGRI Analysis Visualization and Informatics Lab-space||
|| [STANDARDSDATATOPIC:23](STANDARDSDATATOPIC:23)||An R package for quality evaluation of omics data tables. For each data table, OmicsEV uses a series of methods to evaluate data depth, data normalization, batch effect, biological signal, platform reproducibility, and multi-omics concordance, producing comprehensive visual and quantitative evaluation results that help assess data quality of individual data tables and facilitate the identification of the optimal data processing method and parameters for the omics study under investigation.|True|False||[doi:10.1093/bioinformatics/btac698](doi:10.1093/bioinformatics/btac698)|[https://github.com/bzhanglab/OmicsEV](https://github.com/bzhanglab/OmicsEV)|[STANDARDSDATASTANDARDORTOOL:809](https://w3id.org/bridge2ai/standards-datastandardortool-schema/809)|[SoftwareOrTool](SoftwareOrTool)|OmicsEV|OmicsEV||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|OAK provides a collection of interfaces for various ontology operations.|True|False|[https://incatools.github.io/ontology-access-kit/](https://incatools.github.io/ontology-access-kit/)||[https://github.com/INCATools/ontology-access-kit](https://github.com/INCATools/ontology-access-kit)|[STANDARDSDATASTANDARDORTOOL:810](https://w3id.org/bridge2ai/standards-datastandardortool-schema/810)|[SoftwareOrTool](SoftwareOrTool)|OAK|Ontology Access Kit||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:58](STANDARDSORGANIZATION:58)|A toolkit and workflow system for managing the ontology life-cycle.|True|False||[doi:10.1093/database/baac087](doi:10.1093/database/baac087)|[https://github.com/INCATools/ontology-development-kit](https://github.com/INCATools/ontology-development-kit)|[STANDARDSDATASTANDARDORTOOL:811](https://w3id.org/bridge2ai/standards-datastandardortool-schema/811)|[SoftwareOrTool](SoftwareOrTool)|ODK|Ontology Development Kit||
|| [STANDARDSDATATOPIC:18](STANDARDSDATATOPIC:18)||An open-source platform for wearable health monitoring. It aims to design a standard set of hardware/software and wearable devices that can enable autonomous collection of clinically relevant data.|True|False|[https://sites.google.com/view/openhealth-wearable-health/home](https://sites.google.com/view/openhealth-wearable-health/home)|[doi:10.1109/MDAT.2019.2906110](doi:10.1109/MDAT.2019.2906110)||[STANDARDSDATASTANDARDORTOOL:812](https://w3id.org/bridge2ai/standards-datastandardortool-schema/812)|[SoftwareOrTool](SoftwareOrTool)|OpenHealth|OpenHealth||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||An open source data analysis and manipulation tool built on top of the Python programming language.|True|False|[https://pandas.pydata.org/](https://pandas.pydata.org/)|||[STANDARDSDATASTANDARDORTOOL:813](https://w3id.org/bridge2ai/standards-datastandardortool-schema/813)|[SoftwareOrTool](SoftwareOrTool)|pandas|pandas||
| datavisualization| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||An open-source Python library that lets you create custom interactive web apps and dashboards by connecting user-defined widgets to plots, images, tables, or text.|True|False|[https://panel.holoviz.org/](https://panel.holoviz.org/)||[https://github.com/holoviz/panel](https://github.com/holoviz/panel)|[STANDARDSDATASTANDARDORTOOL:814](https://w3id.org/bridge2ai/standards-datastandardortool-schema/814)|[SoftwareOrTool](SoftwareOrTool)|Panel|Panel||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||An open source object-relational database system.|True|False|[https://www.postgresql.org/](https://www.postgresql.org/)||[https://github.com/postgres/postgres](https://github.com/postgres/postgres)|[STANDARDSDATASTANDARDORTOOL:815](https://w3id.org/bridge2ai/standards-datastandardortool-schema/815)|[SoftwareOrTool](SoftwareOrTool)|PostgreSQL|PostgreSQL||
| machinelearningframework| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A popular machine learning platform.|True|False|[https://pytorch.org/](https://pytorch.org/)||[https://github.com/pytorch/pytorch](https://github.com/pytorch/pytorch)|[STANDARDSDATASTANDARDORTOOL:816](https://w3id.org/bridge2ai/standards-datastandardortool-schema/816)|[SoftwareOrTool](SoftwareOrTool)|PyTorch|PyTorch||
| notebookplatform| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||An open-source scientific and technical publishing system built on Pandoc.|True|False|[https://quarto.org/](https://quarto.org/)||[https://github.com/quarto-dev/quarto-cli](https://github.com/quarto-dev/quarto-cli)|[STANDARDSDATASTANDARDORTOOL:817](https://w3id.org/bridge2ai/standards-datastandardortool-schema/817)|[SoftwareOrTool](SoftwareOrTool)|Quarto|Quarto publishing system||
| cloudplatform| [STANDARDSDATATOPIC:4](STANDARDSDATATOPIC:4)| [STANDARDSORGANIZATION:31](STANDARDSORGANIZATION:31)|The Rare Disease Cures Accelerator-Data and Analytics Platform (RDCA-DAP®) is an FDA-funded initiative that provides a centralized and standardized infrastructure to support and accelerate rare disease characterization, with the goal of accelerating therapy development across rare diseases.|False|True|[https://c-path.org/programs/rdca-dap/](https://c-path.org/programs/rdca-dap/)|||[STANDARDSDATASTANDARDORTOOL:818](https://w3id.org/bridge2ai/standards-datastandardortool-schema/818)|[SoftwareOrTool](SoftwareOrTool)|RDCA-DAP|Rare Disease Cures Accelerator-Data and Analytics Platform||
|| [STANDARDSDATATOPIC:13](STANDARDSDATATOPIC:13)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|Enables access to reference genomic sequences without ambiguity from different databases and servers using a checksum identifier based on the sequence content itself.|True|False|||[https://samtools.github.io/hts-specs/refget.html](https://samtools.github.io/hts-specs/refget.html)|[STANDARDSDATASTANDARDORTOOL:819](https://w3id.org/bridge2ai/standards-datastandardortool-schema/819)|[SoftwareOrTool](SoftwareOrTool)|refget|refget API||
| machinelearningframework| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Relexi is an open source reinforcement learning (RL) framework written in Python and based on TensorFlow’s RL library TF-Agents. Relexi allows to employ RL for environments that require computationally intensive simulations like applications in computational fluid dynamics. For this, Relexi couples legacy simulation codes with the RL library TF-Agents at scale on modern high-performance computing (HPC) hardware using the SmartSim library. Relexi thus provides an easy way to explore the potential of RL for HPC applications.|True|False||[doi:10.1016/j.simpa.2022.100422](doi:10.1016/j.simpa.2022.100422)|[https://github.com/flexi-framework/relexi](https://github.com/flexi-framework/relexi)|[STANDARDSDATASTANDARDORTOOL:820](https://w3id.org/bridge2ai/standards-datastandardortool-schema/820)|[SoftwareOrTool](SoftwareOrTool)|Relexi|Relexi||
|| [STANDARDSDATATOPIC:31](STANDARDSDATATOPIC:31)||Electronic data capture software and workflow methodology for designing clinical and translational research databases.|True|True|[https://www.project-redcap.org/](https://www.project-redcap.org/)|[doi:10.1016/j.jbi.2008.08.010](doi:10.1016/j.jbi.2008.08.010)||[STANDARDSDATASTANDARDORTOOL:821](https://w3id.org/bridge2ai/standards-datastandardortool-schema/821)|[SoftwareOrTool](SoftwareOrTool)|REDCap|Research Electronic Data Capture||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:86](STANDARDSORGANIZATION:86)|Synapse is a set of web services and tools that make it easier for researchers to aggregate, organize, analyze, and share scientific data, code, and insights.|True|True|[https://www.synapse.org/](https://www.synapse.org/)|[doi:10.2139/ssrn.3502410](doi:10.2139/ssrn.3502410)|[https://github.com/Sage-Bionetworks/Synapse-Repository-Services](https://github.com/Sage-Bionetworks/Synapse-Repository-Services)|[STANDARDSDATASTANDARDORTOOL:822](https://w3id.org/bridge2ai/standards-datastandardortool-schema/822)|[SoftwareOrTool](SoftwareOrTool)|Synapse|Sage Synapse||
|| [STANDARDSDATATOPIC:9](STANDARDSDATATOPIC:9)||An open source semantic search and analytics tool for EHRs.|True|False||[doi:10.1093/jamia/ocx160](doi:10.1093/jamia/ocx160)|[https://github.com/CogStack/CogStack-SemEHR](https://github.com/CogStack/CogStack-SemEHR)|[STANDARDSDATASTANDARDORTOOL:823](https://w3id.org/bridge2ai/standards-datastandardortool-schema/823)|[SoftwareOrTool](SoftwareOrTool)|SemEHR|SemEHR||
| scrnaseqanalysis| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||A regularized regression prediction and empirical Bayes method to recover the true gene expression profile in noisy and sparse scRNA-seq data.|True|False|[https://mohuangx.github.io/SAVER/](https://mohuangx.github.io/SAVER/)|[doi:10.1038/s41592-018-0033-z](doi:10.1038/s41592-018-0033-z)|[https://github.com/mohuangx/SAVER](https://github.com/mohuangx/SAVER)|[STANDARDSDATASTANDARDORTOOL:824](https://w3id.org/bridge2ai/standards-datastandardortool-schema/824)|[SoftwareOrTool](SoftwareOrTool)|SAVER|Single-cell Analysis Via Expression Recovery||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Platform for automated data labeling.|False|True|[https://www.snorkel.org/](https://www.snorkel.org/)||[https://github.com/snorkel-team/snorkel](https://github.com/snorkel-team/snorkel)|[STANDARDSDATASTANDARDORTOOL:825](https://w3id.org/bridge2ai/standards-datastandardortool-schema/825)|[SoftwareOrTool](SoftwareOrTool)|Snorkel|Snorkel||
|| [STANDARDSDATATOPIC:25](STANDARDSDATATOPIC:25) [STANDARDSDATATOPIC:35](STANDARDSDATATOPIC:35)||SnpEff is a variant annotation and effect prediction tool. It annotates and predicts the effects of genetic variants (such as amino acid changes).|True|False|[https://pcingola.github.io/SnpEff/se_introduction/](https://pcingola.github.io/SnpEff/se_introduction/)|[doi:10.4161/fly.19695](doi:10.4161/fly.19695)|[https://github.com/pcingola/SnpEff](https://github.com/pcingola/SnpEff)|[STANDARDSDATASTANDARDORTOOL:826](https://w3id.org/bridge2ai/standards-datastandardortool-schema/826)|[SoftwareOrTool](SoftwareOrTool)|SnpEff|SnpEff||
| scrnaseqanalysis| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||A method to cluster cells using the genetic variants detected within the scRNA-seq reads.|True|False||[doi:10.1038/s41592-020-0820-1](doi:10.1038/s41592-020-0820-1)|[https://github.com/wheaton5/souporcell](https://github.com/wheaton5/souporcell)|[STANDARDSDATASTANDARDORTOOL:827](https://w3id.org/bridge2ai/standards-datastandardortool-schema/827)|[SoftwareOrTool](SoftwareOrTool)|Souporcell|Souporcell||
|| [Transcript](Transcript) [STANDARDSDATATOPIC:33ome](STANDARDSDATATOPIC:33ome)||Software based on an RNA-seq alignment algorithm that uses sequential maximum mappable seed search in uncompressed suffix arrays followed by seed clustering and stitching procedure.|True|False||[doi:10.1093/bioinformatics/bts635](doi:10.1093/bioinformatics/bts635)|[https://github.com/alexdobin/STAR](https://github.com/alexdobin/STAR)|[STANDARDSDATASTANDARDORTOOL:828](https://w3id.org/bridge2ai/standards-datastandardortool-schema/828)|[SoftwareOrTool](SoftwareOrTool)|STAR|Spliced Transcripts Alignment to a Reference||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A web service for automatic layout of biological data in various standard formats as well as construction of customized images in both raster image and scalable vector formats of these maps. Some of the supported standards are more generic such as GraphML and JSON, whereas others are specialized to biology such as SBGNML (The Systems Biology Graphical Notation Markup Language) and SBML (The Systems Biology Markup Language).|True|False|[http://syblars.cs.bilkent.edu.tr/](http://syblars.cs.bilkent.edu.tr/)|[doi:10.1371/journal.pcbi.1010635](doi:10.1371/journal.pcbi.1010635)|[https://github.com/iVis-at-Bilkent/syblars](https://github.com/iVis-at-Bilkent/syblars)|[STANDARDSDATASTANDARDORTOOL:829](https://w3id.org/bridge2ai/standards-datastandardortool-schema/829)|[SoftwareOrTool](SoftwareOrTool)|SyBLaRS|Systems Biology Layout and Rendering Service||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|standardized schema and API for describing and executing batch execution tasks|True|False|[https://ga4gh.github.io/task-execution-schemas/docs/](https://ga4gh.github.io/task-execution-schemas/docs/)|||[STANDARDSDATASTANDARDORTOOL:830](https://w3id.org/bridge2ai/standards-datastandardortool-schema/830)|[SoftwareOrTool](SoftwareOrTool)|TES|Task Execution Service||
| machinelearningframework| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:37](STANDARDSORGANIZATION:37)|A popular machine learning platform.|True|False|[https://www.tensorflow.org/](https://www.tensorflow.org/)||[https://github.com/tensorflow/tensorflow](https://github.com/tensorflow/tensorflow)|[STANDARDSDATASTANDARDORTOOL:831](https://w3id.org/bridge2ai/standards-datastandardortool-schema/831)|[SoftwareOrTool](SoftwareOrTool)|TF|Tensorflow||
| cloudplatform| [STANDARDSDATATOPIC:20](STANDARDSDATATOPIC:20)| [STANDARDSORGANIZATION:71](STANDARDSORGANIZATION:71)|Terra is a cloud-native platform for biomedical researchers to access data, run analysis tools, and collaborate.|True|True|[https://app.terra.bio/](https://app.terra.bio/)||[https://github.com/DataBiosphere/terra-ui](https://github.com/DataBiosphere/terra-ui)|[STANDARDSDATASTANDARDORTOOL:832](https://w3id.org/bridge2ai/standards-datastandardortool-schema/832)|[SoftwareOrTool](SoftwareOrTool)|Terra|Terra Community Workbench||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A free software environment for statistical computing and graphics.|True|False|[https://www.r-project.org/](https://www.r-project.org/)|||[STANDARDSDATASTANDARDORTOOL:833](https://w3id.org/bridge2ai/standards-datastandardortool-schema/833)|[SoftwareOrTool](SoftwareOrTool)|R|The R Project for Statistical Computing||
| deprecated machinelearningframework| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||A Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It is being continued as aesara.|True|False|||[https://github.com/Theano/Theano](https://github.com/Theano/Theano)|[STANDARDSDATASTANDARDORTOOL:834](https://w3id.org/bridge2ai/standards-datastandardortool-schema/834)|[SoftwareOrTool](SoftwareOrTool)|Theano|Theano||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|common API for describing tools in registries|True|False|[https://ga4gh.github.io/tool-registry-service-schemas/](https://ga4gh.github.io/tool-registry-service-schemas/)|||[STANDARDSDATASTANDARDORTOOL:835](https://w3id.org/bridge2ai/standards-datastandardortool-schema/835)|[SoftwareOrTool](SoftwareOrTool)|TRS|Tool Registry Service||
|| [STANDARDSDATATOPIC:4, Genome](STANDARDSDATATOPIC:4, Genome)| [STANDARDSORGANIZATION:94](STANDARDSORGANIZATION:94)|U-BRITE (UAB Biomedical Research Information Technology Enhancement) assembles new and existing HIPAA-compliant, high-performance informatics tools to provide researchers with a means to better manage and analyze clinical and genomic data sets and implements a “translational research commons” to facilitate and enable interdisciplinary team science across geographical locations.|False|True|[https://ubrite.org/](https://ubrite.org/)|||[STANDARDSDATASTANDARDORTOOL:836](https://w3id.org/bridge2ai/standards-datastandardortool-schema/836)|[SoftwareOrTool](SoftwareOrTool)|U-BRITE|UAB Biomedical Research Information Technology Enhancement Commons Program||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|An application to help create mappings between coding systems and the Vocabulary standard concepts.|True|False|||[https://github.com/OHDSI/Usagi](https://github.com/OHDSI/Usagi)|[STANDARDSDATASTANDARDORTOOL:837](https://w3id.org/bridge2ai/standards-datastandardortool-schema/837)|[SoftwareOrTool](SoftwareOrTool)|Usagi|Usagi||
|| [STANDARDSDATATOPIC:34](STANDARDSDATATOPIC:34)||A computationally efficient Bayesian model to demultiplex single-cell data from pooled experimental designs.|True|False||[doi:10.1186/s13059-019-1865-2](doi:10.1186/s13059-019-1865-2)|[https://github.com/single-cell-genetics/vireo](https://github.com/single-cell-genetics/vireo)|[STANDARDSDATASTANDARDORTOOL:838](https://w3id.org/bridge2ai/standards-datastandardortool-schema/838)|[SoftwareOrTool](SoftwareOrTool)|Vireo|Vireo||
| cloudservice| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Cloud storage platform.|False|True|[https://wasabi.com/](https://wasabi.com/)|||[STANDARDSDATASTANDARDORTOOL:839](https://w3id.org/bridge2ai/standards-datastandardortool-schema/839)|[SoftwareOrTool](SoftwareOrTool)|Wasabi|Wasabi Cloud Storage||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Platform for tracking, comparing, and visualizing machine learning experiments.|True|True|[https://wandb.ai/](https://wandb.ai/)|||[STANDARDSDATASTANDARDORTOOL:840](https://w3id.org/bridge2ai/standards-datastandardortool-schema/840)|[SoftwareOrTool](SoftwareOrTool)|W&B|Weights and Balances platform||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)| [STANDARDSORGANIZATION:34](STANDARDSORGANIZATION:34)|Standard for submitting workflow requests to workflow execution systems.|True|False|[https://ga4gh.github.io/workflow-execution-service-schemas/docs/](https://ga4gh.github.io/workflow-execution-service-schemas/docs/)|||[STANDARDSDATASTANDARDORTOOL:841](https://w3id.org/bridge2ai/standards-datastandardortool-schema/841)|[SoftwareOrTool](SoftwareOrTool)|WES|Workflow Execution Service||
|| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||Git-based collaboration to large scale repositories of data, code, or any combination of files.|True|True|[https://xethub.com/assets/docs/](https://xethub.com/assets/docs/)|||[STANDARDSDATASTANDARDORTOOL:842](https://w3id.org/bridge2ai/standards-datastandardortool-schema/842)|[SoftwareOrTool](SoftwareOrTool)|Xethub|Xethub||
| machinelearningframework| [STANDARDSDATATOPIC:5](STANDARDSDATATOPIC:5)||ZenML is an extensible, open-source MLOps framework for creating portable, production-ready MLOps pipelines.|True|False|[https://zenml.io/](https://zenml.io/)||[https://github.com/zenml-io/zenml](https://github.com/zenml-io/zenml)|[STANDARDSDATASTANDARDORTOOL:843](https://w3id.org/bridge2ai/standards-datastandardortool-schema/843)|[SoftwareOrTool](SoftwareOrTool)|ZenML|ZenML||
||| [STANDARDSORGANIZATION:76](STANDARDSORGANIZATION:76)|This workshop is for data holders who want to apply OHDSI’s data standards to their own observational datasets and researchers who want to be aware of OHDSI’s data standards, so they can leverage data in OMOP CDM format for their own research purposes.|True|False|[https://www.ohdsi.org/2019-tutorials-omop-common-data-model-and-standardized-vocabularies/](https://www.ohdsi.org/2019-tutorials-omop-common-data-model-and-standardized-vocabularies/)||[https://github.com/OHDSI/Tutorial-CDM](https://github.com/OHDSI/Tutorial-CDM)|[STANDARDSDATASTANDARDORTOOL:844](https://w3id.org/bridge2ai/standards-datastandardortool-schema/844)|[TrainingProgram](TrainingProgram)|OHDSI Tutorials|2019 OHDSI Tutorials - OMOP Common Data Model and Standardized Vocabularies||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|A series of HL7 FAIR training lecture recordings made available through YouTube.|True|False|[https://www.cdc.gov/nchs/data/nvss/modernization/Introductory-Training-FHIR.pdf](https://www.cdc.gov/nchs/data/nvss/modernization/Introductory-Training-FHIR.pdf)|||[STANDARDSDATASTANDARDORTOOL:845](https://w3id.org/bridge2ai/standards-datastandardortool-schema/845)|[DataStandardOrTool](DataStandardOrTool)|CDC Introduction to FHIR|CDC Introduction to FHIR - Training Recordings||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|This set of pages contains a series of FHIR tutorials for those just beginning to learn the new specification. The tutorials require no prior knowledge of FHIR or REST. At present these tutorials are in their beta stage of development and we would appreciate any feedback you may have as we plan to build upon these in time to create a full set of tutorials from the very basic to the more complex.|True|False|[https://fhir-drills.github.io/](https://fhir-drills.github.io/)|||[STANDARDSDATASTANDARDORTOOL:846](https://w3id.org/bridge2ai/standards-datastandardortool-schema/846)|[TrainingProgram](TrainingProgram)|FHIR Drills|FHIR Drills||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|This is an asynchronous, instructor-led online course that allows you to work at your own pace. Learning takes place through discussions with the instructor, tutors and peers. Assessments are in the form of weekly assignments, quizzes, exams and projects. Plan on spending 5 to 7 hours per week. There are no live lectures to attend.|False|True|[https://www.hl7.org/training/fhir-fundamentals.cfm](https://www.hl7.org/training/fhir-fundamentals.cfm)||[https://courses.hl7fundamentals.org/campus/](https://courses.hl7fundamentals.org/campus/)|[STANDARDSDATASTANDARDORTOOL:847](https://w3id.org/bridge2ai/standards-datastandardortool-schema/847)|[TrainingProgram](TrainingProgram)|FHIR Fundamentals|HL7 FHIR Fundamentals Course||
||| [STANDARDSORGANIZATION:53](STANDARDSORGANIZATION:53)|Welcome to the LOINC Library. This is our A to Z collection of resources that we've collected to help you learn about LOINC and get connected to the community.|True|False|[https://loinc.org/learn/](https://loinc.org/learn/)|||[STANDARDSDATASTANDARDORTOOL:848](https://w3id.org/bridge2ai/standards-datastandardortool-schema/848)|[TrainingProgram](TrainingProgram)|Learn LOINC|Learn LOINC||
||| [STANDARDSDATASTANDARDORTOOL:98](STANDARDSDATASTANDARDORTOOL:98) [STANDARDSORGANIZATION:56](STANDARDSORGANIZATION:56)|Learn why DICOM standards are important. Explore the DICOM standards and DICOM service. Review the use case for radiology data in cancer treatment with examples.|True|False|[https://learn.microsoft.com/en-us/training/modules/medical-imaging-data/](https://learn.microsoft.com/en-us/training/modules/medical-imaging-data/)|||[STANDARDSDATASTANDARDORTOOL:849](https://w3id.org/bridge2ai/standards-datastandardortool-schema/849)|[TrainingProgram](TrainingProgram)|Microsoft Medical Imaging|Microsoft Learn - Work with medical imaging data and DICOM||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40)|This course will help you understand the basics of FHIR. It is a FREE sample of a comprehensive hands-on introductory course (details inside). The full course includes direct access to the course creator via a private members-only Slack room.|True|True|[https://www.udemy.com/course/introduction-to-fhir/](https://www.udemy.com/course/introduction-to-fhir/)|||[STANDARDSDATASTANDARDORTOOL:850](https://w3id.org/bridge2ai/standards-datastandardortool-schema/850)|[TrainingProgram](TrainingProgram)|Udemy FHIR|Udemy - Introduction to FHIR||
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40) [STANDARDSORGANIZATION:103](STANDARDSORGANIZATION:103)|This is subset of all FHIR profiles for the US Realm, i.e., those supporting the minimum requirements for clinical data exchange in the United States.|True|False|[https://build.fhir.org/ig/HL7/US-Core/index.html](https://build.fhir.org/ig/HL7/US-Core/index.html)|||[STANDARDSDATASTANDARDORTOOL:851](https://w3id.org/bridge2ai/standards-datastandardortool-schema/851)|[BiomedicalStandard](BiomedicalStandard)|FHIR US Core|Fast Healthcare Interoperability Resources - US Core| [STANDARDSDATASTANDARDORTOOL:109](STANDARDSDATASTANDARDORTOOL:109)|
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40) [STANDARDSORGANIZATION:103](STANDARDSORGANIZATION:103)|USCDI is the set of basic healthcare data types expected to supported by other systems. This is the FHIR US Core profile with all elements required by USCDI.|True|False|[https://build.fhir.org/ig/HL7/US-Core/uscdi.html](https://build.fhir.org/ig/HL7/US-Core/uscdi.html)|||[STANDARDSDATASTANDARDORTOOL:852](https://w3id.org/bridge2ai/standards-datastandardortool-schema/852)|[BiomedicalStandard](BiomedicalStandard)|FHIR USCDI|Fast Healthcare Interoperability Resources - US Core Data for Interoperability| [STANDARDSDATASTANDARDORTOOL:851](STANDARDSDATASTANDARDORTOOL:851)|
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40) [STANDARDSORGANIZATION:103](STANDARDSORGANIZATION:103)|USCDI is the set of basic healthcare data types expected to supported by other systems. This is the FHIR US Core profile with all elements required by USCDI v1.|True|False|[https://build.fhir.org/ig/HL7/US-Core/uscdi.html](https://build.fhir.org/ig/HL7/US-Core/uscdi.html)|||[STANDARDSDATASTANDARDORTOOL:853](https://w3id.org/bridge2ai/standards-datastandardortool-schema/853)|[BiomedicalStandard](BiomedicalStandard)|FHIR USCDI v1|Fast Healthcare Interoperability Resources - US Core Data for Interoperability, version 1| [STANDARDSDATASTANDARDORTOOL:852](STANDARDSDATASTANDARDORTOOL:852)|
||| [STANDARDSORGANIZATION:40](STANDARDSORGANIZATION:40) [STANDARDSORGANIZATION:103](STANDARDSORGANIZATION:103)|USCDI is the set of basic healthcare data types expected to supported by other systems. This is the FHIR US Core profile with all elements required by USCDI v4.|True|False|[https://build.fhir.org/ig/HL7/US-Core/uscdi.html](https://build.fhir.org/ig/HL7/US-Core/uscdi.html)|||[STANDARDSDATASTANDARDORTOOL:854](https://w3id.org/bridge2ai/standards-datastandardortool-schema/854)|[BiomedicalStandard](BiomedicalStandard)|FHIR USCDI v4|Fast Healthcare Interoperability Resources - US Core Data for Interoperability, version 4| [STANDARDSDATASTANDARDORTOOL:852](STANDARDSDATASTANDARDORTOOL:852)|
| multimodal|||A cross-platform app for analyzing qualitative and mixed methods research|False|True|[https://www.dedoose.com/](https://www.dedoose.com/)|||[STANDARDSDATASTANDARDORTOOL:855](https://w3id.org/bridge2ai/standards-datastandardortool-schema/855)|[SoftwareOrTool](SoftwareOrTool)|Dedoose|Dedoose app||
||||A lightweight application written in Java, that aims to support researchers in managing research metadata according to the FAIR principles.|True|False|[https://fairbydesign.nl/](https://fairbydesign.nl/)|[doi:10.1093/gigascience/giad014](doi:10.1093/gigascience/giad014)||[STANDARDSDATASTANDARDORTOOL:856](https://w3id.org/bridge2ai/standards-datastandardortool-schema/856)|[SoftwareOrTool](SoftwareOrTool)|FAIR Data Station|FAIR Data Station||
